{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCtT1U6idYFs",
        "outputId": "438def04-7da6-4f3f-aae5-c193a71ede39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age gender residence  competative_exams  access_to_internet  \\\n",
            "0   11      M         H                  0                   0   \n",
            "1   14      F         D                  0                   1   \n",
            "2   21      M         H                  1                   1   \n",
            "3   24      F         H                  1                   0   \n",
            "4   12      F         H                  0                   0   \n",
            "\n",
            "   study_hours_per_day  has_scholarship  extracurricular_activities  \\\n",
            "0                    4                0                           1   \n",
            "1                    1                1                           0   \n",
            "2                    6                0                           1   \n",
            "3                    7                0                           0   \n",
            "4                    5                1                           0   \n",
            "\n",
            "   fam_fin_status  health  ... f_job  m_job  alcoholic  additional_tuition  \\\n",
            "0               3       5  ...     0      0          0                   1   \n",
            "1               4       2  ...     1      0          0                   0   \n",
            "2               5       3  ...     1      1          1                   0   \n",
            "3               4       2  ...     1      1          1                   1   \n",
            "4               3       1  ...     1      0          0                   1   \n",
            "\n",
            "   fam_size  fam_relation  prev_percent_1  prev_percent_2  prev_percent_3  \\\n",
            "0        14             4              73              73              67   \n",
            "1         1             2              96              87              80   \n",
            "2        15             2              81              78              93   \n",
            "3        15             4              77              71              88   \n",
            "4        13             3              66              78              85   \n",
            "\n",
            "   TARGET_PREDICTION_PERCENT  \n",
            "0                         71  \n",
            "1                         87  \n",
            "2                         84  \n",
            "3                         78  \n",
            "4                         76  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming the CSV file is named 'data.csv' and is in the same directory as your Python script\n",
        "file_path = '/content/Final_Training_Data.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_data=[\"gender\",\"location\",\"residence\"]"
      ],
      "metadata": {
        "id": "UZxUQPmwhFhn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded = pd.get_dummies(df,columns=cat_data)\n",
        "df_encoded.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "fyxPHt7BhVtV",
        "outputId": "48ef487b-a725-462b-f2b0-1ee51216c357"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  competative_exams  access_to_internet  study_hours_per_day  \\\n",
              "0   11                  0                   0                    4   \n",
              "1   14                  0                   1                    1   \n",
              "2   21                  1                   1                    6   \n",
              "3   24                  1                   0                    7   \n",
              "4   12                  0                   0                    5   \n",
              "\n",
              "   has_scholarship  extracurricular_activities  fam_fin_status  health  f_edu  \\\n",
              "0                0                           1               3       5      4   \n",
              "1                1                           0               4       2      5   \n",
              "2                0                           1               5       3      3   \n",
              "3                0                           0               4       2      2   \n",
              "4                1                           0               3       1      3   \n",
              "\n",
              "   m_edu  ...  prev_percent_1  prev_percent_2  prev_percent_3  \\\n",
              "0      5  ...              73              73              67   \n",
              "1      0  ...              96              87              80   \n",
              "2      4  ...              81              78              93   \n",
              "3      1  ...              77              71              88   \n",
              "4      3  ...              66              78              85   \n",
              "\n",
              "   TARGET_PREDICTION_PERCENT  gender_F  gender_M  location_R  location_U  \\\n",
              "0                         71     False      True        True       False   \n",
              "1                         87      True     False       False        True   \n",
              "2                         84     False      True       False        True   \n",
              "3                         78      True     False       False        True   \n",
              "4                         76      True     False        True       False   \n",
              "\n",
              "   residence_D  residence_H  \n",
              "0        False         True  \n",
              "1         True        False  \n",
              "2        False         True  \n",
              "3        False         True  \n",
              "4        False         True  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d0aea13-41ec-4211-b8bf-6c59060e1e5c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>competative_exams</th>\n",
              "      <th>access_to_internet</th>\n",
              "      <th>study_hours_per_day</th>\n",
              "      <th>has_scholarship</th>\n",
              "      <th>extracurricular_activities</th>\n",
              "      <th>fam_fin_status</th>\n",
              "      <th>health</th>\n",
              "      <th>f_edu</th>\n",
              "      <th>m_edu</th>\n",
              "      <th>...</th>\n",
              "      <th>prev_percent_1</th>\n",
              "      <th>prev_percent_2</th>\n",
              "      <th>prev_percent_3</th>\n",
              "      <th>TARGET_PREDICTION_PERCENT</th>\n",
              "      <th>gender_F</th>\n",
              "      <th>gender_M</th>\n",
              "      <th>location_R</th>\n",
              "      <th>location_U</th>\n",
              "      <th>residence_D</th>\n",
              "      <th>residence_H</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>73</td>\n",
              "      <td>73</td>\n",
              "      <td>67</td>\n",
              "      <td>71</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>96</td>\n",
              "      <td>87</td>\n",
              "      <td>80</td>\n",
              "      <td>87</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>81</td>\n",
              "      <td>78</td>\n",
              "      <td>93</td>\n",
              "      <td>84</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>77</td>\n",
              "      <td>71</td>\n",
              "      <td>88</td>\n",
              "      <td>78</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>66</td>\n",
              "      <td>78</td>\n",
              "      <td>85</td>\n",
              "      <td>76</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 26 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d0aea13-41ec-4211-b8bf-6c59060e1e5c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1d0aea13-41ec-4211-b8bf-6c59060e1e5c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1d0aea13-41ec-4211-b8bf-6c59060e1e5c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7dc8df5b-b4f0-4d8d-8e27-463f9f28ea3b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7dc8df5b-b4f0-4d8d-8e27-463f9f28ea3b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7dc8df5b-b4f0-4d8d-8e27-463f9f28ea3b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_encoded"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique values of the 'gender' column\n",
        "print(\"Unique values of 'gender' column:\")\n",
        "print(df['gender'].unique())\n",
        "\n",
        "# Check unique values of the 'location' column\n",
        "print(\"\\nUnique values of 'location' column:\")\n",
        "print(df['location'].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QMNgF1B2-NT",
        "outputId": "65fd3646-43dd-4f10-9f75-e8cf08e270d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values of 'gender' column:\n",
            "['M' 'F']\n",
            "\n",
            "Unique values of 'location' column:\n",
            "['R' 'U']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQSLnCSPMPdY",
        "outputId": "d66cb59d-e442-44f7-c95b-7c5906ae6027"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'competative_exams', 'access_to_internet', 'study_hours_per_day',\n",
              "       'has_scholarship', 'extracurricular_activities', 'fam_fin_status',\n",
              "       'health', 'f_edu', 'm_edu', 'f_job', 'm_job', 'alcoholic',\n",
              "       'additional_tuition', 'fam_size', 'fam_relation', 'prev_percent_1',\n",
              "       'prev_percent_2', 'prev_percent_3', 'TARGET_PREDICTION_PERCENT',\n",
              "       'gender_F', 'gender_M', 'location_R', 'location_U', 'residence_D',\n",
              "       'residence_H'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming your target column name is 'TARGET_PREDICTION_PERCENT'\n",
        "features = df_encoded.drop(columns=['TARGET_PREDICTION_PERCENT'])\n",
        "targets = df_encoded['TARGET_PREDICTION_PERCENT']\n",
        "\n",
        "\n",
        "print(\"\\nTargets:\")\n",
        "print(targets.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3zsPQwQd0h2",
        "outputId": "badcd774-fac4-4c6e-a56e-9b4195adf46f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Targets:\n",
            "0    71\n",
            "1    87\n",
            "2    84\n",
            "3    78\n",
            "4    76\n",
            "Name: TARGET_PREDICTION_PERCENT, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and fit any necessary transformations (e.g., StandardScaler) on the training data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transform the testing data using the fitted transformation from the training data\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "-Szlu9EggZZS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTraining features after scaling:\")\n",
        "print(X_train_scaled[:5])\n",
        "\n",
        "print(\"\\nTesting features after scaling:\")\n",
        "print(X_test_scaled[:5])\n",
        "\n",
        "print(\"\\nTraining targets:\")\n",
        "print(y_train.head())\n",
        "\n",
        "print(\"\\nTesting targets:\")\n",
        "print(y_test.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDtr8fbthEDz",
        "outputId": "6666a31c-a980-4fc4-b900-baff6ab78de1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training features after scaling:\n",
            "[[ 1.45674283e+00 -8.98834469e-01  5.02465405e-01  7.05426038e-01\n",
            "  -8.26835603e-01 -1.01348706e+00 -1.90690515e+00  1.06690603e+00\n",
            "   1.28020232e+00  8.19081291e-01 -1.77738316e+00  1.21213257e+00\n",
            "  -9.23217457e-01 -8.35147941e-01 -1.34663446e+00 -2.45182200e+00\n",
            "  -1.79338663e+00  1.09638153e+00 -5.86041494e-01  1.03774904e+00\n",
            "  -1.03774904e+00 -7.89088144e-01  7.89088144e-01  8.87847743e-01\n",
            "  -8.87847743e-01]\n",
            " [-7.09208688e-01 -8.98834469e-01  5.02465405e-01  7.05426038e-01\n",
            "  -8.26835603e-01  4.34226025e-01 -1.07095285e+00  1.06690603e+00\n",
            "  -1.72441930e+00 -1.33133351e+00 -1.77738316e+00 -8.24992270e-01\n",
            "  -1.11830503e-01 -8.35147941e-01 -2.17353933e-01  9.48726070e-01\n",
            "   9.30393652e-02  2.30285736e-03  1.96756949e-02 -9.63624112e-01\n",
            "   9.63624112e-01  1.26728555e+00 -1.26728555e+00 -1.12631924e+00\n",
            "   1.12631924e+00]\n",
            " [-3.99787043e-01 -8.98834469e-01  5.02465405e-01 -4.45667111e-01\n",
            "  -8.26835603e-01  4.34226025e-01 -2.35000555e-01  1.92680045e-01\n",
            "  -2.22108490e-01  1.02276357e-01 -1.77738316e+00 -8.24992270e-01\n",
            "  -1.11830503e-01 -8.35147941e-01 -2.17353933e-01  9.48726070e-01\n",
            "   8.91142670e-01 -7.06357211e-02  7.01107532e-01  1.03774904e+00\n",
            "  -1.03774904e+00  1.26728555e+00 -1.26728555e+00 -1.12631924e+00\n",
            "   1.12631924e+00]\n",
            " [ 5.28477891e-01 -8.98834469e-01  5.02465405e-01 -6.19693944e-02\n",
            "   1.06718142e+00  4.34226025e-01 -1.07095285e+00  1.06690603e+00\n",
            "   1.28020232e+00 -6.14528577e-01  5.62624886e-01  1.21213257e+00\n",
            "   2.32233036e+00 -8.35147941e-01 -2.17353933e-01  9.85890530e-02\n",
            "  -5.59954248e-01  5.85811485e-01 -8.88900088e-01 -9.63624112e-01\n",
            "   9.63624112e-01  1.26728555e+00 -1.26728555e+00  8.87847743e-01\n",
            "  -8.87847743e-01]\n",
            " [-3.18458185e+00 -8.98834469e-01 -1.99018677e+00  3.21728322e-01\n",
            "  -8.26835603e-01  4.34226025e-01 -1.07095285e+00  1.92680045e-01\n",
            "  -2.22108490e-01 -6.14528577e-01  5.62624886e-01  1.21213257e+00\n",
            "  -9.23217457e-01 -8.35147941e-01  2.60584739e+00 -7.51547964e-01\n",
            "  -2.69734864e-01 -7.06357211e-02 -6.61756142e-01 -9.63624112e-01\n",
            "   9.63624112e-01  1.26728555e+00 -1.26728555e+00  8.87847743e-01\n",
            "  -8.87847743e-01]]\n",
            "\n",
            "Testing features after scaling:\n",
            "[[ 0.52847789 -0.89883447 -1.99018677  0.32172832  1.06718142  0.43422602\n",
            "   1.43690404  0.19268004  1.28020232  0.81908129  0.56262489  1.21213257\n",
            "  -0.92321746 -0.83514794 -0.21735393  0.09858905  0.45581359  0.65875006\n",
            "   0.32253429 -0.96362411  0.96362411  1.26728555 -1.26728555  0.88784774\n",
            "  -0.88784774]\n",
            " [ 0.83789954  1.1125519  -1.99018677  0.32172832  1.06718142  0.43422602\n",
            "   1.43690404 -1.55577193 -1.7244193   1.53588622 -1.77738316 -0.82499227\n",
            "  -0.92321746  1.05685847 -0.7819942   0.94872607  0.96369752  0.65875006\n",
            "   0.85253683  1.03774904 -1.03774904 -0.78908814  0.78908814 -1.12631924\n",
            "   1.12631924]\n",
            " [ 1.14732118 -0.89883447 -1.99018677  0.32172832  1.06718142  0.43422602\n",
            "   1.43690404  0.19268004  1.28020232  0.81908129  0.56262489  1.21213257\n",
            "  -0.92321746 -0.83514794 -0.21735393  0.09858905  0.45581359  0.65875006\n",
            "   0.32253429 -0.96362411  0.96362411  1.26728555 -1.26728555  0.88784774\n",
            "  -0.88784774]\n",
            " [-1.63747362 -0.89883447  0.5024654  -0.44566711  1.06718142  0.43422602\n",
            "   1.43690404  0.19268004  0.52904692  0.10227636  0.56262489  1.21213257\n",
            "  -0.1118305  -0.83514794  0.34728633  0.94872607 -0.05207033  0.58581148\n",
            "   0.39824894 -0.96362411  0.96362411  1.26728555 -1.26728555  0.88784774\n",
            "  -0.88784774]\n",
            " [ 4.24153763  1.1125519  -1.99018677  1.08912375  1.06718142  0.43422602\n",
            "  -1.90690515 -0.68154594 -0.9732639  -1.33133351  0.56262489  1.21213257\n",
            "  -0.92321746  1.05685847 -0.7819942   0.09858905  0.23814906 -0.43532861\n",
            "   0.62539288  1.03774904 -1.03774904  1.26728555 -1.26728555  0.88784774\n",
            "  -0.88784774]]\n",
            "\n",
            "Training targets:\n",
            "266     96\n",
            "1133    84\n",
            "1823    85\n",
            "1370    75\n",
            "67      74\n",
            "Name: TARGET_PREDICTION_PERCENT, dtype: int64\n",
            "\n",
            "Testing targets:\n",
            "1298    98\n",
            "591     96\n",
            "1318    82\n",
            "1067    81\n",
            "29      80\n",
            "Name: TARGET_PREDICTION_PERCENT, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mean_squared_error',\n",
        "    metrics=['mae', tf.keras.metrics.RootMeanSquaredError()]\n",
        ")\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "CoDLg22JiGLt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01d2d34c-6173-4086-9710-46e14eee3239"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                1664      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3777 (14.75 KB)\n",
            "Trainable params: 3777 (14.75 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train, validation_data=(X_test_scaled, y_test), epochs=100, batch_size=10, verbose=1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA8aGATKidUr",
        "outputId": "e4e9bbb9-902a-4b7a-97a1-51d5156ac337"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 4346.3447 - mae: 62.6320 - root_mean_squared_error: 65.9268 - val_loss: 939.6412 - val_mae: 27.7895 - val_root_mean_squared_error: 30.6536\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 282.9892 - mae: 13.2447 - root_mean_squared_error: 16.8223 - val_loss: 225.8640 - val_mae: 10.7898 - val_root_mean_squared_error: 15.0288\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 152.0705 - mae: 9.3223 - root_mean_squared_error: 12.3317 - val_loss: 181.0938 - val_mae: 9.7761 - val_root_mean_squared_error: 13.4571\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 125.5243 - mae: 8.3269 - root_mean_squared_error: 11.2038 - val_loss: 153.6542 - val_mae: 8.6891 - val_root_mean_squared_error: 12.3957\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 111.7028 - mae: 7.7566 - root_mean_squared_error: 10.5690 - val_loss: 142.4805 - val_mae: 8.3433 - val_root_mean_squared_error: 11.9365\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 102.7462 - mae: 7.3819 - root_mean_squared_error: 10.1364 - val_loss: 135.9547 - val_mae: 8.0012 - val_root_mean_squared_error: 11.6600\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 95.9880 - mae: 7.1005 - root_mean_squared_error: 9.7973 - val_loss: 132.0967 - val_mae: 7.9166 - val_root_mean_squared_error: 11.4933\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 91.7490 - mae: 6.8896 - root_mean_squared_error: 9.5786 - val_loss: 126.1503 - val_mae: 7.6557 - val_root_mean_squared_error: 11.2317\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 88.8400 - mae: 6.7719 - root_mean_squared_error: 9.4255 - val_loss: 122.3713 - val_mae: 7.5845 - val_root_mean_squared_error: 11.0622\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 85.5003 - mae: 6.5657 - root_mean_squared_error: 9.2466 - val_loss: 122.6215 - val_mae: 7.6701 - val_root_mean_squared_error: 11.0735\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 83.2299 - mae: 6.5290 - root_mean_squared_error: 9.1230 - val_loss: 121.2559 - val_mae: 7.6510 - val_root_mean_squared_error: 11.0116\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 80.2994 - mae: 6.3158 - root_mean_squared_error: 8.9610 - val_loss: 118.1886 - val_mae: 7.3820 - val_root_mean_squared_error: 10.8715\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 79.2105 - mae: 6.2647 - root_mean_squared_error: 8.9000 - val_loss: 116.3827 - val_mae: 7.3374 - val_root_mean_squared_error: 10.7881\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 77.8777 - mae: 6.1997 - root_mean_squared_error: 8.8248 - val_loss: 114.4431 - val_mae: 7.3330 - val_root_mean_squared_error: 10.6978\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 75.9539 - mae: 6.1522 - root_mean_squared_error: 8.7152 - val_loss: 120.3629 - val_mae: 7.7580 - val_root_mean_squared_error: 10.9710\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 75.5379 - mae: 6.1055 - root_mean_squared_error: 8.6913 - val_loss: 111.4272 - val_mae: 7.1158 - val_root_mean_squared_error: 10.5559\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 73.5066 - mae: 6.0191 - root_mean_squared_error: 8.5736 - val_loss: 110.7712 - val_mae: 7.0831 - val_root_mean_squared_error: 10.5248\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 73.0235 - mae: 5.9392 - root_mean_squared_error: 8.5454 - val_loss: 110.6001 - val_mae: 7.0785 - val_root_mean_squared_error: 10.5167\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 71.1911 - mae: 5.8741 - root_mean_squared_error: 8.4375 - val_loss: 112.7291 - val_mae: 7.1539 - val_root_mean_squared_error: 10.6174\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 71.0214 - mae: 5.8922 - root_mean_squared_error: 8.4274 - val_loss: 108.9723 - val_mae: 7.0712 - val_root_mean_squared_error: 10.4390\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 70.1194 - mae: 5.8215 - root_mean_squared_error: 8.3737 - val_loss: 112.4525 - val_mae: 7.3402 - val_root_mean_squared_error: 10.6044\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 69.0905 - mae: 5.7983 - root_mean_squared_error: 8.3121 - val_loss: 108.5025 - val_mae: 6.9599 - val_root_mean_squared_error: 10.4165\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 68.4365 - mae: 5.7418 - root_mean_squared_error: 8.2726 - val_loss: 109.5215 - val_mae: 7.1442 - val_root_mean_squared_error: 10.4653\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 68.0527 - mae: 5.7328 - root_mean_squared_error: 8.2494 - val_loss: 108.2133 - val_mae: 6.9226 - val_root_mean_squared_error: 10.4026\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 67.0770 - mae: 5.7153 - root_mean_squared_error: 8.1901 - val_loss: 109.0758 - val_mae: 7.1087 - val_root_mean_squared_error: 10.4439\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 66.3497 - mae: 5.6589 - root_mean_squared_error: 8.1455 - val_loss: 109.4956 - val_mae: 7.1736 - val_root_mean_squared_error: 10.4640\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 65.5247 - mae: 5.6147 - root_mean_squared_error: 8.0947 - val_loss: 107.4855 - val_mae: 7.0975 - val_root_mean_squared_error: 10.3675\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 64.1350 - mae: 5.5792 - root_mean_squared_error: 8.0084 - val_loss: 107.6654 - val_mae: 6.9252 - val_root_mean_squared_error: 10.3762\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 63.8349 - mae: 5.5540 - root_mean_squared_error: 7.9897 - val_loss: 108.7884 - val_mae: 7.1160 - val_root_mean_squared_error: 10.4302\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 63.8673 - mae: 5.5545 - root_mean_squared_error: 7.9917 - val_loss: 110.4976 - val_mae: 6.9901 - val_root_mean_squared_error: 10.5118\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 62.9494 - mae: 5.5411 - root_mean_squared_error: 7.9341 - val_loss: 104.7761 - val_mae: 6.7751 - val_root_mean_squared_error: 10.2360\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 63.1243 - mae: 5.5312 - root_mean_squared_error: 7.9451 - val_loss: 106.2802 - val_mae: 6.8840 - val_root_mean_squared_error: 10.3092\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 61.8938 - mae: 5.5089 - root_mean_squared_error: 7.8673 - val_loss: 106.8710 - val_mae: 6.8540 - val_root_mean_squared_error: 10.3378\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 61.7153 - mae: 5.4692 - root_mean_squared_error: 7.8559 - val_loss: 107.0210 - val_mae: 6.8852 - val_root_mean_squared_error: 10.3451\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 60.2608 - mae: 5.3849 - root_mean_squared_error: 7.7628 - val_loss: 108.3542 - val_mae: 7.1580 - val_root_mean_squared_error: 10.4093\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 59.8178 - mae: 5.4187 - root_mean_squared_error: 7.7342 - val_loss: 106.8007 - val_mae: 6.8724 - val_root_mean_squared_error: 10.3344\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 59.1866 - mae: 5.3206 - root_mean_squared_error: 7.6933 - val_loss: 105.2967 - val_mae: 6.8090 - val_root_mean_squared_error: 10.2614\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 58.9827 - mae: 5.3698 - root_mean_squared_error: 7.6800 - val_loss: 106.2103 - val_mae: 6.8452 - val_root_mean_squared_error: 10.3058\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 58.1145 - mae: 5.3377 - root_mean_squared_error: 7.6233 - val_loss: 108.4419 - val_mae: 6.9997 - val_root_mean_squared_error: 10.4135\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 57.9717 - mae: 5.2899 - root_mean_squared_error: 7.6139 - val_loss: 108.1799 - val_mae: 6.9798 - val_root_mean_squared_error: 10.4010\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 57.2224 - mae: 5.2785 - root_mean_squared_error: 7.5645 - val_loss: 106.8561 - val_mae: 6.9076 - val_root_mean_squared_error: 10.3371\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 56.3322 - mae: 5.2186 - root_mean_squared_error: 7.5055 - val_loss: 108.3085 - val_mae: 6.9771 - val_root_mean_squared_error: 10.4071\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 55.4677 - mae: 5.1648 - root_mean_squared_error: 7.4477 - val_loss: 108.6057 - val_mae: 7.0234 - val_root_mean_squared_error: 10.4214\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 54.7035 - mae: 5.1842 - root_mean_squared_error: 7.3962 - val_loss: 106.3463 - val_mae: 7.0967 - val_root_mean_squared_error: 10.3124\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 54.3194 - mae: 5.1390 - root_mean_squared_error: 7.3702 - val_loss: 106.0168 - val_mae: 6.8717 - val_root_mean_squared_error: 10.2964\n",
            "Epoch 46/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 53.1457 - mae: 5.0602 - root_mean_squared_error: 7.2901 - val_loss: 108.1761 - val_mae: 7.1922 - val_root_mean_squared_error: 10.4008\n",
            "Epoch 47/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 52.8720 - mae: 5.1298 - root_mean_squared_error: 7.2713 - val_loss: 106.8738 - val_mae: 6.9179 - val_root_mean_squared_error: 10.3380\n",
            "Epoch 48/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 52.1272 - mae: 5.0102 - root_mean_squared_error: 7.2199 - val_loss: 107.7696 - val_mae: 7.0569 - val_root_mean_squared_error: 10.3812\n",
            "Epoch 49/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 50.9327 - mae: 4.9810 - root_mean_squared_error: 7.1367 - val_loss: 105.2308 - val_mae: 6.9382 - val_root_mean_squared_error: 10.2582\n",
            "Epoch 50/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 50.2776 - mae: 4.9447 - root_mean_squared_error: 7.0907 - val_loss: 107.7070 - val_mae: 7.0724 - val_root_mean_squared_error: 10.3782\n",
            "Epoch 51/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 50.7066 - mae: 5.0171 - root_mean_squared_error: 7.1209 - val_loss: 109.3682 - val_mae: 7.0576 - val_root_mean_squared_error: 10.4579\n",
            "Epoch 52/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 49.2906 - mae: 4.8876 - root_mean_squared_error: 7.0207 - val_loss: 106.8109 - val_mae: 7.1192 - val_root_mean_squared_error: 10.3349\n",
            "Epoch 53/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 48.6482 - mae: 4.8621 - root_mean_squared_error: 6.9748 - val_loss: 107.5645 - val_mae: 7.0351 - val_root_mean_squared_error: 10.3713\n",
            "Epoch 54/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 48.3279 - mae: 4.8916 - root_mean_squared_error: 6.9518 - val_loss: 106.1530 - val_mae: 6.9950 - val_root_mean_squared_error: 10.3031\n",
            "Epoch 55/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 47.0919 - mae: 4.7695 - root_mean_squared_error: 6.8624 - val_loss: 104.4052 - val_mae: 6.9638 - val_root_mean_squared_error: 10.2179\n",
            "Epoch 56/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 46.5447 - mae: 4.7527 - root_mean_squared_error: 6.8224 - val_loss: 108.9893 - val_mae: 7.1980 - val_root_mean_squared_error: 10.4398\n",
            "Epoch 57/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 45.9600 - mae: 4.7617 - root_mean_squared_error: 6.7794 - val_loss: 106.3609 - val_mae: 7.0695 - val_root_mean_squared_error: 10.3131\n",
            "Epoch 58/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 44.5770 - mae: 4.6623 - root_mean_squared_error: 6.6766 - val_loss: 106.4073 - val_mae: 7.2380 - val_root_mean_squared_error: 10.3154\n",
            "Epoch 59/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 44.1238 - mae: 4.6732 - root_mean_squared_error: 6.6426 - val_loss: 105.0898 - val_mae: 6.9946 - val_root_mean_squared_error: 10.2513\n",
            "Epoch 60/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 43.7903 - mae: 4.6571 - root_mean_squared_error: 6.6174 - val_loss: 109.2319 - val_mae: 7.1031 - val_root_mean_squared_error: 10.4514\n",
            "Epoch 61/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 42.8397 - mae: 4.5674 - root_mean_squared_error: 6.5452 - val_loss: 107.9775 - val_mae: 7.1825 - val_root_mean_squared_error: 10.3912\n",
            "Epoch 62/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 42.1133 - mae: 4.5680 - root_mean_squared_error: 6.4895 - val_loss: 105.5884 - val_mae: 7.0859 - val_root_mean_squared_error: 10.2756\n",
            "Epoch 63/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 41.6406 - mae: 4.5533 - root_mean_squared_error: 6.4529 - val_loss: 103.8553 - val_mae: 6.9849 - val_root_mean_squared_error: 10.1909\n",
            "Epoch 64/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 40.7990 - mae: 4.5184 - root_mean_squared_error: 6.3874 - val_loss: 105.1618 - val_mae: 7.1283 - val_root_mean_squared_error: 10.2548\n",
            "Epoch 65/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 40.1517 - mae: 4.4801 - root_mean_squared_error: 6.3365 - val_loss: 108.4100 - val_mae: 7.1978 - val_root_mean_squared_error: 10.4120\n",
            "Epoch 66/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 39.5487 - mae: 4.4604 - root_mean_squared_error: 6.2888 - val_loss: 105.3705 - val_mae: 7.1099 - val_root_mean_squared_error: 10.2650\n",
            "Epoch 67/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 39.0612 - mae: 4.4168 - root_mean_squared_error: 6.2499 - val_loss: 104.2018 - val_mae: 7.1422 - val_root_mean_squared_error: 10.2079\n",
            "Epoch 68/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 38.3809 - mae: 4.4129 - root_mean_squared_error: 6.1952 - val_loss: 104.7264 - val_mae: 7.1228 - val_root_mean_squared_error: 10.2336\n",
            "Epoch 69/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 37.7412 - mae: 4.3328 - root_mean_squared_error: 6.1434 - val_loss: 108.7202 - val_mae: 7.2630 - val_root_mean_squared_error: 10.4269\n",
            "Epoch 70/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 37.7500 - mae: 4.3587 - root_mean_squared_error: 6.1441 - val_loss: 103.8793 - val_mae: 7.1453 - val_root_mean_squared_error: 10.1921\n",
            "Epoch 71/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 36.6956 - mae: 4.2848 - root_mean_squared_error: 6.0577 - val_loss: 104.1297 - val_mae: 7.1038 - val_root_mean_squared_error: 10.2044\n",
            "Epoch 72/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 36.2274 - mae: 4.2789 - root_mean_squared_error: 6.0189 - val_loss: 108.4329 - val_mae: 7.4297 - val_root_mean_squared_error: 10.4131\n",
            "Epoch 73/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 35.7687 - mae: 4.3163 - root_mean_squared_error: 5.9807 - val_loss: 108.2131 - val_mae: 7.2215 - val_root_mean_squared_error: 10.4026\n",
            "Epoch 74/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 34.7506 - mae: 4.2352 - root_mean_squared_error: 5.8950 - val_loss: 105.0383 - val_mae: 7.1925 - val_root_mean_squared_error: 10.2488\n",
            "Epoch 75/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 34.1999 - mae: 4.1653 - root_mean_squared_error: 5.8481 - val_loss: 103.4451 - val_mae: 7.1458 - val_root_mean_squared_error: 10.1708\n",
            "Epoch 76/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 33.7723 - mae: 4.1070 - root_mean_squared_error: 5.8114 - val_loss: 107.9671 - val_mae: 7.3337 - val_root_mean_squared_error: 10.3907\n",
            "Epoch 77/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 33.2562 - mae: 4.1381 - root_mean_squared_error: 5.7668 - val_loss: 108.5478 - val_mae: 7.2919 - val_root_mean_squared_error: 10.4186\n",
            "Epoch 78/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 32.5230 - mae: 4.1057 - root_mean_squared_error: 5.7029 - val_loss: 107.2723 - val_mae: 7.2640 - val_root_mean_squared_error: 10.3572\n",
            "Epoch 79/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 32.4474 - mae: 4.0702 - root_mean_squared_error: 5.6963 - val_loss: 103.8543 - val_mae: 7.2382 - val_root_mean_squared_error: 10.1909\n",
            "Epoch 80/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 31.7895 - mae: 4.0763 - root_mean_squared_error: 5.6382 - val_loss: 109.5616 - val_mae: 7.3489 - val_root_mean_squared_error: 10.4672\n",
            "Epoch 81/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 31.0460 - mae: 3.9785 - root_mean_squared_error: 5.5719 - val_loss: 105.2174 - val_mae: 7.1992 - val_root_mean_squared_error: 10.2576\n",
            "Epoch 82/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 31.0796 - mae: 4.0355 - root_mean_squared_error: 5.5749 - val_loss: 104.3779 - val_mae: 7.2141 - val_root_mean_squared_error: 10.2165\n",
            "Epoch 83/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 30.4798 - mae: 3.9557 - root_mean_squared_error: 5.5209 - val_loss: 106.1543 - val_mae: 7.3443 - val_root_mean_squared_error: 10.3031\n",
            "Epoch 84/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 29.8457 - mae: 3.9216 - root_mean_squared_error: 5.4631 - val_loss: 108.5229 - val_mae: 7.4694 - val_root_mean_squared_error: 10.4174\n",
            "Epoch 85/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 29.6041 - mae: 3.9395 - root_mean_squared_error: 5.4410 - val_loss: 111.4679 - val_mae: 7.4141 - val_root_mean_squared_error: 10.5578\n",
            "Epoch 86/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 29.1958 - mae: 3.8874 - root_mean_squared_error: 5.4033 - val_loss: 109.6139 - val_mae: 7.4235 - val_root_mean_squared_error: 10.4697\n",
            "Epoch 87/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 28.5162 - mae: 3.8957 - root_mean_squared_error: 5.3401 - val_loss: 106.8886 - val_mae: 7.2677 - val_root_mean_squared_error: 10.3387\n",
            "Epoch 88/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 28.6616 - mae: 3.8449 - root_mean_squared_error: 5.3537 - val_loss: 106.5225 - val_mae: 7.3808 - val_root_mean_squared_error: 10.3210\n",
            "Epoch 89/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 28.2435 - mae: 3.8452 - root_mean_squared_error: 5.3145 - val_loss: 107.0140 - val_mae: 7.3697 - val_root_mean_squared_error: 10.3448\n",
            "Epoch 90/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 27.1418 - mae: 3.7563 - root_mean_squared_error: 5.2098 - val_loss: 107.8394 - val_mae: 7.4372 - val_root_mean_squared_error: 10.3846\n",
            "Epoch 91/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 27.1613 - mae: 3.8018 - root_mean_squared_error: 5.2117 - val_loss: 108.4565 - val_mae: 7.4475 - val_root_mean_squared_error: 10.4142\n",
            "Epoch 92/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 26.8203 - mae: 3.7759 - root_mean_squared_error: 5.1788 - val_loss: 109.3375 - val_mae: 7.3570 - val_root_mean_squared_error: 10.4565\n",
            "Epoch 93/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 26.4232 - mae: 3.7390 - root_mean_squared_error: 5.1404 - val_loss: 102.8609 - val_mae: 7.2644 - val_root_mean_squared_error: 10.1420\n",
            "Epoch 94/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 26.0445 - mae: 3.7122 - root_mean_squared_error: 5.1034 - val_loss: 106.8688 - val_mae: 7.4255 - val_root_mean_squared_error: 10.3377\n",
            "Epoch 95/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 25.6391 - mae: 3.6986 - root_mean_squared_error: 5.0635 - val_loss: 107.4740 - val_mae: 7.3821 - val_root_mean_squared_error: 10.3670\n",
            "Epoch 96/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 25.7044 - mae: 3.7040 - root_mean_squared_error: 5.0700 - val_loss: 104.4487 - val_mae: 7.3594 - val_root_mean_squared_error: 10.2200\n",
            "Epoch 97/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 24.8506 - mae: 3.6664 - root_mean_squared_error: 4.9850 - val_loss: 108.1225 - val_mae: 7.4005 - val_root_mean_squared_error: 10.3982\n",
            "Epoch 98/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 24.6495 - mae: 3.6115 - root_mean_squared_error: 4.9648 - val_loss: 108.0676 - val_mae: 7.4279 - val_root_mean_squared_error: 10.3956\n",
            "Epoch 99/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 24.2863 - mae: 3.5982 - root_mean_squared_error: 4.9281 - val_loss: 106.8483 - val_mae: 7.4371 - val_root_mean_squared_error: 10.3367\n",
            "Epoch 100/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 23.5696 - mae: 3.5072 - root_mean_squared_error: 4.8549 - val_loss: 107.2575 - val_mae: 7.3912 - val_root_mean_squared_error: 10.3565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "# Load the test data\n",
        "test_data = pd.read_csv('/content/test.csv')\n",
        "\n",
        "# Perform one-hot encoding on categorical features (if needed)\n",
        "# Assuming 'categorical_cols' contains the names of categorical columns\n",
        "catogrical_data=[\"gender\",\"location\",\"residence\"]\n",
        "test_encoded = pd.get_dummies(df,columns=catogrical_data)\n",
        "test_encoded.head()\n"
      ],
      "metadata": {
        "id": "sHGimkiyjc9p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "be7e4103-c404-4746-c71c-9e8ad4827345"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  competative_exams  access_to_internet  study_hours_per_day  \\\n",
              "0   11                  0                   0                    4   \n",
              "1   14                  0                   1                    1   \n",
              "2   21                  1                   1                    6   \n",
              "3   24                  1                   0                    7   \n",
              "4   12                  0                   0                    5   \n",
              "\n",
              "   has_scholarship  extracurricular_activities  fam_fin_status  health  f_edu  \\\n",
              "0                0                           1               3       5      4   \n",
              "1                1                           0               4       2      5   \n",
              "2                0                           1               5       3      3   \n",
              "3                0                           0               4       2      2   \n",
              "4                1                           0               3       1      3   \n",
              "\n",
              "   m_edu  ...  prev_percent_1  prev_percent_2  prev_percent_3  \\\n",
              "0      5  ...              73              73              67   \n",
              "1      0  ...              96              87              80   \n",
              "2      4  ...              81              78              93   \n",
              "3      1  ...              77              71              88   \n",
              "4      3  ...              66              78              85   \n",
              "\n",
              "   TARGET_PREDICTION_PERCENT  gender_F  gender_M  location_R  location_U  \\\n",
              "0                         71     False      True        True       False   \n",
              "1                         87      True     False       False        True   \n",
              "2                         84     False      True       False        True   \n",
              "3                         78      True     False       False        True   \n",
              "4                         76      True     False        True       False   \n",
              "\n",
              "   residence_D  residence_H  \n",
              "0        False         True  \n",
              "1         True        False  \n",
              "2        False         True  \n",
              "3        False         True  \n",
              "4        False         True  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2995da98-a90d-4d64-bede-da1d8ed68d55\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>competative_exams</th>\n",
              "      <th>access_to_internet</th>\n",
              "      <th>study_hours_per_day</th>\n",
              "      <th>has_scholarship</th>\n",
              "      <th>extracurricular_activities</th>\n",
              "      <th>fam_fin_status</th>\n",
              "      <th>health</th>\n",
              "      <th>f_edu</th>\n",
              "      <th>m_edu</th>\n",
              "      <th>...</th>\n",
              "      <th>prev_percent_1</th>\n",
              "      <th>prev_percent_2</th>\n",
              "      <th>prev_percent_3</th>\n",
              "      <th>TARGET_PREDICTION_PERCENT</th>\n",
              "      <th>gender_F</th>\n",
              "      <th>gender_M</th>\n",
              "      <th>location_R</th>\n",
              "      <th>location_U</th>\n",
              "      <th>residence_D</th>\n",
              "      <th>residence_H</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>73</td>\n",
              "      <td>73</td>\n",
              "      <td>67</td>\n",
              "      <td>71</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>96</td>\n",
              "      <td>87</td>\n",
              "      <td>80</td>\n",
              "      <td>87</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>81</td>\n",
              "      <td>78</td>\n",
              "      <td>93</td>\n",
              "      <td>84</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>77</td>\n",
              "      <td>71</td>\n",
              "      <td>88</td>\n",
              "      <td>78</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>66</td>\n",
              "      <td>78</td>\n",
              "      <td>85</td>\n",
              "      <td>76</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 26 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2995da98-a90d-4d64-bede-da1d8ed68d55')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2995da98-a90d-4d64-bede-da1d8ed68d55 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2995da98-a90d-4d64-bede-da1d8ed68d55');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bda51938-088a-4236-b69a-056c7ef52496\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bda51938-088a-4236-b69a-056c7ef52496')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bda51938-088a-4236-b69a-056c7ef52496 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_encoded"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_encoded.columns"
      ],
      "metadata": {
        "id": "6hJPPLIwkGwN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "963066dd-c8b5-4673-a104-f17b025b4b81"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'competative_exams', 'access_to_internet', 'study_hours_per_day',\n",
              "       'has_scholarship', 'extracurricular_activities', 'fam_fin_status',\n",
              "       'health', 'f_edu', 'm_edu', 'f_job', 'm_job', 'alcoholic',\n",
              "       'additional_tuition', 'fam_size', 'fam_relation', 'prev_percent_1',\n",
              "       'prev_percent_2', 'prev_percent_3', 'TARGET_PREDICTION_PERCENT',\n",
              "       'gender_F', 'gender_M', 'location_R', 'location_U', 'residence_D',\n",
              "       'residence_H'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = test_encoded.drop(columns=['TARGET_PREDICTION_PERCENT'])"
      ],
      "metadata": {
        "id": "w58pkfCd4YQS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y= test_encoded['TARGET_PREDICTION_PERCENT']"
      ],
      "metadata": {
        "id": "2xknKTjK2sGK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "scaler = StandardScaler()\n",
        "X_test = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "KYP2Yn-I4Hwp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boJlPUV6fw5t",
        "outputId": "947d615c-eb61-42c7-9e92-34acba3c71d1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-2.8939147  -0.90138782 -1.99636473 -0.07292276 -0.81606404  0.4470694\n",
            "  -0.25479701  1.07945912  0.5286302   1.53087524 -1.77752523 -0.81682708\n",
            "  -0.92356392  1.07323664  5.50827611  0.11439027 -0.39067264 -0.39229041\n",
            "  -0.79670901 -0.96985672  0.96985672  1.24810415 -1.24810415 -1.11158151\n",
            "   1.11158151]\n",
            " [-1.96409878 -0.90138782  0.50091047 -1.22495319  1.09117303 -1.0328597\n",
            "   0.58595145 -1.54463336  1.28188251 -2.04858436  0.56257992 -0.81682708\n",
            "  -0.92356392 -0.83011758 -1.93668585 -1.56796379  1.2544531   0.59895813\n",
            "   0.1768363   1.03108014 -1.03108014 -0.80121519  0.80121519  0.89961913\n",
            "  -0.89961913]\n",
            " [ 0.20547171  1.10940039  0.50091047  0.69509752 -0.81606404  0.4470694\n",
            "   1.4266999  -0.66993587 -0.22462211  0.81498332  0.56257992  1.22424932\n",
            "  -0.10671765 -0.83011758  6.08096549 -1.56796379  0.18154501 -0.03827307\n",
            "   1.15038161 -0.96985672  0.96985672 -0.80121519  0.80121519 -1.11158151\n",
            "   1.11158151]\n",
            " [ 1.13528763  1.10940039 -1.99636473  1.07910766 -0.81606404 -1.0328597\n",
            "   0.58595145 -1.54463336 -0.97787442 -1.33269244  0.56257992  1.22424932\n",
            "  -0.10671765  1.07323664  6.08096549  0.11439027 -0.10456381 -0.53389735\n",
            "   0.77594111  1.03108014 -1.03108014 -0.80121519  0.80121519 -1.11158151\n",
            "   1.11158151]\n",
            " [-2.58397606 -0.90138782 -1.99636473  0.31108738  1.09117303 -1.0328597\n",
            "  -0.25479701 -2.41933085 -0.22462211  0.0990914   0.56257992 -0.81682708\n",
            "  -0.92356392  1.07323664  4.93558672 -0.72678676 -0.89136308 -0.03827307\n",
            "   0.55127681  1.03108014 -1.03108014  1.24810415 -1.24810415 -1.11158151\n",
            "   1.11158151]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "import numpy as np\n",
        "# Assuming you have a trained model named 'model'\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "print(y_pred)\n",
        "# for pred in y_pred.flatten():\n",
        "#     print(pred)\n",
        "\n"
      ],
      "metadata": {
        "id": "HavB-APrf2Wu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71bd4354-dfb8-4ec3-e531-5f26686c0b3b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 1ms/step\n",
            "[[ 86.59794 ]\n",
            " [ 96.08146 ]\n",
            " [ 88.0879  ]\n",
            " [ 87.1211  ]\n",
            " [101.69221 ]\n",
            " [ 79.782616]\n",
            " [ 66.67852 ]\n",
            " [ 92.169205]\n",
            " [ 84.915215]\n",
            " [ 81.01066 ]\n",
            " [ 71.84196 ]\n",
            " [ 95.48283 ]\n",
            " [ 85.06992 ]\n",
            " [ 75.84493 ]\n",
            " [ 99.175705]\n",
            " [ 84.87718 ]\n",
            " [ 84.199554]\n",
            " [ 84.64648 ]\n",
            " [ 74.85198 ]\n",
            " [ 70.000404]\n",
            " [ 83.084076]\n",
            " [ 81.12328 ]\n",
            " [ 83.35584 ]\n",
            " [ 74.31623 ]\n",
            " [ 86.178734]\n",
            " [ 85.88779 ]\n",
            " [ 82.73019 ]\n",
            " [ 91.36835 ]\n",
            " [ 83.08813 ]\n",
            " [ 85.813835]\n",
            " [ 70.40018 ]\n",
            " [ 88.23079 ]\n",
            " [ 73.12693 ]\n",
            " [ 86.76755 ]\n",
            " [ 73.89675 ]\n",
            " [ 22.862856]\n",
            " [ 98.91516 ]\n",
            " [ 90.13146 ]\n",
            " [ 72.95935 ]\n",
            " [ 74.66008 ]\n",
            " [ 75.93702 ]\n",
            " [ 92.73166 ]\n",
            " [ 67.359184]\n",
            " [ 72.59081 ]\n",
            " [ 89.70062 ]\n",
            " [ 94.95916 ]\n",
            " [ 79.490944]\n",
            " [ 89.56992 ]\n",
            " [ 81.59376 ]\n",
            " [ 89.1777  ]\n",
            " [ 83.20272 ]\n",
            " [ 90.12351 ]\n",
            " [ 87.79202 ]\n",
            " [ 72.67707 ]\n",
            " [ 71.58201 ]\n",
            " [105.698784]\n",
            " [ 91.774864]\n",
            " [ 87.66944 ]\n",
            " [ 67.868965]\n",
            " [ 61.66084 ]\n",
            " [ 90.70519 ]\n",
            " [ 80.24038 ]\n",
            " [ 71.38734 ]\n",
            " [ 52.75215 ]\n",
            " [ 90.093666]\n",
            " [ 83.51716 ]\n",
            " [ 78.017525]\n",
            " [ 74.75761 ]\n",
            " [ 88.90029 ]\n",
            " [ 76.36825 ]\n",
            " [ 82.19692 ]\n",
            " [ 89.309326]\n",
            " [ 84.06286 ]\n",
            " [ 86.7129  ]\n",
            " [ 79.11997 ]\n",
            " [ 88.4992  ]\n",
            " [ 73.0905  ]\n",
            " [ 87.35006 ]\n",
            " [ 82.8492  ]\n",
            " [ 89.61837 ]\n",
            " [ 75.08632 ]\n",
            " [ 78.14211 ]\n",
            " [ 87.410866]\n",
            " [ 91.79935 ]\n",
            " [ 63.161488]\n",
            " [ 90.541435]\n",
            " [ 83.25678 ]\n",
            " [ 97.61662 ]\n",
            " [ 75.43574 ]\n",
            " [ 84.612564]\n",
            " [ 87.276695]\n",
            " [ 77.72263 ]\n",
            " [ 90.01876 ]\n",
            " [ 65.117065]\n",
            " [ 77.648766]\n",
            " [ 59.49561 ]\n",
            " [ 71.840744]\n",
            " [ 78.60038 ]\n",
            " [ 89.30572 ]\n",
            " [ 88.33109 ]\n",
            " [ 83.43902 ]\n",
            " [102.65824 ]\n",
            " [ 81.407616]\n",
            " [ 97.24947 ]\n",
            " [ 73.76952 ]\n",
            " [ 84.34705 ]\n",
            " [ 81.103004]\n",
            " [ 90.17422 ]\n",
            " [ 86.645164]\n",
            " [ 54.530228]\n",
            " [ 65.873085]\n",
            " [ 33.756886]\n",
            " [ 73.28575 ]\n",
            " [ 86.66747 ]\n",
            " [ 93.15609 ]\n",
            " [ 63.638206]\n",
            " [ 70.930855]\n",
            " [ 73.26713 ]\n",
            " [ 74.42855 ]\n",
            " [ 83.52177 ]\n",
            " [ 87.440575]\n",
            " [ 88.936676]\n",
            " [ 77.049736]\n",
            " [ 90.52172 ]\n",
            " [ 68.18047 ]\n",
            " [ 85.44474 ]\n",
            " [ 81.371956]\n",
            " [ 81.58439 ]\n",
            " [ 90.09522 ]\n",
            " [ 91.77088 ]\n",
            " [ 94.26264 ]\n",
            " [103.41284 ]\n",
            " [ 78.85977 ]\n",
            " [ 65.38317 ]\n",
            " [103.08031 ]\n",
            " [ 84.34174 ]\n",
            " [ 60.111412]\n",
            " [ 59.70027 ]\n",
            " [ 95.238686]\n",
            " [ 83.13064 ]\n",
            " [ 77.690414]\n",
            " [ 78.05552 ]\n",
            " [ 86.42247 ]\n",
            " [ 83.20486 ]\n",
            " [ 86.52865 ]\n",
            " [ 78.81625 ]\n",
            " [ 84.10395 ]\n",
            " [ 76.77426 ]\n",
            " [ 92.480705]\n",
            " [ 90.77194 ]\n",
            " [ 65.589066]\n",
            " [ 92.57717 ]\n",
            " [ 70.3814  ]\n",
            " [ 96.2702  ]\n",
            " [ 92.480705]\n",
            " [ 83.001915]\n",
            " [ 88.76363 ]\n",
            " [ 79.94973 ]\n",
            " [ 76.12534 ]\n",
            " [ 74.72001 ]\n",
            " [ 75.772354]\n",
            " [ 83.47799 ]\n",
            " [ 86.59831 ]\n",
            " [ 82.79029 ]\n",
            " [ 70.71236 ]\n",
            " [ 77.42092 ]\n",
            " [ 81.73933 ]\n",
            " [ 68.84228 ]\n",
            " [ 90.95526 ]\n",
            " [ 94.44552 ]\n",
            " [ 77.05149 ]\n",
            " [ 93.323326]\n",
            " [ 87.94694 ]\n",
            " [ 87.82531 ]\n",
            " [ 69.808815]\n",
            " [ 83.01078 ]\n",
            " [ 86.10291 ]\n",
            " [ 72.59429 ]\n",
            " [ 81.81839 ]\n",
            " [ 92.163765]\n",
            " [ 90.57811 ]\n",
            " [ 75.61955 ]\n",
            " [ 82.81855 ]\n",
            " [ 88.50666 ]\n",
            " [ 65.40313 ]\n",
            " [ 67.0629  ]\n",
            " [ 94.04801 ]\n",
            " [ 84.05993 ]\n",
            " [ 81.078964]\n",
            " [ 80.24785 ]\n",
            " [ 90.37174 ]\n",
            " [ 80.456604]\n",
            " [ 90.42517 ]\n",
            " [ 77.54809 ]\n",
            " [ 96.65887 ]\n",
            " [ 71.72729 ]\n",
            " [ 69.92419 ]\n",
            " [ 95.5312  ]\n",
            " [ 88.02931 ]\n",
            " [ 80.587074]\n",
            " [ 80.50009 ]\n",
            " [ 88.02787 ]\n",
            " [ 90.765144]\n",
            " [ 90.78894 ]\n",
            " [ 92.00342 ]\n",
            " [ 83.757355]\n",
            " [ 90.02036 ]\n",
            " [ 80.17185 ]\n",
            " [ 87.6518  ]\n",
            " [ 67.17237 ]\n",
            " [102.65569 ]\n",
            " [ 82.68421 ]\n",
            " [ 84.40087 ]\n",
            " [ 88.84548 ]\n",
            " [ 67.53096 ]\n",
            " [ 80.872185]\n",
            " [ 80.04893 ]\n",
            " [ 81.50969 ]\n",
            " [ 85.98562 ]\n",
            " [ 83.11924 ]\n",
            " [ 77.57615 ]\n",
            " [ 86.20818 ]\n",
            " [ 78.43597 ]\n",
            " [ 63.783863]\n",
            " [ 87.179375]\n",
            " [ 81.225235]\n",
            " [ 80.09264 ]\n",
            " [ 74.22308 ]\n",
            " [ 86.356125]\n",
            " [ 78.41079 ]\n",
            " [ 79.16444 ]\n",
            " [ 73.28353 ]\n",
            " [ 72.62917 ]\n",
            " [ 81.55683 ]\n",
            " [ 78.20583 ]\n",
            " [ 85.2033  ]\n",
            " [ 93.41299 ]\n",
            " [ 54.99889 ]\n",
            " [ 78.89621 ]\n",
            " [ 79.697716]\n",
            " [ 71.7047  ]\n",
            " [ 83.9865  ]\n",
            " [ 77.50924 ]\n",
            " [ 93.631874]\n",
            " [ 71.51406 ]\n",
            " [ 74.40183 ]\n",
            " [ 83.74543 ]\n",
            " [ 95.3327  ]\n",
            " [ 74.798035]\n",
            " [ 67.03888 ]\n",
            " [ 89.30508 ]\n",
            " [ 87.01728 ]\n",
            " [ 88.271614]\n",
            " [ 82.63328 ]\n",
            " [ 96.808815]\n",
            " [ 76.92716 ]\n",
            " [ 81.195915]\n",
            " [ 62.034176]\n",
            " [ 90.515144]\n",
            " [ 73.419495]\n",
            " [ 75.15685 ]\n",
            " [ 44.993084]\n",
            " [ 81.10459 ]\n",
            " [ 56.106487]\n",
            " [ 84.76872 ]\n",
            " [ 72.29777 ]\n",
            " [ 85.9124  ]\n",
            " [ 87.19152 ]\n",
            " [ 72.444374]\n",
            " [ 93.98688 ]\n",
            " [ 81.15539 ]\n",
            " [ 74.691216]\n",
            " [ 80.54682 ]\n",
            " [ 69.143394]\n",
            " [ 59.313953]\n",
            " [ 71.12058 ]\n",
            " [ 85.10914 ]\n",
            " [ 82.77466 ]\n",
            " [ 63.041744]\n",
            " [ 92.2963  ]\n",
            " [ 44.96944 ]\n",
            " [ 67.389534]\n",
            " [ 79.934395]\n",
            " [ 85.44397 ]\n",
            " [ 81.873085]\n",
            " [ 67.40812 ]\n",
            " [ 78.05852 ]\n",
            " [ 88.50098 ]\n",
            " [ 86.108376]\n",
            " [ 77.07412 ]\n",
            " [ 75.91591 ]\n",
            " [ 90.28428 ]\n",
            " [ 84.55819 ]\n",
            " [ 71.11794 ]\n",
            " [ 95.42041 ]\n",
            " [ 69.891556]\n",
            " [ 85.11355 ]\n",
            " [ 94.09823 ]\n",
            " [ 76.82737 ]\n",
            " [ 86.39294 ]\n",
            " [ 67.48852 ]\n",
            " [ 61.904682]\n",
            " [ 51.58785 ]\n",
            " [ 75.69515 ]\n",
            " [ 83.32619 ]\n",
            " [ 87.772385]\n",
            " [ 86.78238 ]\n",
            " [ 66.436615]\n",
            " [ 90.42517 ]\n",
            " [ 82.467705]\n",
            " [ 82.40255 ]\n",
            " [ 69.44858 ]\n",
            " [ 84.73091 ]\n",
            " [ 66.195984]\n",
            " [ 73.89272 ]\n",
            " [ 87.17748 ]\n",
            " [ 92.08622 ]\n",
            " [ 78.18753 ]\n",
            " [ 87.75354 ]\n",
            " [ 88.74208 ]\n",
            " [ 83.901085]\n",
            " [ 76.85856 ]\n",
            " [ 96.66612 ]\n",
            " [ 92.30077 ]\n",
            " [ 67.52998 ]\n",
            " [ 58.371998]\n",
            " [ 86.91965 ]\n",
            " [ 86.579025]\n",
            " [ 76.18389 ]\n",
            " [ 87.24643 ]\n",
            " [ 82.775375]\n",
            " [ 71.97752 ]\n",
            " [ 83.03792 ]\n",
            " [ 85.99578 ]\n",
            " [ 89.17653 ]\n",
            " [ 89.97236 ]\n",
            " [ 64.4366  ]\n",
            " [ 92.47229 ]\n",
            " [ 57.574898]\n",
            " [ 85.63877 ]\n",
            " [ 67.4032  ]\n",
            " [ 59.735817]\n",
            " [ 86.68883 ]\n",
            " [ 80.96357 ]\n",
            " [ 88.81392 ]\n",
            " [ 80.44178 ]\n",
            " [ 69.22379 ]\n",
            " [ 89.18934 ]\n",
            " [ 80.628365]\n",
            " [ 74.70439 ]\n",
            " [ 72.209984]\n",
            " [ 78.53936 ]\n",
            " [ 72.64773 ]\n",
            " [ 87.22639 ]\n",
            " [ 82.86297 ]\n",
            " [ 73.27623 ]\n",
            " [ 91.94808 ]\n",
            " [ 67.90431 ]\n",
            " [ 73.48492 ]\n",
            " [ 73.61164 ]\n",
            " [ 80.036   ]\n",
            " [ 78.20583 ]\n",
            " [ 81.61025 ]\n",
            " [ 79.57598 ]\n",
            " [ 77.08013 ]\n",
            " [101.4882  ]\n",
            " [101.176994]\n",
            " [ 94.15118 ]\n",
            " [ 89.3077  ]\n",
            " [ 97.3697  ]\n",
            " [ 69.0985  ]\n",
            " [106.36488 ]\n",
            " [ 78.27097 ]\n",
            " [ 75.73528 ]\n",
            " [ 71.67859 ]\n",
            " [ 60.258045]\n",
            " [ 83.55981 ]\n",
            " [ 97.60899 ]\n",
            " [ 82.051445]\n",
            " [ 74.38368 ]\n",
            " [ 82.65128 ]\n",
            " [ 92.73166 ]\n",
            " [ 73.565575]\n",
            " [ 76.80462 ]\n",
            " [ 57.04826 ]\n",
            " [ 88.974434]\n",
            " [ 67.90721 ]\n",
            " [ 82.41133 ]\n",
            " [ 67.19499 ]\n",
            " [ 77.9403  ]\n",
            " [ 76.038506]\n",
            " [ 99.59117 ]\n",
            " [ 85.86194 ]\n",
            " [ 85.73038 ]\n",
            " [ 74.64956 ]\n",
            " [ 90.53881 ]\n",
            " [ 82.85021 ]\n",
            " [ 88.47258 ]\n",
            " [ 81.26371 ]\n",
            " [ 85.669426]\n",
            " [ 69.275246]\n",
            " [ 83.7985  ]\n",
            " [ 74.60375 ]\n",
            " [ 70.766525]\n",
            " [ 74.09062 ]\n",
            " [ 38.006573]\n",
            " [ 94.66879 ]\n",
            " [ 98.65653 ]\n",
            " [ 69.223564]\n",
            " [ 93.03614 ]\n",
            " [ 79.43877 ]\n",
            " [ 84.152   ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdYT6JSr89Ze",
        "outputId": "39ed213f-11a6-4ca2-ac86-e68c65b0967a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 107.25749117454922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Assuming y_test and y_pred are your actual and predicted values\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Root Mean Squared Error:\", rmse)"
      ],
      "metadata": {
        "id": "dOXnOvXVAXeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28f91e6c-8181-4287-ff52-e6660f809a60"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error: 10.356519259604031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Type of y_test: {type(y_test)}\")\n",
        "print(f\"Type of y_pred: {type(y_pred)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifePPGW2HTCe",
        "outputId": "d2a4934d-2dcd-48bd-f6a8-2972fea7416a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of y_test: <class 'pandas.core.series.Series'>\n",
            "Type of y_pred: <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of y_pred: {y_pred.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc_5LjgIHZTx",
        "outputId": "44671a7f-dd2d-46ff-de16-867d1eb78fe3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_pred: (412,)\n",
            "Shape of y_test: (412,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Define a function to create a model with given parameters\n",
        "def create_model(learning_rate=0.001, optimizer='adam', dropout_rate=0.0):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "    if dropout_rate > 0:\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    if dropout_rate > 0:\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    if dropout_rate > 0:\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "\n",
        "\n",
        "    model.compile(optimizer=opt, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return model\n",
        "\n",
        "# Define parameters to experiment with\n",
        "learning_rates = [0.0001, 0.001, 0.01]\n",
        "\n",
        "dropout_rates = [0.0, 0.2, 0.5]\n",
        "epoch_list = [50, 100, 150]\n",
        "\n",
        "# Use early stopping to avoid overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train and evaluate the model with different combinations of parameters\n",
        "best_rmse = float('inf')\n",
        "best_params = {}\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for opt in optimizers:\n",
        "        for dr in dropout_rates:\n",
        "            for epochs in epoch_list:\n",
        "                print(f'Training with learning rate={lr}, optimizer={opt}, dropout_rate={dr}, epochs={epochs}')\n",
        "                model = create_model(learning_rate=lr, optimizer=opt, dropout_rate=dr)\n",
        "                history = model.fit(X_train_scaled, y_train,\n",
        "                                    validation_data=(X_test_scaled, y_test),\n",
        "                                    epochs=epochs, batch_size=10, verbose=1,\n",
        "                                    callbacks=[early_stopping])\n",
        "\n",
        "                # Evaluate the model\n",
        "                y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "                # Check for NaN values in predictions\n",
        "                if np.isnan(y_pred).any():\n",
        "                    print(f'NaN values found in predictions with learning rate={lr}, optimizer={opt}, dropout_rate={dr}, epochs={epochs}')\n",
        "                    continue\n",
        "\n",
        "                mse = mean_squared_error(y_test, y_pred)\n",
        "                rmse = np.sqrt(mse)\n",
        "                print(f'RMSE: {rmse}\\n')\n",
        "\n",
        "                # Track the best parameters\n",
        "                if rmse < best_rmse:\n",
        "                    best_rmse = rmse\n",
        "                    best_params = {'learning_rate': lr, 'optimizer': opt, 'dropout_rate': dr, 'epochs': epochs}\n",
        "\n",
        "print(f'Best RMSE: {best_rmse} with parameters: {best_params}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CRsFzFeIkbE",
        "outputId": "88ef7cc5-0f5c-40c8-e14b-b9b2e2175c8b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with learning rate=0.0001, optimizer=adam, dropout_rate=0.0, epochs=50\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 2s 5ms/step - loss: 2278.9500 - mean_squared_error: 2278.9500 - val_loss: 201.7406 - val_mean_squared_error: 201.7406\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 145.7348 - mean_squared_error: 145.7348 - val_loss: 172.2114 - val_mean_squared_error: 172.2114\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 118.8765 - mean_squared_error: 118.8765 - val_loss: 142.2910 - val_mean_squared_error: 142.2910\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 102.7014 - mean_squared_error: 102.7014 - val_loss: 136.4175 - val_mean_squared_error: 136.4175\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 95.8306 - mean_squared_error: 95.8306 - val_loss: 129.2094 - val_mean_squared_error: 129.2094\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 89.1644 - mean_squared_error: 89.1644 - val_loss: 125.3652 - val_mean_squared_error: 125.3652\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 85.8310 - mean_squared_error: 85.8310 - val_loss: 120.1228 - val_mean_squared_error: 120.1228\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 82.1728 - mean_squared_error: 82.1728 - val_loss: 119.8767 - val_mean_squared_error: 119.8767\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 78.9881 - mean_squared_error: 78.9881 - val_loss: 120.3377 - val_mean_squared_error: 120.3377\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 75.7736 - mean_squared_error: 75.7736 - val_loss: 119.1702 - val_mean_squared_error: 119.1702\n",
            "Epoch 11/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 78.2695 - mean_squared_error: 78.2695 - val_loss: 118.3365 - val_mean_squared_error: 118.3365\n",
            "Epoch 12/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 74.3915 - mean_squared_error: 74.3915 - val_loss: 115.9950 - val_mean_squared_error: 115.9950\n",
            "Epoch 13/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 72.1880 - mean_squared_error: 72.1880 - val_loss: 111.6973 - val_mean_squared_error: 111.6973\n",
            "Epoch 14/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 70.8507 - mean_squared_error: 70.8507 - val_loss: 115.2158 - val_mean_squared_error: 115.2158\n",
            "Epoch 15/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 69.0718 - mean_squared_error: 69.0718 - val_loss: 113.2506 - val_mean_squared_error: 113.2506\n",
            "Epoch 16/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 68.6029 - mean_squared_error: 68.6029 - val_loss: 113.5622 - val_mean_squared_error: 113.5622\n",
            "Epoch 17/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 67.4419 - mean_squared_error: 67.4419 - val_loss: 111.4270 - val_mean_squared_error: 111.4270\n",
            "Epoch 18/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 63.5751 - mean_squared_error: 63.5751 - val_loss: 106.2749 - val_mean_squared_error: 106.2749\n",
            "Epoch 19/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 63.0574 - mean_squared_error: 63.0574 - val_loss: 109.6125 - val_mean_squared_error: 109.6125\n",
            "Epoch 20/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 61.2399 - mean_squared_error: 61.2399 - val_loss: 107.8969 - val_mean_squared_error: 107.8969\n",
            "Epoch 21/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 59.7505 - mean_squared_error: 59.7505 - val_loss: 105.7744 - val_mean_squared_error: 105.7744\n",
            "Epoch 22/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 60.9071 - mean_squared_error: 60.9071 - val_loss: 111.8153 - val_mean_squared_error: 111.8153\n",
            "Epoch 23/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 56.9108 - mean_squared_error: 56.9108 - val_loss: 106.3021 - val_mean_squared_error: 106.3021\n",
            "Epoch 24/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 56.7771 - mean_squared_error: 56.7771 - val_loss: 103.2612 - val_mean_squared_error: 103.2612\n",
            "Epoch 25/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 53.7960 - mean_squared_error: 53.7960 - val_loss: 102.7078 - val_mean_squared_error: 102.7078\n",
            "Epoch 26/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 51.1462 - mean_squared_error: 51.1462 - val_loss: 98.4039 - val_mean_squared_error: 98.4039\n",
            "Epoch 27/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 49.8183 - mean_squared_error: 49.8183 - val_loss: 99.8091 - val_mean_squared_error: 99.8091\n",
            "Epoch 28/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 48.7331 - mean_squared_error: 48.7331 - val_loss: 100.3040 - val_mean_squared_error: 100.3040\n",
            "Epoch 29/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 45.6980 - mean_squared_error: 45.6980 - val_loss: 113.8151 - val_mean_squared_error: 113.8151\n",
            "Epoch 30/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 43.9102 - mean_squared_error: 43.9102 - val_loss: 95.2638 - val_mean_squared_error: 95.2638\n",
            "Epoch 31/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 43.3484 - mean_squared_error: 43.3484 - val_loss: 94.7690 - val_mean_squared_error: 94.7690\n",
            "Epoch 32/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 41.7592 - mean_squared_error: 41.7592 - val_loss: 94.3238 - val_mean_squared_error: 94.3238\n",
            "Epoch 33/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 39.3736 - mean_squared_error: 39.3736 - val_loss: 99.1425 - val_mean_squared_error: 99.1425\n",
            "Epoch 34/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 37.9439 - mean_squared_error: 37.9439 - val_loss: 102.3484 - val_mean_squared_error: 102.3484\n",
            "Epoch 35/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 37.5231 - mean_squared_error: 37.5231 - val_loss: 105.2015 - val_mean_squared_error: 105.2015\n",
            "Epoch 36/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 35.8321 - mean_squared_error: 35.8321 - val_loss: 99.9610 - val_mean_squared_error: 99.9610\n",
            "Epoch 37/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 33.1360 - mean_squared_error: 33.1360 - val_loss: 97.1731 - val_mean_squared_error: 97.1731\n",
            "Epoch 38/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 32.6454 - mean_squared_error: 32.6454 - val_loss: 102.0841 - val_mean_squared_error: 102.0841\n",
            "Epoch 39/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 32.2547 - mean_squared_error: 32.2547 - val_loss: 108.9869 - val_mean_squared_error: 108.9869\n",
            "Epoch 40/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 30.3760 - mean_squared_error: 30.3760 - val_loss: 104.6655 - val_mean_squared_error: 104.6655\n",
            "Epoch 41/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 30.7135 - mean_squared_error: 30.7135 - val_loss: 111.6495 - val_mean_squared_error: 111.6495\n",
            "Epoch 42/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 29.6921 - mean_squared_error: 29.6921 - val_loss: 104.4147 - val_mean_squared_error: 104.4147\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 9.712043589463898\n",
            "\n",
            "Training with learning rate=0.0001, optimizer=adam, dropout_rate=0.0, epochs=100\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 1984.8966 - mean_squared_error: 1984.8966 - val_loss: 200.9290 - val_mean_squared_error: 200.9290\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 134.7575 - mean_squared_error: 134.7575 - val_loss: 156.2269 - val_mean_squared_error: 156.2269\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 111.6514 - mean_squared_error: 111.6514 - val_loss: 141.3033 - val_mean_squared_error: 141.3033\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 99.5878 - mean_squared_error: 99.5878 - val_loss: 132.8031 - val_mean_squared_error: 132.8031\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 91.3980 - mean_squared_error: 91.3980 - val_loss: 133.0867 - val_mean_squared_error: 133.0868\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 86.2034 - mean_squared_error: 86.2034 - val_loss: 119.8804 - val_mean_squared_error: 119.8804\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 82.8299 - mean_squared_error: 82.8299 - val_loss: 121.7194 - val_mean_squared_error: 121.7194\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 80.2447 - mean_squared_error: 80.2447 - val_loss: 120.2704 - val_mean_squared_error: 120.2704\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 76.5118 - mean_squared_error: 76.5118 - val_loss: 117.3918 - val_mean_squared_error: 117.3918\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 73.6965 - mean_squared_error: 73.6965 - val_loss: 119.3465 - val_mean_squared_error: 119.3465\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 73.8200 - mean_squared_error: 73.8200 - val_loss: 115.1805 - val_mean_squared_error: 115.1805\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 72.1041 - mean_squared_error: 72.1041 - val_loss: 117.6877 - val_mean_squared_error: 117.6877\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 69.6563 - mean_squared_error: 69.6563 - val_loss: 118.0137 - val_mean_squared_error: 118.0137\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 66.7482 - mean_squared_error: 66.7482 - val_loss: 114.3187 - val_mean_squared_error: 114.3187\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 64.9007 - mean_squared_error: 64.9007 - val_loss: 108.4379 - val_mean_squared_error: 108.4379\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 62.9708 - mean_squared_error: 62.9708 - val_loss: 109.7477 - val_mean_squared_error: 109.7477\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 62.3923 - mean_squared_error: 62.3923 - val_loss: 110.1696 - val_mean_squared_error: 110.1696\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 59.3521 - mean_squared_error: 59.3521 - val_loss: 105.7405 - val_mean_squared_error: 105.7405\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 57.7510 - mean_squared_error: 57.7510 - val_loss: 104.9832 - val_mean_squared_error: 104.9832\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 54.5133 - mean_squared_error: 54.5133 - val_loss: 100.7995 - val_mean_squared_error: 100.7995\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 54.9818 - mean_squared_error: 54.9818 - val_loss: 124.5279 - val_mean_squared_error: 124.5279\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 52.3253 - mean_squared_error: 52.3253 - val_loss: 99.5312 - val_mean_squared_error: 99.5312\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 48.4479 - mean_squared_error: 48.4479 - val_loss: 102.9419 - val_mean_squared_error: 102.9419\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 49.5638 - mean_squared_error: 49.5638 - val_loss: 102.7799 - val_mean_squared_error: 102.7799\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 46.9317 - mean_squared_error: 46.9317 - val_loss: 95.4231 - val_mean_squared_error: 95.4231\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 43.1820 - mean_squared_error: 43.1820 - val_loss: 98.7343 - val_mean_squared_error: 98.7343\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 40.7228 - mean_squared_error: 40.7228 - val_loss: 99.5281 - val_mean_squared_error: 99.5281\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 38.4847 - mean_squared_error: 38.4847 - val_loss: 100.0046 - val_mean_squared_error: 100.0046\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 37.3440 - mean_squared_error: 37.3440 - val_loss: 98.4834 - val_mean_squared_error: 98.4834\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 35.1931 - mean_squared_error: 35.1931 - val_loss: 106.0586 - val_mean_squared_error: 106.0586\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 35.0931 - mean_squared_error: 35.0931 - val_loss: 109.1392 - val_mean_squared_error: 109.1392\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 33.5270 - mean_squared_error: 33.5270 - val_loss: 97.2542 - val_mean_squared_error: 97.2542\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 29.9972 - mean_squared_error: 29.9972 - val_loss: 105.8060 - val_mean_squared_error: 105.8060\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 31.5460 - mean_squared_error: 31.5460 - val_loss: 105.6787 - val_mean_squared_error: 105.6787\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 27.9450 - mean_squared_error: 27.9450 - val_loss: 100.1214 - val_mean_squared_error: 100.1214\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 9.768475257369868\n",
            "\n",
            "Training with learning rate=0.0001, optimizer=adam, dropout_rate=0.0, epochs=150\n",
            "Epoch 1/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 2063.3401 - mean_squared_error: 2063.3401 - val_loss: 207.0122 - val_mean_squared_error: 207.0122\n",
            "Epoch 2/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 138.0527 - mean_squared_error: 138.0527 - val_loss: 170.9109 - val_mean_squared_error: 170.9109\n",
            "Epoch 3/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 113.5485 - mean_squared_error: 113.5485 - val_loss: 149.2671 - val_mean_squared_error: 149.2671\n",
            "Epoch 4/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 100.8903 - mean_squared_error: 100.8903 - val_loss: 139.8518 - val_mean_squared_error: 139.8518\n",
            "Epoch 5/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 94.9080 - mean_squared_error: 94.9080 - val_loss: 134.0632 - val_mean_squared_error: 134.0632\n",
            "Epoch 6/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 88.7339 - mean_squared_error: 88.7339 - val_loss: 131.1801 - val_mean_squared_error: 131.1801\n",
            "Epoch 7/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 84.9594 - mean_squared_error: 84.9594 - val_loss: 129.0254 - val_mean_squared_error: 129.0254\n",
            "Epoch 8/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 82.4056 - mean_squared_error: 82.4056 - val_loss: 121.8989 - val_mean_squared_error: 121.8989\n",
            "Epoch 9/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 79.0416 - mean_squared_error: 79.0416 - val_loss: 122.4406 - val_mean_squared_error: 122.4406\n",
            "Epoch 10/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 77.1201 - mean_squared_error: 77.1201 - val_loss: 122.0946 - val_mean_squared_error: 122.0946\n",
            "Epoch 11/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 74.1400 - mean_squared_error: 74.1400 - val_loss: 115.7316 - val_mean_squared_error: 115.7316\n",
            "Epoch 12/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 71.4573 - mean_squared_error: 71.4573 - val_loss: 116.3872 - val_mean_squared_error: 116.3872\n",
            "Epoch 13/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 69.1354 - mean_squared_error: 69.1354 - val_loss: 115.9136 - val_mean_squared_error: 115.9136\n",
            "Epoch 14/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 67.1696 - mean_squared_error: 67.1696 - val_loss: 127.5118 - val_mean_squared_error: 127.5118\n",
            "Epoch 15/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 66.2647 - mean_squared_error: 66.2647 - val_loss: 115.4401 - val_mean_squared_error: 115.4401\n",
            "Epoch 16/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 64.7526 - mean_squared_error: 64.7526 - val_loss: 127.3005 - val_mean_squared_error: 127.3005\n",
            "Epoch 17/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 64.8820 - mean_squared_error: 64.8820 - val_loss: 118.4577 - val_mean_squared_error: 118.4577\n",
            "Epoch 18/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 60.3318 - mean_squared_error: 60.3318 - val_loss: 118.2434 - val_mean_squared_error: 118.2434\n",
            "Epoch 19/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 58.3302 - mean_squared_error: 58.3302 - val_loss: 111.1575 - val_mean_squared_error: 111.1575\n",
            "Epoch 20/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 59.0398 - mean_squared_error: 59.0398 - val_loss: 113.5255 - val_mean_squared_error: 113.5255\n",
            "Epoch 21/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 54.6149 - mean_squared_error: 54.6149 - val_loss: 111.9927 - val_mean_squared_error: 111.9927\n",
            "Epoch 22/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 52.2170 - mean_squared_error: 52.2170 - val_loss: 113.2777 - val_mean_squared_error: 113.2778\n",
            "Epoch 23/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 50.5431 - mean_squared_error: 50.5431 - val_loss: 127.3295 - val_mean_squared_error: 127.3295\n",
            "Epoch 24/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 48.4400 - mean_squared_error: 48.4400 - val_loss: 118.4745 - val_mean_squared_error: 118.4745\n",
            "Epoch 25/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 47.2255 - mean_squared_error: 47.2255 - val_loss: 119.3030 - val_mean_squared_error: 119.3030\n",
            "Epoch 26/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 45.0931 - mean_squared_error: 45.0931 - val_loss: 113.6465 - val_mean_squared_error: 113.6465\n",
            "Epoch 27/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 42.9824 - mean_squared_error: 42.9824 - val_loss: 119.5245 - val_mean_squared_error: 119.5245\n",
            "Epoch 28/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 40.4701 - mean_squared_error: 40.4701 - val_loss: 120.2558 - val_mean_squared_error: 120.2558\n",
            "Epoch 29/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 40.3073 - mean_squared_error: 40.3073 - val_loss: 126.8929 - val_mean_squared_error: 126.8929\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 10.543127032432075\n",
            "\n",
            "Training with learning rate=0.0001, optimizer=adam, dropout_rate=0.2, epochs=50\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 2s 4ms/step - loss: 2301.7334 - mean_squared_error: 2301.7334 - val_loss: 224.6742 - val_mean_squared_error: 224.6742\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 319.3005 - mean_squared_error: 319.3005 - val_loss: 178.5535 - val_mean_squared_error: 178.5535\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 299.5041 - mean_squared_error: 299.5041 - val_loss: 161.6356 - val_mean_squared_error: 161.6356\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 274.9696 - mean_squared_error: 274.9696 - val_loss: 170.3392 - val_mean_squared_error: 170.3392\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 274.9197 - mean_squared_error: 274.9197 - val_loss: 154.4851 - val_mean_squared_error: 154.4851\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 265.2502 - mean_squared_error: 265.2502 - val_loss: 142.9602 - val_mean_squared_error: 142.9602\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 249.9950 - mean_squared_error: 249.9950 - val_loss: 132.6607 - val_mean_squared_error: 132.6607\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 252.4247 - mean_squared_error: 252.4247 - val_loss: 131.1431 - val_mean_squared_error: 131.1431\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 236.4655 - mean_squared_error: 236.4655 - val_loss: 127.6024 - val_mean_squared_error: 127.6024\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 235.4220 - mean_squared_error: 235.4220 - val_loss: 133.7106 - val_mean_squared_error: 133.7106\n",
            "Epoch 11/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 226.6611 - mean_squared_error: 226.6611 - val_loss: 123.6875 - val_mean_squared_error: 123.6875\n",
            "Epoch 12/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 229.7276 - mean_squared_error: 229.7276 - val_loss: 123.2223 - val_mean_squared_error: 123.2223\n",
            "Epoch 13/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 221.6571 - mean_squared_error: 221.6571 - val_loss: 135.5041 - val_mean_squared_error: 135.5041\n",
            "Epoch 14/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 215.8456 - mean_squared_error: 215.8456 - val_loss: 121.5277 - val_mean_squared_error: 121.5277\n",
            "Epoch 15/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 228.1150 - mean_squared_error: 228.1150 - val_loss: 117.5173 - val_mean_squared_error: 117.5173\n",
            "Epoch 16/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 216.7947 - mean_squared_error: 216.7947 - val_loss: 139.8433 - val_mean_squared_error: 139.8433\n",
            "Epoch 17/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 221.0703 - mean_squared_error: 221.0703 - val_loss: 117.5234 - val_mean_squared_error: 117.5234\n",
            "Epoch 18/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 219.7341 - mean_squared_error: 219.7341 - val_loss: 116.7174 - val_mean_squared_error: 116.7174\n",
            "Epoch 19/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 218.0726 - mean_squared_error: 218.0726 - val_loss: 111.6426 - val_mean_squared_error: 111.6426\n",
            "Epoch 20/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 219.0600 - mean_squared_error: 219.0600 - val_loss: 132.7942 - val_mean_squared_error: 132.7942\n",
            "Epoch 21/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 198.0220 - mean_squared_error: 198.0220 - val_loss: 140.5193 - val_mean_squared_error: 140.5193\n",
            "Epoch 22/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 203.2954 - mean_squared_error: 203.2954 - val_loss: 111.5733 - val_mean_squared_error: 111.5733\n",
            "Epoch 23/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 213.9976 - mean_squared_error: 213.9976 - val_loss: 123.4862 - val_mean_squared_error: 123.4862\n",
            "Epoch 24/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 215.0561 - mean_squared_error: 215.0561 - val_loss: 115.8769 - val_mean_squared_error: 115.8769\n",
            "Epoch 25/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 200.8166 - mean_squared_error: 200.8166 - val_loss: 139.7569 - val_mean_squared_error: 139.7569\n",
            "Epoch 26/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 210.8311 - mean_squared_error: 210.8311 - val_loss: 112.2546 - val_mean_squared_error: 112.2546\n",
            "Epoch 27/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 203.9159 - mean_squared_error: 203.9159 - val_loss: 116.2752 - val_mean_squared_error: 116.2752\n",
            "Epoch 28/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 209.2662 - mean_squared_error: 209.2662 - val_loss: 120.0743 - val_mean_squared_error: 120.0743\n",
            "Epoch 29/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 212.4511 - mean_squared_error: 212.4511 - val_loss: 132.5921 - val_mean_squared_error: 132.5921\n",
            "Epoch 30/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 212.4839 - mean_squared_error: 212.4839 - val_loss: 132.5872 - val_mean_squared_error: 132.5872\n",
            "Epoch 31/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 208.3369 - mean_squared_error: 208.3369 - val_loss: 111.2855 - val_mean_squared_error: 111.2855\n",
            "Epoch 32/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 195.4060 - mean_squared_error: 195.4059 - val_loss: 119.1755 - val_mean_squared_error: 119.1755\n",
            "Epoch 33/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 198.0926 - mean_squared_error: 198.0926 - val_loss: 107.3085 - val_mean_squared_error: 107.3085\n",
            "Epoch 34/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 199.1072 - mean_squared_error: 199.1072 - val_loss: 111.0023 - val_mean_squared_error: 111.0023\n",
            "Epoch 35/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 196.6263 - mean_squared_error: 196.6263 - val_loss: 105.6000 - val_mean_squared_error: 105.6000\n",
            "Epoch 36/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 208.5357 - mean_squared_error: 208.5356 - val_loss: 107.4129 - val_mean_squared_error: 107.4129\n",
            "Epoch 37/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 194.2260 - mean_squared_error: 194.2260 - val_loss: 122.9961 - val_mean_squared_error: 122.9961\n",
            "Epoch 38/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 193.6408 - mean_squared_error: 193.6408 - val_loss: 104.6612 - val_mean_squared_error: 104.6612\n",
            "Epoch 39/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 186.8826 - mean_squared_error: 186.8826 - val_loss: 118.1378 - val_mean_squared_error: 118.1378\n",
            "Epoch 40/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 208.2371 - mean_squared_error: 208.2371 - val_loss: 102.6032 - val_mean_squared_error: 102.6032\n",
            "Epoch 41/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 188.1674 - mean_squared_error: 188.1674 - val_loss: 107.4731 - val_mean_squared_error: 107.4731\n",
            "Epoch 42/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 185.6997 - mean_squared_error: 185.6997 - val_loss: 106.8985 - val_mean_squared_error: 106.8985\n",
            "Epoch 43/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 193.1911 - mean_squared_error: 193.1911 - val_loss: 109.2939 - val_mean_squared_error: 109.2939\n",
            "Epoch 44/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 182.8737 - mean_squared_error: 182.8737 - val_loss: 122.7684 - val_mean_squared_error: 122.7684\n",
            "Epoch 45/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 197.0019 - mean_squared_error: 197.0019 - val_loss: 119.3734 - val_mean_squared_error: 119.3734\n",
            "Epoch 46/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 192.5456 - mean_squared_error: 192.5456 - val_loss: 116.1238 - val_mean_squared_error: 116.1238\n",
            "Epoch 47/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 187.1700 - mean_squared_error: 187.1700 - val_loss: 104.4902 - val_mean_squared_error: 104.4902\n",
            "Epoch 48/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 188.0540 - mean_squared_error: 188.0540 - val_loss: 107.5130 - val_mean_squared_error: 107.5130\n",
            "Epoch 49/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 206.8119 - mean_squared_error: 206.8119 - val_loss: 113.4427 - val_mean_squared_error: 113.4427\n",
            "Epoch 50/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 190.5377 - mean_squared_error: 190.5377 - val_loss: 108.4828 - val_mean_squared_error: 108.4828\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "RMSE: 10.12932206153982\n",
            "\n",
            "Training with learning rate=0.0001, optimizer=adam, dropout_rate=0.2, epochs=100\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 2s 3ms/step - loss: 2536.1536 - mean_squared_error: 2536.1536 - val_loss: 219.0211 - val_mean_squared_error: 219.0211\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 381.7077 - mean_squared_error: 381.7077 - val_loss: 170.5273 - val_mean_squared_error: 170.5273\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 321.2717 - mean_squared_error: 321.2717 - val_loss: 182.1959 - val_mean_squared_error: 182.1959\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 299.9992 - mean_squared_error: 299.9992 - val_loss: 149.9987 - val_mean_squared_error: 149.9987\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 293.8508 - mean_squared_error: 293.8508 - val_loss: 145.1842 - val_mean_squared_error: 145.1842\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 279.0311 - mean_squared_error: 279.0310 - val_loss: 149.5775 - val_mean_squared_error: 149.5775\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 272.6969 - mean_squared_error: 272.6969 - val_loss: 135.2579 - val_mean_squared_error: 135.2579\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 274.8964 - mean_squared_error: 274.8964 - val_loss: 136.5194 - val_mean_squared_error: 136.5194\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 257.5118 - mean_squared_error: 257.5118 - val_loss: 144.9510 - val_mean_squared_error: 144.9510\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 270.5676 - mean_squared_error: 270.5676 - val_loss: 133.5303 - val_mean_squared_error: 133.5303\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 257.7995 - mean_squared_error: 257.7995 - val_loss: 122.7142 - val_mean_squared_error: 122.7142\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 261.4841 - mean_squared_error: 261.4841 - val_loss: 143.3220 - val_mean_squared_error: 143.3220\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 246.5689 - mean_squared_error: 246.5689 - val_loss: 122.7643 - val_mean_squared_error: 122.7643\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 249.4533 - mean_squared_error: 249.4533 - val_loss: 130.2030 - val_mean_squared_error: 130.2030\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 238.9381 - mean_squared_error: 238.9381 - val_loss: 127.2624 - val_mean_squared_error: 127.2624\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 229.5754 - mean_squared_error: 229.5754 - val_loss: 118.1051 - val_mean_squared_error: 118.1051\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 248.6484 - mean_squared_error: 248.6484 - val_loss: 122.9595 - val_mean_squared_error: 122.9595\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 232.3804 - mean_squared_error: 232.3804 - val_loss: 129.7315 - val_mean_squared_error: 129.7315\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 230.8859 - mean_squared_error: 230.8859 - val_loss: 130.3043 - val_mean_squared_error: 130.3043\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 224.1289 - mean_squared_error: 224.1289 - val_loss: 144.5094 - val_mean_squared_error: 144.5094\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 230.5170 - mean_squared_error: 230.5170 - val_loss: 118.8958 - val_mean_squared_error: 118.8958\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 235.7995 - mean_squared_error: 235.7995 - val_loss: 121.6652 - val_mean_squared_error: 121.6652\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 224.6884 - mean_squared_error: 224.6884 - val_loss: 119.2913 - val_mean_squared_error: 119.2913\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 244.5521 - mean_squared_error: 244.5521 - val_loss: 125.3152 - val_mean_squared_error: 125.3152\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 226.1517 - mean_squared_error: 226.1517 - val_loss: 119.3618 - val_mean_squared_error: 119.3618\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 222.6271 - mean_squared_error: 222.6271 - val_loss: 118.9270 - val_mean_squared_error: 118.9270\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 10.867617020695977\n",
            "\n",
            "Training with learning rate=0.0001, optimizer=adam, dropout_rate=0.2, epochs=150\n",
            "Epoch 1/150\n",
            "165/165 [==============================] - 2s 3ms/step - loss: 1959.6808 - mean_squared_error: 1959.6808 - val_loss: 217.5043 - val_mean_squared_error: 217.5043\n",
            "Epoch 2/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 320.6878 - mean_squared_error: 320.6878 - val_loss: 208.7034 - val_mean_squared_error: 208.7034\n",
            "Epoch 3/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 280.1917 - mean_squared_error: 280.1917 - val_loss: 177.2856 - val_mean_squared_error: 177.2856\n",
            "Epoch 4/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 264.1990 - mean_squared_error: 264.1990 - val_loss: 161.7569 - val_mean_squared_error: 161.7569\n",
            "Epoch 5/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 246.7426 - mean_squared_error: 246.7426 - val_loss: 161.6588 - val_mean_squared_error: 161.6588\n",
            "Epoch 6/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 246.5601 - mean_squared_error: 246.5601 - val_loss: 162.7493 - val_mean_squared_error: 162.7493\n",
            "Epoch 7/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 256.2292 - mean_squared_error: 256.2292 - val_loss: 140.4919 - val_mean_squared_error: 140.4919\n",
            "Epoch 8/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 228.6400 - mean_squared_error: 228.6400 - val_loss: 150.0109 - val_mean_squared_error: 150.0109\n",
            "Epoch 9/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 230.0863 - mean_squared_error: 230.0863 - val_loss: 126.9106 - val_mean_squared_error: 126.9106\n",
            "Epoch 10/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 240.8756 - mean_squared_error: 240.8756 - val_loss: 131.3055 - val_mean_squared_error: 131.3055\n",
            "Epoch 11/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 225.4041 - mean_squared_error: 225.4041 - val_loss: 134.3383 - val_mean_squared_error: 134.3383\n",
            "Epoch 12/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 226.9370 - mean_squared_error: 226.9370 - val_loss: 119.7681 - val_mean_squared_error: 119.7681\n",
            "Epoch 13/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 222.1390 - mean_squared_error: 222.1390 - val_loss: 118.8032 - val_mean_squared_error: 118.8032\n",
            "Epoch 14/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 219.6915 - mean_squared_error: 219.6915 - val_loss: 125.5994 - val_mean_squared_error: 125.5994\n",
            "Epoch 15/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 216.9385 - mean_squared_error: 216.9385 - val_loss: 118.2935 - val_mean_squared_error: 118.2935\n",
            "Epoch 16/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 223.2768 - mean_squared_error: 223.2768 - val_loss: 124.4339 - val_mean_squared_error: 124.4339\n",
            "Epoch 17/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 217.4414 - mean_squared_error: 217.4414 - val_loss: 121.2327 - val_mean_squared_error: 121.2327\n",
            "Epoch 18/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 217.2296 - mean_squared_error: 217.2296 - val_loss: 115.5304 - val_mean_squared_error: 115.5304\n",
            "Epoch 19/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 213.5633 - mean_squared_error: 213.5633 - val_loss: 117.0983 - val_mean_squared_error: 117.0983\n",
            "Epoch 20/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 206.3425 - mean_squared_error: 206.3425 - val_loss: 121.8038 - val_mean_squared_error: 121.8038\n",
            "Epoch 21/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 210.6348 - mean_squared_error: 210.6348 - val_loss: 111.9429 - val_mean_squared_error: 111.9429\n",
            "Epoch 22/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 201.2230 - mean_squared_error: 201.2230 - val_loss: 109.4656 - val_mean_squared_error: 109.4656\n",
            "Epoch 23/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 208.9890 - mean_squared_error: 208.9890 - val_loss: 112.7065 - val_mean_squared_error: 112.7065\n",
            "Epoch 24/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 206.1669 - mean_squared_error: 206.1669 - val_loss: 114.4391 - val_mean_squared_error: 114.4391\n",
            "Epoch 25/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 205.7926 - mean_squared_error: 205.7926 - val_loss: 127.2782 - val_mean_squared_error: 127.2782\n",
            "Epoch 26/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 202.6456 - mean_squared_error: 202.6456 - val_loss: 106.9623 - val_mean_squared_error: 106.9623\n",
            "Epoch 27/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 197.7768 - mean_squared_error: 197.7768 - val_loss: 108.6045 - val_mean_squared_error: 108.6045\n",
            "Epoch 28/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 202.4225 - mean_squared_error: 202.4225 - val_loss: 105.5977 - val_mean_squared_error: 105.5977\n",
            "Epoch 29/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 208.3439 - mean_squared_error: 208.3439 - val_loss: 112.7326 - val_mean_squared_error: 112.7326\n",
            "Epoch 30/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 193.9894 - mean_squared_error: 193.9894 - val_loss: 112.8623 - val_mean_squared_error: 112.8623\n",
            "Epoch 31/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 199.8922 - mean_squared_error: 199.8922 - val_loss: 123.0774 - val_mean_squared_error: 123.0774\n",
            "Epoch 32/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 202.3758 - mean_squared_error: 202.3758 - val_loss: 120.6570 - val_mean_squared_error: 120.6570\n",
            "Epoch 33/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 192.6017 - mean_squared_error: 192.6017 - val_loss: 125.0550 - val_mean_squared_error: 125.0550\n",
            "Epoch 34/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 200.4277 - mean_squared_error: 200.4277 - val_loss: 113.7617 - val_mean_squared_error: 113.7617\n",
            "Epoch 35/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 193.7475 - mean_squared_error: 193.7475 - val_loss: 113.8034 - val_mean_squared_error: 113.8034\n",
            "Epoch 36/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 195.1467 - mean_squared_error: 195.1467 - val_loss: 104.4347 - val_mean_squared_error: 104.4347\n",
            "Epoch 37/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 192.4028 - mean_squared_error: 192.4028 - val_loss: 103.3552 - val_mean_squared_error: 103.3552\n",
            "Epoch 38/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 201.1228 - mean_squared_error: 201.1228 - val_loss: 118.2010 - val_mean_squared_error: 118.2010\n",
            "Epoch 39/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 185.5718 - mean_squared_error: 185.5718 - val_loss: 120.0604 - val_mean_squared_error: 120.0604\n",
            "Epoch 40/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 189.9292 - mean_squared_error: 189.9292 - val_loss: 117.3195 - val_mean_squared_error: 117.3195\n",
            "Epoch 41/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 199.6053 - mean_squared_error: 199.6053 - val_loss: 118.2798 - val_mean_squared_error: 118.2798\n",
            "Epoch 42/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 184.6380 - mean_squared_error: 184.6380 - val_loss: 117.9547 - val_mean_squared_error: 117.9547\n",
            "Epoch 43/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 187.6579 - mean_squared_error: 187.6579 - val_loss: 115.7159 - val_mean_squared_error: 115.7159\n",
            "Epoch 44/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 191.1358 - mean_squared_error: 191.1358 - val_loss: 116.8810 - val_mean_squared_error: 116.8810\n",
            "Epoch 45/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 195.6460 - mean_squared_error: 195.6460 - val_loss: 116.6708 - val_mean_squared_error: 116.6708\n",
            "Epoch 46/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 180.2677 - mean_squared_error: 180.2677 - val_loss: 110.6662 - val_mean_squared_error: 110.6662\n",
            "Epoch 47/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 186.7932 - mean_squared_error: 186.7932 - val_loss: 115.8037 - val_mean_squared_error: 115.8037\n",
            "13/13 [==============================] - 0s 4ms/step\n",
            "RMSE: 10.166375193469863\n",
            "\n",
            "Training with learning rate=0.0001, optimizer=adam, dropout_rate=0.5, epochs=50\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 3s 10ms/step - loss: 2916.6226 - mean_squared_error: 2916.6226 - val_loss: 319.3778 - val_mean_squared_error: 319.3778\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 769.3164 - mean_squared_error: 769.3164 - val_loss: 297.4763 - val_mean_squared_error: 297.4763\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 706.4623 - mean_squared_error: 706.4623 - val_loss: 260.2281 - val_mean_squared_error: 260.2281\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 683.4647 - mean_squared_error: 683.4648 - val_loss: 222.8852 - val_mean_squared_error: 222.8852\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 640.5601 - mean_squared_error: 640.5601 - val_loss: 179.9899 - val_mean_squared_error: 179.9898\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 643.3793 - mean_squared_error: 643.3793 - val_loss: 162.8269 - val_mean_squared_error: 162.8269\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 615.7473 - mean_squared_error: 615.7473 - val_loss: 206.7389 - val_mean_squared_error: 206.7389\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 640.2153 - mean_squared_error: 640.2153 - val_loss: 199.8980 - val_mean_squared_error: 199.8980\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 600.8673 - mean_squared_error: 600.8673 - val_loss: 165.0255 - val_mean_squared_error: 165.0255\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 540.7088 - mean_squared_error: 540.7088 - val_loss: 160.7202 - val_mean_squared_error: 160.7202\n",
            "Epoch 11/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 602.6885 - mean_squared_error: 602.6885 - val_loss: 132.1840 - val_mean_squared_error: 132.1840\n",
            "Epoch 12/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 531.1122 - mean_squared_error: 531.1122 - val_loss: 133.0067 - val_mean_squared_error: 133.0067\n",
            "Epoch 13/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 528.8509 - mean_squared_error: 528.8509 - val_loss: 186.3463 - val_mean_squared_error: 186.3463\n",
            "Epoch 14/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 555.5492 - mean_squared_error: 555.5492 - val_loss: 120.8143 - val_mean_squared_error: 120.8143\n",
            "Epoch 15/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 543.4962 - mean_squared_error: 543.4962 - val_loss: 157.7507 - val_mean_squared_error: 157.7507\n",
            "Epoch 16/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 522.2704 - mean_squared_error: 522.2704 - val_loss: 125.8525 - val_mean_squared_error: 125.8525\n",
            "Epoch 17/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 497.9010 - mean_squared_error: 497.9011 - val_loss: 157.7145 - val_mean_squared_error: 157.7145\n",
            "Epoch 18/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 525.5112 - mean_squared_error: 525.5112 - val_loss: 188.9030 - val_mean_squared_error: 188.9030\n",
            "Epoch 19/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 498.4037 - mean_squared_error: 498.4037 - val_loss: 148.8149 - val_mean_squared_error: 148.8149\n",
            "Epoch 20/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 531.3143 - mean_squared_error: 531.3143 - val_loss: 147.3439 - val_mean_squared_error: 147.3439\n",
            "Epoch 21/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 490.4748 - mean_squared_error: 490.4748 - val_loss: 175.4537 - val_mean_squared_error: 175.4537\n",
            "Epoch 22/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 486.8847 - mean_squared_error: 486.8847 - val_loss: 149.1183 - val_mean_squared_error: 149.1183\n",
            "Epoch 23/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 493.7246 - mean_squared_error: 493.7246 - val_loss: 145.2399 - val_mean_squared_error: 145.2399\n",
            "Epoch 24/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 500.4696 - mean_squared_error: 500.4696 - val_loss: 147.2788 - val_mean_squared_error: 147.2788\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 10.991554616845269\n",
            "\n",
            "Training with learning rate=0.0001, optimizer=adam, dropout_rate=0.5, epochs=100\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 2s 5ms/step - loss: 3105.0808 - mean_squared_error: 3105.0808 - val_loss: 300.6111 - val_mean_squared_error: 300.6111\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 938.9948 - mean_squared_error: 938.9948 - val_loss: 234.3744 - val_mean_squared_error: 234.3744\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 806.6942 - mean_squared_error: 806.6942 - val_loss: 262.6041 - val_mean_squared_error: 262.6041\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 717.5701 - mean_squared_error: 717.5701 - val_loss: 193.6053 - val_mean_squared_error: 193.6053\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 733.2949 - mean_squared_error: 733.2949 - val_loss: 237.1609 - val_mean_squared_error: 237.1609\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 708.3981 - mean_squared_error: 708.3981 - val_loss: 205.0089 - val_mean_squared_error: 205.0089\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 705.2389 - mean_squared_error: 705.2389 - val_loss: 182.0173 - val_mean_squared_error: 182.0173\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 660.7848 - mean_squared_error: 660.7848 - val_loss: 226.6406 - val_mean_squared_error: 226.6406\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 645.7402 - mean_squared_error: 645.7402 - val_loss: 212.0540 - val_mean_squared_error: 212.0540\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 650.0957 - mean_squared_error: 650.0957 - val_loss: 172.9150 - val_mean_squared_error: 172.9150\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 647.6185 - mean_squared_error: 647.6185 - val_loss: 195.8185 - val_mean_squared_error: 195.8185\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 638.5197 - mean_squared_error: 638.5197 - val_loss: 202.6892 - val_mean_squared_error: 202.6892\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 610.8745 - mean_squared_error: 610.8745 - val_loss: 218.5382 - val_mean_squared_error: 218.5382\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 586.5478 - mean_squared_error: 586.5477 - val_loss: 150.7358 - val_mean_squared_error: 150.7358\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 603.1802 - mean_squared_error: 603.1802 - val_loss: 146.1746 - val_mean_squared_error: 146.1746\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 633.7429 - mean_squared_error: 633.7429 - val_loss: 158.3595 - val_mean_squared_error: 158.3595\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 578.3124 - mean_squared_error: 578.3124 - val_loss: 140.4512 - val_mean_squared_error: 140.4512\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 577.4476 - mean_squared_error: 577.4476 - val_loss: 130.3987 - val_mean_squared_error: 130.3987\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 595.9891 - mean_squared_error: 595.9891 - val_loss: 192.5292 - val_mean_squared_error: 192.5292\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 574.1653 - mean_squared_error: 574.1653 - val_loss: 175.7960 - val_mean_squared_error: 175.7960\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 605.4466 - mean_squared_error: 605.4466 - val_loss: 184.5961 - val_mean_squared_error: 184.5961\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 562.6894 - mean_squared_error: 562.6894 - val_loss: 214.5322 - val_mean_squared_error: 214.5322\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 575.6268 - mean_squared_error: 575.6268 - val_loss: 262.6632 - val_mean_squared_error: 262.6632\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 578.2496 - mean_squared_error: 578.2496 - val_loss: 177.6504 - val_mean_squared_error: 177.6504\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 582.3933 - mean_squared_error: 582.3933 - val_loss: 148.2785 - val_mean_squared_error: 148.2785\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 564.1005 - mean_squared_error: 564.1005 - val_loss: 145.6051 - val_mean_squared_error: 145.6051\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 552.2146 - mean_squared_error: 552.2146 - val_loss: 169.1720 - val_mean_squared_error: 169.1720\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 558.2953 - mean_squared_error: 558.2953 - val_loss: 160.5800 - val_mean_squared_error: 160.5800\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "RMSE: 11.41922555517504\n",
            "\n",
            "Training with learning rate=0.0001, optimizer=adam, dropout_rate=0.5, epochs=150\n",
            "Epoch 1/150\n",
            "165/165 [==============================] - 2s 4ms/step - loss: 3330.7551 - mean_squared_error: 3330.7551 - val_loss: 354.3282 - val_mean_squared_error: 354.3282\n",
            "Epoch 2/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 901.2613 - mean_squared_error: 901.2613 - val_loss: 298.1465 - val_mean_squared_error: 298.1465\n",
            "Epoch 3/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 792.9481 - mean_squared_error: 792.9481 - val_loss: 229.6363 - val_mean_squared_error: 229.6363\n",
            "Epoch 4/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 748.6754 - mean_squared_error: 748.6754 - val_loss: 236.9528 - val_mean_squared_error: 236.9528\n",
            "Epoch 5/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 773.7592 - mean_squared_error: 773.7592 - val_loss: 277.0284 - val_mean_squared_error: 277.0284\n",
            "Epoch 6/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 733.7693 - mean_squared_error: 733.7693 - val_loss: 203.5715 - val_mean_squared_error: 203.5715\n",
            "Epoch 7/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 698.4323 - mean_squared_error: 698.4323 - val_loss: 217.1341 - val_mean_squared_error: 217.1341\n",
            "Epoch 8/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 671.3385 - mean_squared_error: 671.3385 - val_loss: 157.5106 - val_mean_squared_error: 157.5106\n",
            "Epoch 9/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 651.9785 - mean_squared_error: 651.9785 - val_loss: 190.2710 - val_mean_squared_error: 190.2710\n",
            "Epoch 10/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 684.1405 - mean_squared_error: 684.1405 - val_loss: 215.8318 - val_mean_squared_error: 215.8318\n",
            "Epoch 11/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 670.9924 - mean_squared_error: 670.9924 - val_loss: 218.7167 - val_mean_squared_error: 218.7167\n",
            "Epoch 12/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 656.0481 - mean_squared_error: 656.0481 - val_loss: 172.3267 - val_mean_squared_error: 172.3267\n",
            "Epoch 13/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 638.7311 - mean_squared_error: 638.7311 - val_loss: 157.5408 - val_mean_squared_error: 157.5408\n",
            "Epoch 14/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 632.9587 - mean_squared_error: 632.9587 - val_loss: 168.5598 - val_mean_squared_error: 168.5598\n",
            "Epoch 15/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 660.1016 - mean_squared_error: 660.1016 - val_loss: 216.1819 - val_mean_squared_error: 216.1819\n",
            "Epoch 16/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 672.2865 - mean_squared_error: 672.2866 - val_loss: 212.6771 - val_mean_squared_error: 212.6771\n",
            "Epoch 17/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 657.1602 - mean_squared_error: 657.1602 - val_loss: 179.4449 - val_mean_squared_error: 179.4449\n",
            "Epoch 18/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 667.4800 - mean_squared_error: 667.4800 - val_loss: 156.3460 - val_mean_squared_error: 156.3460\n",
            "Epoch 19/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 596.0580 - mean_squared_error: 596.0580 - val_loss: 167.2546 - val_mean_squared_error: 167.2546\n",
            "Epoch 20/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 599.1983 - mean_squared_error: 599.1983 - val_loss: 175.9226 - val_mean_squared_error: 175.9226\n",
            "Epoch 21/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 586.9742 - mean_squared_error: 586.9742 - val_loss: 188.7665 - val_mean_squared_error: 188.7665\n",
            "Epoch 22/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 582.7864 - mean_squared_error: 582.7864 - val_loss: 132.4477 - val_mean_squared_error: 132.4477\n",
            "Epoch 23/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 637.2184 - mean_squared_error: 637.2184 - val_loss: 204.0045 - val_mean_squared_error: 204.0045\n",
            "Epoch 24/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 615.4691 - mean_squared_error: 615.4691 - val_loss: 190.9636 - val_mean_squared_error: 190.9636\n",
            "Epoch 25/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 603.4001 - mean_squared_error: 603.4001 - val_loss: 211.0557 - val_mean_squared_error: 211.0557\n",
            "Epoch 26/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 602.7981 - mean_squared_error: 602.7981 - val_loss: 147.8819 - val_mean_squared_error: 147.8819\n",
            "Epoch 27/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 594.6589 - mean_squared_error: 594.6589 - val_loss: 145.2885 - val_mean_squared_error: 145.2885\n",
            "Epoch 28/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 601.8195 - mean_squared_error: 601.8195 - val_loss: 180.8769 - val_mean_squared_error: 180.8769\n",
            "Epoch 29/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 561.2164 - mean_squared_error: 561.2164 - val_loss: 127.0392 - val_mean_squared_error: 127.0392\n",
            "Epoch 30/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 534.8375 - mean_squared_error: 534.8375 - val_loss: 162.6768 - val_mean_squared_error: 162.6768\n",
            "Epoch 31/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 551.9551 - mean_squared_error: 551.9551 - val_loss: 157.1184 - val_mean_squared_error: 157.1184\n",
            "Epoch 32/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 523.0116 - mean_squared_error: 523.0116 - val_loss: 151.0628 - val_mean_squared_error: 151.0628\n",
            "Epoch 33/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 550.4622 - mean_squared_error: 550.4622 - val_loss: 139.0532 - val_mean_squared_error: 139.0532\n",
            "Epoch 34/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 561.9420 - mean_squared_error: 561.9420 - val_loss: 185.0495 - val_mean_squared_error: 185.0495\n",
            "Epoch 35/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 536.1277 - mean_squared_error: 536.1277 - val_loss: 119.1020 - val_mean_squared_error: 119.1020\n",
            "Epoch 36/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 531.8417 - mean_squared_error: 531.8417 - val_loss: 130.8943 - val_mean_squared_error: 130.8943\n",
            "Epoch 37/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 515.6768 - mean_squared_error: 515.6768 - val_loss: 134.2878 - val_mean_squared_error: 134.2878\n",
            "Epoch 38/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 528.2947 - mean_squared_error: 528.2947 - val_loss: 179.8208 - val_mean_squared_error: 179.8208\n",
            "Epoch 39/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 499.4241 - mean_squared_error: 499.4241 - val_loss: 147.5006 - val_mean_squared_error: 147.5006\n",
            "Epoch 40/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 508.1757 - mean_squared_error: 508.1757 - val_loss: 187.2246 - val_mean_squared_error: 187.2246\n",
            "Epoch 41/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 543.5361 - mean_squared_error: 543.5361 - val_loss: 136.1101 - val_mean_squared_error: 136.1101\n",
            "Epoch 42/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 500.2631 - mean_squared_error: 500.2631 - val_loss: 163.4119 - val_mean_squared_error: 163.4119\n",
            "Epoch 43/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 506.2569 - mean_squared_error: 506.2569 - val_loss: 124.2632 - val_mean_squared_error: 124.2632\n",
            "Epoch 44/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 499.4277 - mean_squared_error: 499.4277 - val_loss: 149.8375 - val_mean_squared_error: 149.8375\n",
            "Epoch 45/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 486.1599 - mean_squared_error: 486.1599 - val_loss: 141.4543 - val_mean_squared_error: 141.4543\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 10.913385261692868\n",
            "\n",
            "Training with learning rate=0.0001, optimizer=sgd, dropout_rate=0.0, epochs=50\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 1s 5ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.0001, optimizer=sgd, dropout_rate=0.0, epochs=50\n",
            "Training with learning rate=0.0001, optimizer=sgd, dropout_rate=0.0, epochs=100\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.0001, optimizer=sgd, dropout_rate=0.0, epochs=100\n",
            "Training with learning rate=0.0001, optimizer=sgd, dropout_rate=0.0, epochs=150\n",
            "Epoch 1/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.0001, optimizer=sgd, dropout_rate=0.0, epochs=150\n",
            "Training with learning rate=0.0001, optimizer=sgd, dropout_rate=0.2, epochs=50\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.0001, optimizer=sgd, dropout_rate=0.2, epochs=50\n",
            "Training with learning rate=0.0001, optimizer=sgd, dropout_rate=0.2, epochs=100\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "NaN values found in predictions with learning rate=0.0001, optimizer=sgd, dropout_rate=0.2, epochs=100\n",
            "Training with learning rate=0.0001, optimizer=sgd, dropout_rate=0.2, epochs=150\n",
            "Epoch 1/150\n",
            "165/165 [==============================] - 2s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.0001, optimizer=sgd, dropout_rate=0.2, epochs=150\n",
            "Training with learning rate=0.0001, optimizer=sgd, dropout_rate=0.5, epochs=50\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.0001, optimizer=sgd, dropout_rate=0.5, epochs=50\n",
            "Training with learning rate=0.0001, optimizer=sgd, dropout_rate=0.5, epochs=100\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 2s 5ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.0001, optimizer=sgd, dropout_rate=0.5, epochs=100\n",
            "Training with learning rate=0.0001, optimizer=sgd, dropout_rate=0.5, epochs=150\n",
            "Epoch 1/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.0001, optimizer=sgd, dropout_rate=0.5, epochs=150\n",
            "Training with learning rate=0.001, optimizer=adam, dropout_rate=0.0, epochs=50\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 2s 4ms/step - loss: 1897.2166 - mean_squared_error: 1897.2166 - val_loss: 193.5114 - val_mean_squared_error: 193.5114\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 143.2700 - mean_squared_error: 143.2700 - val_loss: 155.9240 - val_mean_squared_error: 155.9240\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 115.9485 - mean_squared_error: 115.9485 - val_loss: 141.5339 - val_mean_squared_error: 141.5339\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 101.2572 - mean_squared_error: 101.2572 - val_loss: 127.2416 - val_mean_squared_error: 127.2416\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 93.8157 - mean_squared_error: 93.8157 - val_loss: 123.2856 - val_mean_squared_error: 123.2856\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 87.1500 - mean_squared_error: 87.1500 - val_loss: 120.1490 - val_mean_squared_error: 120.1490\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 83.6378 - mean_squared_error: 83.6378 - val_loss: 118.3249 - val_mean_squared_error: 118.3249\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 80.0258 - mean_squared_error: 80.0258 - val_loss: 114.4671 - val_mean_squared_error: 114.4671\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 77.4483 - mean_squared_error: 77.4483 - val_loss: 117.6351 - val_mean_squared_error: 117.6351\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 76.0303 - mean_squared_error: 76.0303 - val_loss: 116.8338 - val_mean_squared_error: 116.8338\n",
            "Epoch 11/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 71.8630 - mean_squared_error: 71.8630 - val_loss: 112.5716 - val_mean_squared_error: 112.5716\n",
            "Epoch 12/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 70.3857 - mean_squared_error: 70.3857 - val_loss: 113.0478 - val_mean_squared_error: 113.0477\n",
            "Epoch 13/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 67.3874 - mean_squared_error: 67.3874 - val_loss: 112.9621 - val_mean_squared_error: 112.9621\n",
            "Epoch 14/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 65.0820 - mean_squared_error: 65.0820 - val_loss: 107.3882 - val_mean_squared_error: 107.3882\n",
            "Epoch 15/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 64.5341 - mean_squared_error: 64.5341 - val_loss: 114.3627 - val_mean_squared_error: 114.3627\n",
            "Epoch 16/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 62.5850 - mean_squared_error: 62.5850 - val_loss: 110.3086 - val_mean_squared_error: 110.3086\n",
            "Epoch 17/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 60.1792 - mean_squared_error: 60.1792 - val_loss: 106.8246 - val_mean_squared_error: 106.8246\n",
            "Epoch 18/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 57.8779 - mean_squared_error: 57.8779 - val_loss: 112.1522 - val_mean_squared_error: 112.1522\n",
            "Epoch 19/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 56.3740 - mean_squared_error: 56.3740 - val_loss: 100.9625 - val_mean_squared_error: 100.9625\n",
            "Epoch 20/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 54.5291 - mean_squared_error: 54.5291 - val_loss: 104.5816 - val_mean_squared_error: 104.5816\n",
            "Epoch 21/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 51.4805 - mean_squared_error: 51.4805 - val_loss: 104.7316 - val_mean_squared_error: 104.7316\n",
            "Epoch 22/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 50.9871 - mean_squared_error: 50.9871 - val_loss: 105.0141 - val_mean_squared_error: 105.0141\n",
            "Epoch 23/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 47.9626 - mean_squared_error: 47.9626 - val_loss: 106.7654 - val_mean_squared_error: 106.7654\n",
            "Epoch 24/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 47.6830 - mean_squared_error: 47.6830 - val_loss: 106.4870 - val_mean_squared_error: 106.4870\n",
            "Epoch 25/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 44.5951 - mean_squared_error: 44.5951 - val_loss: 104.4673 - val_mean_squared_error: 104.4673\n",
            "Epoch 26/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 42.2792 - mean_squared_error: 42.2792 - val_loss: 105.8570 - val_mean_squared_error: 105.8570\n",
            "Epoch 27/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 41.8355 - mean_squared_error: 41.8355 - val_loss: 103.9360 - val_mean_squared_error: 103.9360\n",
            "Epoch 28/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 37.7176 - mean_squared_error: 37.7176 - val_loss: 104.6626 - val_mean_squared_error: 104.6626\n",
            "Epoch 29/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 36.9771 - mean_squared_error: 36.9771 - val_loss: 109.9870 - val_mean_squared_error: 109.9870\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 10.04801186313679\n",
            "\n",
            "Training with learning rate=0.001, optimizer=adam, dropout_rate=0.0, epochs=100\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 2138.2832 - mean_squared_error: 2138.2832 - val_loss: 210.3851 - val_mean_squared_error: 210.3851\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 139.1539 - mean_squared_error: 139.1539 - val_loss: 168.9044 - val_mean_squared_error: 168.9044\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 113.9861 - mean_squared_error: 113.9861 - val_loss: 142.8633 - val_mean_squared_error: 142.8633\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 98.8508 - mean_squared_error: 98.8508 - val_loss: 137.9135 - val_mean_squared_error: 137.9135\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 92.5345 - mean_squared_error: 92.5345 - val_loss: 133.7341 - val_mean_squared_error: 133.7341\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 87.8993 - mean_squared_error: 87.8993 - val_loss: 126.3327 - val_mean_squared_error: 126.3327\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 84.2970 - mean_squared_error: 84.2970 - val_loss: 122.8556 - val_mean_squared_error: 122.8556\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 79.6221 - mean_squared_error: 79.6221 - val_loss: 120.1196 - val_mean_squared_error: 120.1196\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 77.3810 - mean_squared_error: 77.3810 - val_loss: 115.6502 - val_mean_squared_error: 115.6502\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 74.5318 - mean_squared_error: 74.5318 - val_loss: 114.5764 - val_mean_squared_error: 114.5764\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 72.6789 - mean_squared_error: 72.6789 - val_loss: 108.7289 - val_mean_squared_error: 108.7289\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 69.7934 - mean_squared_error: 69.7934 - val_loss: 116.1441 - val_mean_squared_error: 116.1441\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 69.9246 - mean_squared_error: 69.9246 - val_loss: 110.1072 - val_mean_squared_error: 110.1072\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 67.1502 - mean_squared_error: 67.1502 - val_loss: 109.8433 - val_mean_squared_error: 109.8433\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 63.6277 - mean_squared_error: 63.6277 - val_loss: 109.7857 - val_mean_squared_error: 109.7857\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 63.0408 - mean_squared_error: 63.0408 - val_loss: 110.8945 - val_mean_squared_error: 110.8945\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 62.0569 - mean_squared_error: 62.0569 - val_loss: 103.0980 - val_mean_squared_error: 103.0980\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 58.6039 - mean_squared_error: 58.6039 - val_loss: 105.8301 - val_mean_squared_error: 105.8301\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 57.3113 - mean_squared_error: 57.3113 - val_loss: 106.3781 - val_mean_squared_error: 106.3781\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 54.6149 - mean_squared_error: 54.6149 - val_loss: 99.8988 - val_mean_squared_error: 99.8988\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 54.1911 - mean_squared_error: 54.1911 - val_loss: 106.0713 - val_mean_squared_error: 106.0713\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 52.8823 - mean_squared_error: 52.8823 - val_loss: 102.6912 - val_mean_squared_error: 102.6912\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 51.5404 - mean_squared_error: 51.5404 - val_loss: 112.5042 - val_mean_squared_error: 112.5042\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 47.6201 - mean_squared_error: 47.6201 - val_loss: 101.2820 - val_mean_squared_error: 101.2820\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 46.6560 - mean_squared_error: 46.6560 - val_loss: 105.7755 - val_mean_squared_error: 105.7755\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 43.7635 - mean_squared_error: 43.7635 - val_loss: 102.1971 - val_mean_squared_error: 102.1971\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 40.8623 - mean_squared_error: 40.8623 - val_loss: 109.3684 - val_mean_squared_error: 109.3684\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 40.1399 - mean_squared_error: 40.1399 - val_loss: 110.1780 - val_mean_squared_error: 110.1780\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 37.1075 - mean_squared_error: 37.1075 - val_loss: 106.5765 - val_mean_squared_error: 106.5765\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 36.7774 - mean_squared_error: 36.7774 - val_loss: 102.8868 - val_mean_squared_error: 102.8868\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "RMSE: 9.994938130428578\n",
            "\n",
            "Training with learning rate=0.001, optimizer=adam, dropout_rate=0.0, epochs=150\n",
            "Epoch 1/150\n",
            "165/165 [==============================] - 2s 4ms/step - loss: 1698.2106 - mean_squared_error: 1698.2106 - val_loss: 198.5957 - val_mean_squared_error: 198.5957\n",
            "Epoch 2/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 137.0206 - mean_squared_error: 137.0206 - val_loss: 176.9883 - val_mean_squared_error: 176.9883\n",
            "Epoch 3/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 114.3343 - mean_squared_error: 114.3343 - val_loss: 153.6016 - val_mean_squared_error: 153.6016\n",
            "Epoch 4/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 101.5623 - mean_squared_error: 101.5623 - val_loss: 135.8216 - val_mean_squared_error: 135.8216\n",
            "Epoch 5/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 93.1918 - mean_squared_error: 93.1918 - val_loss: 127.8805 - val_mean_squared_error: 127.8805\n",
            "Epoch 6/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 87.1391 - mean_squared_error: 87.1391 - val_loss: 125.7818 - val_mean_squared_error: 125.7818\n",
            "Epoch 7/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 82.8672 - mean_squared_error: 82.8672 - val_loss: 126.7954 - val_mean_squared_error: 126.7954\n",
            "Epoch 8/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 80.3966 - mean_squared_error: 80.3966 - val_loss: 125.0875 - val_mean_squared_error: 125.0875\n",
            "Epoch 9/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 78.5232 - mean_squared_error: 78.5232 - val_loss: 116.7044 - val_mean_squared_error: 116.7044\n",
            "Epoch 10/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 75.2663 - mean_squared_error: 75.2663 - val_loss: 111.5890 - val_mean_squared_error: 111.5890\n",
            "Epoch 11/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 72.9865 - mean_squared_error: 72.9865 - val_loss: 112.2562 - val_mean_squared_error: 112.2562\n",
            "Epoch 12/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 69.4404 - mean_squared_error: 69.4404 - val_loss: 107.4353 - val_mean_squared_error: 107.4353\n",
            "Epoch 13/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 70.6312 - mean_squared_error: 70.6312 - val_loss: 122.0698 - val_mean_squared_error: 122.0698\n",
            "Epoch 14/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 64.9026 - mean_squared_error: 64.9026 - val_loss: 112.1100 - val_mean_squared_error: 112.1100\n",
            "Epoch 15/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 65.9091 - mean_squared_error: 65.9091 - val_loss: 106.2534 - val_mean_squared_error: 106.2534\n",
            "Epoch 16/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 63.6375 - mean_squared_error: 63.6375 - val_loss: 108.4454 - val_mean_squared_error: 108.4454\n",
            "Epoch 17/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 61.0656 - mean_squared_error: 61.0656 - val_loss: 106.1989 - val_mean_squared_error: 106.1989\n",
            "Epoch 18/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 59.5872 - mean_squared_error: 59.5872 - val_loss: 102.7261 - val_mean_squared_error: 102.7261\n",
            "Epoch 19/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 57.5511 - mean_squared_error: 57.5511 - val_loss: 107.3734 - val_mean_squared_error: 107.3734\n",
            "Epoch 20/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 55.9985 - mean_squared_error: 55.9985 - val_loss: 104.9543 - val_mean_squared_error: 104.9543\n",
            "Epoch 21/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 52.5968 - mean_squared_error: 52.5968 - val_loss: 99.6768 - val_mean_squared_error: 99.6768\n",
            "Epoch 22/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 52.4570 - mean_squared_error: 52.4570 - val_loss: 103.4987 - val_mean_squared_error: 103.4987\n",
            "Epoch 23/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 50.4759 - mean_squared_error: 50.4759 - val_loss: 105.4793 - val_mean_squared_error: 105.4793\n",
            "Epoch 24/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 47.8720 - mean_squared_error: 47.8720 - val_loss: 101.1688 - val_mean_squared_error: 101.1688\n",
            "Epoch 25/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 45.9709 - mean_squared_error: 45.9709 - val_loss: 103.9162 - val_mean_squared_error: 103.9162\n",
            "Epoch 26/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 44.4002 - mean_squared_error: 44.4002 - val_loss: 104.4199 - val_mean_squared_error: 104.4199\n",
            "Epoch 27/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 45.6474 - mean_squared_error: 45.6474 - val_loss: 106.5759 - val_mean_squared_error: 106.5759\n",
            "Epoch 28/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 42.8842 - mean_squared_error: 42.8842 - val_loss: 105.1275 - val_mean_squared_error: 105.1275\n",
            "Epoch 29/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 40.4523 - mean_squared_error: 40.4523 - val_loss: 111.4854 - val_mean_squared_error: 111.4854\n",
            "Epoch 30/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 41.0232 - mean_squared_error: 41.0232 - val_loss: 108.4754 - val_mean_squared_error: 108.4754\n",
            "Epoch 31/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 38.9730 - mean_squared_error: 38.9730 - val_loss: 112.2210 - val_mean_squared_error: 112.2210\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 9.983825299864028\n",
            "\n",
            "Training with learning rate=0.001, optimizer=adam, dropout_rate=0.2, epochs=50\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 2s 4ms/step - loss: 2412.9009 - mean_squared_error: 2412.9009 - val_loss: 214.3308 - val_mean_squared_error: 214.3308\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 357.4722 - mean_squared_error: 357.4722 - val_loss: 177.9733 - val_mean_squared_error: 177.9733\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 310.3935 - mean_squared_error: 310.3935 - val_loss: 186.8744 - val_mean_squared_error: 186.8744\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 286.8457 - mean_squared_error: 286.8457 - val_loss: 147.4026 - val_mean_squared_error: 147.4026\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 281.4614 - mean_squared_error: 281.4614 - val_loss: 150.3978 - val_mean_squared_error: 150.3978\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 264.7962 - mean_squared_error: 264.7962 - val_loss: 137.5622 - val_mean_squared_error: 137.5622\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 252.5813 - mean_squared_error: 252.5813 - val_loss: 138.1004 - val_mean_squared_error: 138.1004\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 256.0561 - mean_squared_error: 256.0561 - val_loss: 132.1496 - val_mean_squared_error: 132.1496\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 260.5184 - mean_squared_error: 260.5184 - val_loss: 139.4629 - val_mean_squared_error: 139.4629\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 254.9590 - mean_squared_error: 254.9590 - val_loss: 129.0726 - val_mean_squared_error: 129.0726\n",
            "Epoch 11/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 233.4688 - mean_squared_error: 233.4688 - val_loss: 127.0936 - val_mean_squared_error: 127.0936\n",
            "Epoch 12/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 242.1074 - mean_squared_error: 242.1074 - val_loss: 122.0069 - val_mean_squared_error: 122.0069\n",
            "Epoch 13/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 239.6447 - mean_squared_error: 239.6447 - val_loss: 114.4798 - val_mean_squared_error: 114.4798\n",
            "Epoch 14/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 233.9746 - mean_squared_error: 233.9746 - val_loss: 117.7990 - val_mean_squared_error: 117.7990\n",
            "Epoch 15/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 241.1344 - mean_squared_error: 241.1344 - val_loss: 120.2646 - val_mean_squared_error: 120.2646\n",
            "Epoch 16/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 236.3577 - mean_squared_error: 236.3577 - val_loss: 123.6012 - val_mean_squared_error: 123.6012\n",
            "Epoch 17/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 234.6334 - mean_squared_error: 234.6334 - val_loss: 131.5524 - val_mean_squared_error: 131.5524\n",
            "Epoch 18/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 227.2770 - mean_squared_error: 227.2770 - val_loss: 119.6295 - val_mean_squared_error: 119.6295\n",
            "Epoch 19/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 221.1986 - mean_squared_error: 221.1986 - val_loss: 127.4524 - val_mean_squared_error: 127.4524\n",
            "Epoch 20/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 228.9859 - mean_squared_error: 228.9859 - val_loss: 119.2345 - val_mean_squared_error: 119.2345\n",
            "Epoch 21/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 206.1459 - mean_squared_error: 206.1459 - val_loss: 128.4796 - val_mean_squared_error: 128.4796\n",
            "Epoch 22/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 226.2793 - mean_squared_error: 226.2793 - val_loss: 129.4520 - val_mean_squared_error: 129.4520\n",
            "Epoch 23/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 222.0288 - mean_squared_error: 222.0288 - val_loss: 123.0525 - val_mean_squared_error: 123.0525\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 10.699524303420757\n",
            "\n",
            "Training with learning rate=0.001, optimizer=adam, dropout_rate=0.2, epochs=100\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 2s 4ms/step - loss: 2101.5334 - mean_squared_error: 2101.5334 - val_loss: 223.6457 - val_mean_squared_error: 223.6457\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 337.9548 - mean_squared_error: 337.9548 - val_loss: 191.2422 - val_mean_squared_error: 191.2422\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 306.8738 - mean_squared_error: 306.8738 - val_loss: 166.6992 - val_mean_squared_error: 166.6992\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 288.5155 - mean_squared_error: 288.5155 - val_loss: 156.2891 - val_mean_squared_error: 156.2891\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 270.3641 - mean_squared_error: 270.3641 - val_loss: 144.4729 - val_mean_squared_error: 144.4729\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 264.2281 - mean_squared_error: 264.2281 - val_loss: 142.4639 - val_mean_squared_error: 142.4639\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 248.5555 - mean_squared_error: 248.5555 - val_loss: 136.0020 - val_mean_squared_error: 136.0020\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 265.4107 - mean_squared_error: 265.4107 - val_loss: 128.6725 - val_mean_squared_error: 128.6725\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 242.3529 - mean_squared_error: 242.3529 - val_loss: 133.0609 - val_mean_squared_error: 133.0609\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 251.5894 - mean_squared_error: 251.5894 - val_loss: 146.6501 - val_mean_squared_error: 146.6501\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 220.2726 - mean_squared_error: 220.2726 - val_loss: 125.8850 - val_mean_squared_error: 125.8850\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 223.5755 - mean_squared_error: 223.5755 - val_loss: 129.8853 - val_mean_squared_error: 129.8853\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 244.3821 - mean_squared_error: 244.3821 - val_loss: 120.0613 - val_mean_squared_error: 120.0613\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 238.4214 - mean_squared_error: 238.4214 - val_loss: 147.3724 - val_mean_squared_error: 147.3724\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 222.7349 - mean_squared_error: 222.7349 - val_loss: 117.5503 - val_mean_squared_error: 117.5503\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 224.8477 - mean_squared_error: 224.8477 - val_loss: 138.9578 - val_mean_squared_error: 138.9578\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 225.6494 - mean_squared_error: 225.6494 - val_loss: 110.6917 - val_mean_squared_error: 110.6917\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 213.9218 - mean_squared_error: 213.9218 - val_loss: 139.0862 - val_mean_squared_error: 139.0862\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 231.2784 - mean_squared_error: 231.2784 - val_loss: 115.5039 - val_mean_squared_error: 115.5039\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 214.2475 - mean_squared_error: 214.2475 - val_loss: 111.0356 - val_mean_squared_error: 111.0356\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 206.5853 - mean_squared_error: 206.5853 - val_loss: 110.9970 - val_mean_squared_error: 110.9970\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 213.1754 - mean_squared_error: 213.1754 - val_loss: 110.0131 - val_mean_squared_error: 110.0131\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 218.9767 - mean_squared_error: 218.9767 - val_loss: 109.2945 - val_mean_squared_error: 109.2945\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 207.2442 - mean_squared_error: 207.2443 - val_loss: 110.4062 - val_mean_squared_error: 110.4062\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 221.0375 - mean_squared_error: 221.0375 - val_loss: 117.4563 - val_mean_squared_error: 117.4563\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 218.7271 - mean_squared_error: 218.7271 - val_loss: 107.5613 - val_mean_squared_error: 107.5613\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 217.9367 - mean_squared_error: 217.9367 - val_loss: 144.0091 - val_mean_squared_error: 144.0091\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 218.5090 - mean_squared_error: 218.5090 - val_loss: 120.1835 - val_mean_squared_error: 120.1835\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 194.6308 - mean_squared_error: 194.6308 - val_loss: 116.9311 - val_mean_squared_error: 116.9311\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 205.8607 - mean_squared_error: 205.8607 - val_loss: 146.9243 - val_mean_squared_error: 146.9243\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 213.0231 - mean_squared_error: 213.0231 - val_loss: 116.7575 - val_mean_squared_error: 116.7575\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 208.2048 - mean_squared_error: 208.2048 - val_loss: 121.7623 - val_mean_squared_error: 121.7623\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 197.6887 - mean_squared_error: 197.6887 - val_loss: 111.5689 - val_mean_squared_error: 111.5689\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 212.8855 - mean_squared_error: 212.8855 - val_loss: 108.6091 - val_mean_squared_error: 108.6091\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 199.9276 - mean_squared_error: 199.9276 - val_loss: 101.0389 - val_mean_squared_error: 101.0389\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 198.5360 - mean_squared_error: 198.5360 - val_loss: 116.3849 - val_mean_squared_error: 116.3849\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 202.2179 - mean_squared_error: 202.2179 - val_loss: 109.5751 - val_mean_squared_error: 109.5751\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 197.4388 - mean_squared_error: 197.4388 - val_loss: 110.5629 - val_mean_squared_error: 110.5629\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 202.3048 - mean_squared_error: 202.3048 - val_loss: 106.6015 - val_mean_squared_error: 106.6015\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 188.2429 - mean_squared_error: 188.2429 - val_loss: 102.5049 - val_mean_squared_error: 102.5049\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 203.2983 - mean_squared_error: 203.2983 - val_loss: 105.9496 - val_mean_squared_error: 105.9496\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 199.6295 - mean_squared_error: 199.6295 - val_loss: 101.3276 - val_mean_squared_error: 101.3276\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 192.8418 - mean_squared_error: 192.8418 - val_loss: 101.0801 - val_mean_squared_error: 101.0801\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 190.9565 - mean_squared_error: 190.9565 - val_loss: 105.0404 - val_mean_squared_error: 105.0404\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 204.1305 - mean_squared_error: 204.1305 - val_loss: 106.2364 - val_mean_squared_error: 106.2364\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 10.0518133042595\n",
            "\n",
            "Training with learning rate=0.001, optimizer=adam, dropout_rate=0.2, epochs=150\n",
            "Epoch 1/150\n",
            "165/165 [==============================] - 2s 4ms/step - loss: 2500.8584 - mean_squared_error: 2500.8584 - val_loss: 224.0603 - val_mean_squared_error: 224.0603\n",
            "Epoch 2/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 375.0589 - mean_squared_error: 375.0589 - val_loss: 178.9093 - val_mean_squared_error: 178.9093\n",
            "Epoch 3/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 325.7995 - mean_squared_error: 325.7995 - val_loss: 155.7173 - val_mean_squared_error: 155.7173\n",
            "Epoch 4/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 320.1544 - mean_squared_error: 320.1544 - val_loss: 159.8396 - val_mean_squared_error: 159.8396\n",
            "Epoch 5/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 311.2310 - mean_squared_error: 311.2310 - val_loss: 149.7555 - val_mean_squared_error: 149.7555\n",
            "Epoch 6/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 288.7173 - mean_squared_error: 288.7173 - val_loss: 146.8500 - val_mean_squared_error: 146.8500\n",
            "Epoch 7/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 285.1022 - mean_squared_error: 285.1022 - val_loss: 139.1839 - val_mean_squared_error: 139.1839\n",
            "Epoch 8/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 278.2426 - mean_squared_error: 278.2426 - val_loss: 133.3941 - val_mean_squared_error: 133.3941\n",
            "Epoch 9/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 284.2761 - mean_squared_error: 284.2761 - val_loss: 133.5955 - val_mean_squared_error: 133.5955\n",
            "Epoch 10/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 278.0288 - mean_squared_error: 278.0287 - val_loss: 135.2723 - val_mean_squared_error: 135.2723\n",
            "Epoch 11/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 247.6101 - mean_squared_error: 247.6101 - val_loss: 126.6094 - val_mean_squared_error: 126.6094\n",
            "Epoch 12/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 260.8041 - mean_squared_error: 260.8041 - val_loss: 122.9439 - val_mean_squared_error: 122.9439\n",
            "Epoch 13/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 256.2943 - mean_squared_error: 256.2943 - val_loss: 146.9680 - val_mean_squared_error: 146.9680\n",
            "Epoch 14/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 245.4473 - mean_squared_error: 245.4473 - val_loss: 124.9411 - val_mean_squared_error: 124.9411\n",
            "Epoch 15/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 248.1470 - mean_squared_error: 248.1470 - val_loss: 133.6942 - val_mean_squared_error: 133.6942\n",
            "Epoch 16/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 252.0280 - mean_squared_error: 252.0280 - val_loss: 131.1367 - val_mean_squared_error: 131.1367\n",
            "Epoch 17/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 250.2973 - mean_squared_error: 250.2973 - val_loss: 121.6322 - val_mean_squared_error: 121.6322\n",
            "Epoch 18/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 248.9049 - mean_squared_error: 248.9049 - val_loss: 114.9599 - val_mean_squared_error: 114.9599\n",
            "Epoch 19/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 237.9736 - mean_squared_error: 237.9736 - val_loss: 110.4123 - val_mean_squared_error: 110.4123\n",
            "Epoch 20/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 253.8203 - mean_squared_error: 253.8203 - val_loss: 114.2466 - val_mean_squared_error: 114.2466\n",
            "Epoch 21/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 229.1825 - mean_squared_error: 229.1825 - val_loss: 162.7477 - val_mean_squared_error: 162.7477\n",
            "Epoch 22/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 249.5868 - mean_squared_error: 249.5868 - val_loss: 113.5132 - val_mean_squared_error: 113.5132\n",
            "Epoch 23/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 225.1249 - mean_squared_error: 225.1249 - val_loss: 118.3227 - val_mean_squared_error: 118.3227\n",
            "Epoch 24/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 239.8194 - mean_squared_error: 239.8194 - val_loss: 107.9933 - val_mean_squared_error: 107.9933\n",
            "Epoch 25/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 231.9902 - mean_squared_error: 231.9902 - val_loss: 107.2150 - val_mean_squared_error: 107.2150\n",
            "Epoch 26/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 232.3956 - mean_squared_error: 232.3956 - val_loss: 108.1840 - val_mean_squared_error: 108.1840\n",
            "Epoch 27/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 239.5739 - mean_squared_error: 239.5739 - val_loss: 115.4344 - val_mean_squared_error: 115.4344\n",
            "Epoch 28/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 221.9552 - mean_squared_error: 221.9552 - val_loss: 110.2358 - val_mean_squared_error: 110.2358\n",
            "Epoch 29/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 235.4733 - mean_squared_error: 235.4733 - val_loss: 116.7553 - val_mean_squared_error: 116.7553\n",
            "Epoch 30/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 236.5807 - mean_squared_error: 236.5807 - val_loss: 111.1553 - val_mean_squared_error: 111.1553\n",
            "Epoch 31/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 233.0793 - mean_squared_error: 233.0793 - val_loss: 114.7000 - val_mean_squared_error: 114.7000\n",
            "Epoch 32/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 224.1006 - mean_squared_error: 224.1006 - val_loss: 114.9147 - val_mean_squared_error: 114.9147\n",
            "Epoch 33/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 225.9514 - mean_squared_error: 225.9514 - val_loss: 118.6512 - val_mean_squared_error: 118.6512\n",
            "Epoch 34/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 234.1030 - mean_squared_error: 234.1030 - val_loss: 117.7870 - val_mean_squared_error: 117.7870\n",
            "Epoch 35/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 220.6655 - mean_squared_error: 220.6655 - val_loss: 115.1933 - val_mean_squared_error: 115.1933\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 10.354469603833957\n",
            "\n",
            "Training with learning rate=0.001, optimizer=adam, dropout_rate=0.5, epochs=50\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 2s 4ms/step - loss: 3589.4053 - mean_squared_error: 3589.4053 - val_loss: 354.3199 - val_mean_squared_error: 354.3199\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 960.0133 - mean_squared_error: 960.0133 - val_loss: 304.9187 - val_mean_squared_error: 304.9187\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 834.4301 - mean_squared_error: 834.4301 - val_loss: 214.1990 - val_mean_squared_error: 214.1990\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 805.2026 - mean_squared_error: 805.2026 - val_loss: 210.4646 - val_mean_squared_error: 210.4646\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 729.9716 - mean_squared_error: 729.9716 - val_loss: 224.4522 - val_mean_squared_error: 224.4522\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 728.6589 - mean_squared_error: 728.6589 - val_loss: 255.6539 - val_mean_squared_error: 255.6539\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 708.3664 - mean_squared_error: 708.3664 - val_loss: 171.5768 - val_mean_squared_error: 171.5768\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 715.5742 - mean_squared_error: 715.5742 - val_loss: 201.9111 - val_mean_squared_error: 201.9111\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 713.6257 - mean_squared_error: 713.6257 - val_loss: 258.5231 - val_mean_squared_error: 258.5231\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 676.2453 - mean_squared_error: 676.2453 - val_loss: 218.1763 - val_mean_squared_error: 218.1763\n",
            "Epoch 11/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 669.8382 - mean_squared_error: 669.8382 - val_loss: 177.9573 - val_mean_squared_error: 177.9573\n",
            "Epoch 12/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 709.5342 - mean_squared_error: 709.5342 - val_loss: 248.5440 - val_mean_squared_error: 248.5440\n",
            "Epoch 13/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 653.4103 - mean_squared_error: 653.4103 - val_loss: 150.0006 - val_mean_squared_error: 150.0006\n",
            "Epoch 14/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 642.7172 - mean_squared_error: 642.7172 - val_loss: 256.6069 - val_mean_squared_error: 256.6069\n",
            "Epoch 15/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 670.8856 - mean_squared_error: 670.8856 - val_loss: 140.8013 - val_mean_squared_error: 140.8013\n",
            "Epoch 16/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 659.5299 - mean_squared_error: 659.5299 - val_loss: 170.7034 - val_mean_squared_error: 170.7033\n",
            "Epoch 17/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 649.5607 - mean_squared_error: 649.5607 - val_loss: 229.7210 - val_mean_squared_error: 229.7210\n",
            "Epoch 18/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 648.6536 - mean_squared_error: 648.6537 - val_loss: 201.5325 - val_mean_squared_error: 201.5325\n",
            "Epoch 19/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 642.0798 - mean_squared_error: 642.0798 - val_loss: 150.4076 - val_mean_squared_error: 150.4076\n",
            "Epoch 20/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 626.6131 - mean_squared_error: 626.6131 - val_loss: 159.0581 - val_mean_squared_error: 159.0581\n",
            "Epoch 21/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 654.7512 - mean_squared_error: 654.7512 - val_loss: 197.0302 - val_mean_squared_error: 197.0302\n",
            "Epoch 22/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 617.2482 - mean_squared_error: 617.2482 - val_loss: 180.2260 - val_mean_squared_error: 180.2260\n",
            "Epoch 23/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 608.8514 - mean_squared_error: 608.8515 - val_loss: 195.9762 - val_mean_squared_error: 195.9762\n",
            "Epoch 24/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 612.4090 - mean_squared_error: 612.4090 - val_loss: 198.6798 - val_mean_squared_error: 198.6798\n",
            "Epoch 25/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 653.7348 - mean_squared_error: 653.7349 - val_loss: 139.1750 - val_mean_squared_error: 139.1750\n",
            "Epoch 26/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 596.3807 - mean_squared_error: 596.3807 - val_loss: 231.9143 - val_mean_squared_error: 231.9143\n",
            "Epoch 27/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 593.2687 - mean_squared_error: 593.2687 - val_loss: 151.6437 - val_mean_squared_error: 151.6437\n",
            "Epoch 28/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 589.9163 - mean_squared_error: 589.9163 - val_loss: 133.9006 - val_mean_squared_error: 133.9006\n",
            "Epoch 29/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 559.2542 - mean_squared_error: 559.2542 - val_loss: 218.8715 - val_mean_squared_error: 218.8715\n",
            "Epoch 30/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 575.6478 - mean_squared_error: 575.6478 - val_loss: 150.9229 - val_mean_squared_error: 150.9229\n",
            "Epoch 31/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 575.9365 - mean_squared_error: 575.9365 - val_loss: 153.8545 - val_mean_squared_error: 153.8545\n",
            "Epoch 32/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 592.3942 - mean_squared_error: 592.3942 - val_loss: 166.1125 - val_mean_squared_error: 166.1125\n",
            "Epoch 33/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 580.3442 - mean_squared_error: 580.3442 - val_loss: 115.3887 - val_mean_squared_error: 115.3887\n",
            "Epoch 34/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 574.4114 - mean_squared_error: 574.4114 - val_loss: 169.8493 - val_mean_squared_error: 169.8493\n",
            "Epoch 35/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 569.6003 - mean_squared_error: 569.6003 - val_loss: 155.9550 - val_mean_squared_error: 155.9550\n",
            "Epoch 36/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 572.9340 - mean_squared_error: 572.9340 - val_loss: 178.0603 - val_mean_squared_error: 178.0603\n",
            "Epoch 37/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 592.7886 - mean_squared_error: 592.7886 - val_loss: 130.7345 - val_mean_squared_error: 130.7345\n",
            "Epoch 38/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 538.5528 - mean_squared_error: 538.5528 - val_loss: 141.7892 - val_mean_squared_error: 141.7892\n",
            "Epoch 39/50\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 575.4890 - mean_squared_error: 575.4890 - val_loss: 150.9362 - val_mean_squared_error: 150.9362\n",
            "Epoch 40/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 534.8292 - mean_squared_error: 534.8292 - val_loss: 157.6787 - val_mean_squared_error: 157.6787\n",
            "Epoch 41/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 530.1708 - mean_squared_error: 530.1708 - val_loss: 147.7858 - val_mean_squared_error: 147.7858\n",
            "Epoch 42/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 566.6430 - mean_squared_error: 566.6430 - val_loss: 137.8195 - val_mean_squared_error: 137.8195\n",
            "Epoch 43/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 530.7281 - mean_squared_error: 530.7281 - val_loss: 147.8898 - val_mean_squared_error: 147.8898\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 10.741914846225502\n",
            "\n",
            "Training with learning rate=0.001, optimizer=adam, dropout_rate=0.5, epochs=100\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 3831.6169 - mean_squared_error: 3831.6169 - val_loss: 416.2182 - val_mean_squared_error: 416.2182\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 880.2222 - mean_squared_error: 880.2222 - val_loss: 336.1341 - val_mean_squared_error: 336.1341\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 828.2790 - mean_squared_error: 828.2790 - val_loss: 263.2119 - val_mean_squared_error: 263.2119\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 786.2874 - mean_squared_error: 786.2874 - val_loss: 201.1418 - val_mean_squared_error: 201.1418\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 807.1251 - mean_squared_error: 807.1252 - val_loss: 177.8806 - val_mean_squared_error: 177.8806\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 767.4896 - mean_squared_error: 767.4896 - val_loss: 261.6721 - val_mean_squared_error: 261.6721\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 721.1298 - mean_squared_error: 721.1298 - val_loss: 183.5753 - val_mean_squared_error: 183.5753\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 746.4265 - mean_squared_error: 746.4265 - val_loss: 172.8266 - val_mean_squared_error: 172.8266\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 699.1700 - mean_squared_error: 699.1700 - val_loss: 223.3671 - val_mean_squared_error: 223.3671\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 713.1368 - mean_squared_error: 713.1367 - val_loss: 213.8204 - val_mean_squared_error: 213.8204\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 723.9833 - mean_squared_error: 723.9833 - val_loss: 183.7069 - val_mean_squared_error: 183.7069\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 665.8865 - mean_squared_error: 665.8865 - val_loss: 169.3427 - val_mean_squared_error: 169.3427\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 653.3893 - mean_squared_error: 653.3893 - val_loss: 171.8340 - val_mean_squared_error: 171.8340\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 659.8285 - mean_squared_error: 659.8286 - val_loss: 174.5212 - val_mean_squared_error: 174.5212\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 675.2491 - mean_squared_error: 675.2491 - val_loss: 186.9754 - val_mean_squared_error: 186.9754\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 646.9862 - mean_squared_error: 646.9862 - val_loss: 191.6331 - val_mean_squared_error: 191.6331\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 678.1863 - mean_squared_error: 678.1864 - val_loss: 147.1012 - val_mean_squared_error: 147.1012\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 658.6477 - mean_squared_error: 658.6477 - val_loss: 163.3717 - val_mean_squared_error: 163.3717\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 599.0223 - mean_squared_error: 599.0223 - val_loss: 147.6560 - val_mean_squared_error: 147.6560\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 659.8294 - mean_squared_error: 659.8294 - val_loss: 149.2446 - val_mean_squared_error: 149.2446\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 617.4304 - mean_squared_error: 617.4304 - val_loss: 150.7378 - val_mean_squared_error: 150.7378\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 660.4626 - mean_squared_error: 660.4626 - val_loss: 175.2988 - val_mean_squared_error: 175.2988\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 588.4708 - mean_squared_error: 588.4708 - val_loss: 129.9291 - val_mean_squared_error: 129.9291\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 601.3213 - mean_squared_error: 601.3213 - val_loss: 160.7909 - val_mean_squared_error: 160.7909\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 626.2636 - mean_squared_error: 626.2636 - val_loss: 180.9039 - val_mean_squared_error: 180.9039\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 600.9321 - mean_squared_error: 600.9321 - val_loss: 166.4201 - val_mean_squared_error: 166.4201\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 604.4813 - mean_squared_error: 604.4813 - val_loss: 182.4529 - val_mean_squared_error: 182.4529\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 607.1420 - mean_squared_error: 607.1420 - val_loss: 159.6237 - val_mean_squared_error: 159.6237\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 562.0742 - mean_squared_error: 562.0742 - val_loss: 160.5598 - val_mean_squared_error: 160.5598\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 597.2592 - mean_squared_error: 597.2592 - val_loss: 158.2591 - val_mean_squared_error: 158.2591\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 566.2400 - mean_squared_error: 566.2400 - val_loss: 156.9648 - val_mean_squared_error: 156.9648\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 545.9431 - mean_squared_error: 545.9431 - val_loss: 156.5428 - val_mean_squared_error: 156.5428\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 583.4965 - mean_squared_error: 583.4965 - val_loss: 162.7709 - val_mean_squared_error: 162.7708\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 11.398643567379812\n",
            "\n",
            "Training with learning rate=0.001, optimizer=adam, dropout_rate=0.5, epochs=150\n",
            "Epoch 1/150\n",
            "165/165 [==============================] - 2s 9ms/step - loss: 3636.5840 - mean_squared_error: 3636.5840 - val_loss: 363.4781 - val_mean_squared_error: 363.4781\n",
            "Epoch 2/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 889.6879 - mean_squared_error: 889.6879 - val_loss: 341.2520 - val_mean_squared_error: 341.2520\n",
            "Epoch 3/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 825.1968 - mean_squared_error: 825.1967 - val_loss: 306.9743 - val_mean_squared_error: 306.9743\n",
            "Epoch 4/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 796.5666 - mean_squared_error: 796.5666 - val_loss: 308.4671 - val_mean_squared_error: 308.4671\n",
            "Epoch 5/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 811.8227 - mean_squared_error: 811.8227 - val_loss: 231.0547 - val_mean_squared_error: 231.0547\n",
            "Epoch 6/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 775.9052 - mean_squared_error: 775.9052 - val_loss: 195.2360 - val_mean_squared_error: 195.2360\n",
            "Epoch 7/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 732.0848 - mean_squared_error: 732.0848 - val_loss: 186.9113 - val_mean_squared_error: 186.9113\n",
            "Epoch 8/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 761.0197 - mean_squared_error: 761.0197 - val_loss: 286.7979 - val_mean_squared_error: 286.7979\n",
            "Epoch 9/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 708.8670 - mean_squared_error: 708.8670 - val_loss: 188.2767 - val_mean_squared_error: 188.2767\n",
            "Epoch 10/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 769.8444 - mean_squared_error: 769.8444 - val_loss: 211.3132 - val_mean_squared_error: 211.3132\n",
            "Epoch 11/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 732.8600 - mean_squared_error: 732.8600 - val_loss: 208.6974 - val_mean_squared_error: 208.6974\n",
            "Epoch 12/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 736.4875 - mean_squared_error: 736.4875 - val_loss: 202.0584 - val_mean_squared_error: 202.0584\n",
            "Epoch 13/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 703.3810 - mean_squared_error: 703.3810 - val_loss: 212.5318 - val_mean_squared_error: 212.5318\n",
            "Epoch 14/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 687.2965 - mean_squared_error: 687.2965 - val_loss: 182.9014 - val_mean_squared_error: 182.9014\n",
            "Epoch 15/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 657.1631 - mean_squared_error: 657.1631 - val_loss: 209.0363 - val_mean_squared_error: 209.0363\n",
            "Epoch 16/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 682.8503 - mean_squared_error: 682.8503 - val_loss: 164.6832 - val_mean_squared_error: 164.6832\n",
            "Epoch 17/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 719.8452 - mean_squared_error: 719.8452 - val_loss: 211.2182 - val_mean_squared_error: 211.2182\n",
            "Epoch 18/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 714.7587 - mean_squared_error: 714.7587 - val_loss: 139.9575 - val_mean_squared_error: 139.9575\n",
            "Epoch 19/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 702.8986 - mean_squared_error: 702.8986 - val_loss: 205.3346 - val_mean_squared_error: 205.3346\n",
            "Epoch 20/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 664.2599 - mean_squared_error: 664.2599 - val_loss: 150.5252 - val_mean_squared_error: 150.5252\n",
            "Epoch 21/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 694.2833 - mean_squared_error: 694.2833 - val_loss: 156.8827 - val_mean_squared_error: 156.8827\n",
            "Epoch 22/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 641.5443 - mean_squared_error: 641.5443 - val_loss: 188.6846 - val_mean_squared_error: 188.6846\n",
            "Epoch 23/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 620.3558 - mean_squared_error: 620.3558 - val_loss: 153.3587 - val_mean_squared_error: 153.3587\n",
            "Epoch 24/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 674.8423 - mean_squared_error: 674.8423 - val_loss: 162.5810 - val_mean_squared_error: 162.5810\n",
            "Epoch 25/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 621.6011 - mean_squared_error: 621.6011 - val_loss: 167.2436 - val_mean_squared_error: 167.2436\n",
            "Epoch 26/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 654.8489 - mean_squared_error: 654.8489 - val_loss: 162.7272 - val_mean_squared_error: 162.7272\n",
            "Epoch 27/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 635.9675 - mean_squared_error: 635.9675 - val_loss: 190.6529 - val_mean_squared_error: 190.6529\n",
            "Epoch 28/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 647.8950 - mean_squared_error: 647.8950 - val_loss: 202.1719 - val_mean_squared_error: 202.1719\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 11.830363096729624\n",
            "\n",
            "Training with learning rate=0.001, optimizer=sgd, dropout_rate=0.0, epochs=50\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.001, optimizer=sgd, dropout_rate=0.0, epochs=50\n",
            "Training with learning rate=0.001, optimizer=sgd, dropout_rate=0.0, epochs=100\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.001, optimizer=sgd, dropout_rate=0.0, epochs=100\n",
            "Training with learning rate=0.001, optimizer=sgd, dropout_rate=0.0, epochs=150\n",
            "Epoch 1/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.001, optimizer=sgd, dropout_rate=0.0, epochs=150\n",
            "Training with learning rate=0.001, optimizer=sgd, dropout_rate=0.2, epochs=50\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.001, optimizer=sgd, dropout_rate=0.2, epochs=50\n",
            "Training with learning rate=0.001, optimizer=sgd, dropout_rate=0.2, epochs=100\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.001, optimizer=sgd, dropout_rate=0.2, epochs=100\n",
            "Training with learning rate=0.001, optimizer=sgd, dropout_rate=0.2, epochs=150\n",
            "Epoch 1/150\n",
            "165/165 [==============================] - 2s 5ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.001, optimizer=sgd, dropout_rate=0.2, epochs=150\n",
            "Training with learning rate=0.001, optimizer=sgd, dropout_rate=0.5, epochs=50\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.001, optimizer=sgd, dropout_rate=0.5, epochs=50\n",
            "Training with learning rate=0.001, optimizer=sgd, dropout_rate=0.5, epochs=100\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 2s 5ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.001, optimizer=sgd, dropout_rate=0.5, epochs=100\n",
            "Training with learning rate=0.001, optimizer=sgd, dropout_rate=0.5, epochs=150\n",
            "Epoch 1/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/150\n",
            "165/165 [==============================] - 0s 2ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.001, optimizer=sgd, dropout_rate=0.5, epochs=150\n",
            "Training with learning rate=0.01, optimizer=adam, dropout_rate=0.0, epochs=50\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 2s 3ms/step - loss: 2088.1279 - mean_squared_error: 2088.1279 - val_loss: 196.7952 - val_mean_squared_error: 196.7952\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 139.7157 - mean_squared_error: 139.7157 - val_loss: 163.0114 - val_mean_squared_error: 163.0114\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 115.8812 - mean_squared_error: 115.8812 - val_loss: 143.7145 - val_mean_squared_error: 143.7145\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 102.1001 - mean_squared_error: 102.1001 - val_loss: 141.9510 - val_mean_squared_error: 141.9510\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 95.9768 - mean_squared_error: 95.9768 - val_loss: 126.8859 - val_mean_squared_error: 126.8859\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 87.9180 - mean_squared_error: 87.9180 - val_loss: 120.9737 - val_mean_squared_error: 120.9737\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 84.1469 - mean_squared_error: 84.1469 - val_loss: 120.0955 - val_mean_squared_error: 120.0955\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 81.1845 - mean_squared_error: 81.1845 - val_loss: 115.7938 - val_mean_squared_error: 115.7938\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 79.1935 - mean_squared_error: 79.1935 - val_loss: 114.1999 - val_mean_squared_error: 114.1999\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 75.1789 - mean_squared_error: 75.1789 - val_loss: 117.0461 - val_mean_squared_error: 117.0461\n",
            "Epoch 11/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 74.2217 - mean_squared_error: 74.2217 - val_loss: 111.7752 - val_mean_squared_error: 111.7752\n",
            "Epoch 12/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 70.8391 - mean_squared_error: 70.8391 - val_loss: 113.8923 - val_mean_squared_error: 113.8923\n",
            "Epoch 13/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 70.0061 - mean_squared_error: 70.0061 - val_loss: 112.9166 - val_mean_squared_error: 112.9166\n",
            "Epoch 14/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 68.4538 - mean_squared_error: 68.4538 - val_loss: 108.2201 - val_mean_squared_error: 108.2201\n",
            "Epoch 15/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 66.2644 - mean_squared_error: 66.2644 - val_loss: 109.2872 - val_mean_squared_error: 109.2872\n",
            "Epoch 16/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 65.5795 - mean_squared_error: 65.5795 - val_loss: 106.6930 - val_mean_squared_error: 106.6930\n",
            "Epoch 17/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 62.4051 - mean_squared_error: 62.4051 - val_loss: 109.3384 - val_mean_squared_error: 109.3384\n",
            "Epoch 18/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 60.6675 - mean_squared_error: 60.6675 - val_loss: 104.8549 - val_mean_squared_error: 104.8549\n",
            "Epoch 19/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 60.6054 - mean_squared_error: 60.6054 - val_loss: 114.0566 - val_mean_squared_error: 114.0566\n",
            "Epoch 20/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 61.1298 - mean_squared_error: 61.1298 - val_loss: 107.6564 - val_mean_squared_error: 107.6564\n",
            "Epoch 21/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 57.1591 - mean_squared_error: 57.1591 - val_loss: 111.8195 - val_mean_squared_error: 111.8195\n",
            "Epoch 22/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 55.2473 - mean_squared_error: 55.2473 - val_loss: 104.6900 - val_mean_squared_error: 104.6900\n",
            "Epoch 23/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 51.8396 - mean_squared_error: 51.8396 - val_loss: 109.2000 - val_mean_squared_error: 109.2000\n",
            "Epoch 24/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 50.8824 - mean_squared_error: 50.8824 - val_loss: 105.9578 - val_mean_squared_error: 105.9578\n",
            "Epoch 25/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 48.8786 - mean_squared_error: 48.8786 - val_loss: 108.8258 - val_mean_squared_error: 108.8258\n",
            "Epoch 26/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 48.0332 - mean_squared_error: 48.0332 - val_loss: 105.5955 - val_mean_squared_error: 105.5955\n",
            "Epoch 27/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 48.4715 - mean_squared_error: 48.4715 - val_loss: 109.6085 - val_mean_squared_error: 109.6085\n",
            "Epoch 28/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 45.3961 - mean_squared_error: 45.3961 - val_loss: 105.0285 - val_mean_squared_error: 105.0285\n",
            "Epoch 29/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 42.5555 - mean_squared_error: 42.5555 - val_loss: 109.9554 - val_mean_squared_error: 109.9553\n",
            "Epoch 30/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 42.4751 - mean_squared_error: 42.4751 - val_loss: 111.0450 - val_mean_squared_error: 111.0450\n",
            "Epoch 31/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 40.5407 - mean_squared_error: 40.5407 - val_loss: 103.8060 - val_mean_squared_error: 103.8060\n",
            "Epoch 32/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 38.6547 - mean_squared_error: 38.6547 - val_loss: 106.6968 - val_mean_squared_error: 106.6968\n",
            "Epoch 33/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 37.2751 - mean_squared_error: 37.2751 - val_loss: 108.1198 - val_mean_squared_error: 108.1198\n",
            "Epoch 34/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 38.8863 - mean_squared_error: 38.8863 - val_loss: 112.4367 - val_mean_squared_error: 112.4367\n",
            "Epoch 35/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 34.9830 - mean_squared_error: 34.9830 - val_loss: 112.5229 - val_mean_squared_error: 112.5229\n",
            "Epoch 36/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 35.4763 - mean_squared_error: 35.4763 - val_loss: 112.0132 - val_mean_squared_error: 112.0132\n",
            "Epoch 37/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 33.1441 - mean_squared_error: 33.1441 - val_loss: 109.4810 - val_mean_squared_error: 109.4810\n",
            "Epoch 38/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 31.2195 - mean_squared_error: 31.2195 - val_loss: 111.5089 - val_mean_squared_error: 111.5089\n",
            "Epoch 39/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 31.5894 - mean_squared_error: 31.5894 - val_loss: 111.6041 - val_mean_squared_error: 111.6041\n",
            "Epoch 40/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 29.8861 - mean_squared_error: 29.8861 - val_loss: 119.1060 - val_mean_squared_error: 119.1060\n",
            "Epoch 41/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 29.6604 - mean_squared_error: 29.6604 - val_loss: 117.3721 - val_mean_squared_error: 117.3721\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 10.188525580421269\n",
            "\n",
            "Training with learning rate=0.01, optimizer=adam, dropout_rate=0.0, epochs=100\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 1772.4695 - mean_squared_error: 1772.4695 - val_loss: 201.4965 - val_mean_squared_error: 201.4965\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 140.8120 - mean_squared_error: 140.8120 - val_loss: 156.7142 - val_mean_squared_error: 156.7142\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 115.6206 - mean_squared_error: 115.6206 - val_loss: 140.9454 - val_mean_squared_error: 140.9454\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 102.4112 - mean_squared_error: 102.4112 - val_loss: 131.6099 - val_mean_squared_error: 131.6099\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 93.9333 - mean_squared_error: 93.9333 - val_loss: 132.3115 - val_mean_squared_error: 132.3115\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 88.9045 - mean_squared_error: 88.9045 - val_loss: 125.6038 - val_mean_squared_error: 125.6038\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 85.3557 - mean_squared_error: 85.3557 - val_loss: 120.3923 - val_mean_squared_error: 120.3923\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 81.1328 - mean_squared_error: 81.1328 - val_loss: 117.9742 - val_mean_squared_error: 117.9742\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 79.2258 - mean_squared_error: 79.2258 - val_loss: 117.4159 - val_mean_squared_error: 117.4159\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 76.9973 - mean_squared_error: 76.9973 - val_loss: 114.7100 - val_mean_squared_error: 114.7100\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 73.9334 - mean_squared_error: 73.9334 - val_loss: 114.0723 - val_mean_squared_error: 114.0723\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 72.4992 - mean_squared_error: 72.4992 - val_loss: 113.3300 - val_mean_squared_error: 113.3300\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 69.4034 - mean_squared_error: 69.4034 - val_loss: 108.0903 - val_mean_squared_error: 108.0903\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 67.1213 - mean_squared_error: 67.1213 - val_loss: 110.0053 - val_mean_squared_error: 110.0053\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 64.7138 - mean_squared_error: 64.7138 - val_loss: 107.2868 - val_mean_squared_error: 107.2868\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 64.1740 - mean_squared_error: 64.1740 - val_loss: 116.6921 - val_mean_squared_error: 116.6921\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 62.1877 - mean_squared_error: 62.1877 - val_loss: 107.9354 - val_mean_squared_error: 107.9354\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 61.4821 - mean_squared_error: 61.4821 - val_loss: 110.0299 - val_mean_squared_error: 110.0299\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 58.2074 - mean_squared_error: 58.2074 - val_loss: 108.8778 - val_mean_squared_error: 108.8778\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 56.1105 - mean_squared_error: 56.1105 - val_loss: 106.1770 - val_mean_squared_error: 106.1770\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 55.1797 - mean_squared_error: 55.1797 - val_loss: 108.7101 - val_mean_squared_error: 108.7101\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 53.4304 - mean_squared_error: 53.4304 - val_loss: 106.5811 - val_mean_squared_error: 106.5811\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 54.1890 - mean_squared_error: 54.1890 - val_loss: 111.6684 - val_mean_squared_error: 111.6684\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 50.3605 - mean_squared_error: 50.3605 - val_loss: 106.9894 - val_mean_squared_error: 106.9894\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 48.3917 - mean_squared_error: 48.3917 - val_loss: 105.0033 - val_mean_squared_error: 105.0033\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 47.4813 - mean_squared_error: 47.4813 - val_loss: 102.7261 - val_mean_squared_error: 102.7261\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 45.1154 - mean_squared_error: 45.1154 - val_loss: 120.5852 - val_mean_squared_error: 120.5852\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 44.3266 - mean_squared_error: 44.3266 - val_loss: 108.5380 - val_mean_squared_error: 108.5380\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 42.0850 - mean_squared_error: 42.0850 - val_loss: 109.6670 - val_mean_squared_error: 109.6670\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 42.3598 - mean_squared_error: 42.3598 - val_loss: 112.5534 - val_mean_squared_error: 112.5534\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 40.1196 - mean_squared_error: 40.1196 - val_loss: 113.1719 - val_mean_squared_error: 113.1719\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 37.7570 - mean_squared_error: 37.7570 - val_loss: 106.8387 - val_mean_squared_error: 106.8387\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 35.9307 - mean_squared_error: 35.9307 - val_loss: 110.6478 - val_mean_squared_error: 110.6478\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 33.9367 - mean_squared_error: 33.9367 - val_loss: 108.1347 - val_mean_squared_error: 108.1347\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 34.2959 - mean_squared_error: 34.2959 - val_loss: 112.2541 - val_mean_squared_error: 112.2541\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 32.1792 - mean_squared_error: 32.1792 - val_loss: 116.0351 - val_mean_squared_error: 116.0351\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "RMSE: 10.135390870423665\n",
            "\n",
            "Training with learning rate=0.01, optimizer=adam, dropout_rate=0.0, epochs=150\n",
            "Epoch 1/150\n",
            "165/165 [==============================] - 2s 5ms/step - loss: 2221.7334 - mean_squared_error: 2221.7334 - val_loss: 204.5168 - val_mean_squared_error: 204.5168\n",
            "Epoch 2/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 138.5967 - mean_squared_error: 138.5967 - val_loss: 163.9868 - val_mean_squared_error: 163.9868\n",
            "Epoch 3/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 114.6254 - mean_squared_error: 114.6254 - val_loss: 148.1819 - val_mean_squared_error: 148.1819\n",
            "Epoch 4/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 101.2138 - mean_squared_error: 101.2138 - val_loss: 141.4007 - val_mean_squared_error: 141.4007\n",
            "Epoch 5/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 93.6361 - mean_squared_error: 93.6361 - val_loss: 131.8931 - val_mean_squared_error: 131.8931\n",
            "Epoch 6/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 87.3540 - mean_squared_error: 87.3540 - val_loss: 123.8267 - val_mean_squared_error: 123.8267\n",
            "Epoch 7/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 84.4697 - mean_squared_error: 84.4697 - val_loss: 124.6059 - val_mean_squared_error: 124.6059\n",
            "Epoch 8/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 80.1817 - mean_squared_error: 80.1817 - val_loss: 119.9343 - val_mean_squared_error: 119.9343\n",
            "Epoch 9/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 77.7337 - mean_squared_error: 77.7337 - val_loss: 117.0231 - val_mean_squared_error: 117.0231\n",
            "Epoch 10/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 75.2771 - mean_squared_error: 75.2771 - val_loss: 117.4064 - val_mean_squared_error: 117.4064\n",
            "Epoch 11/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 72.9684 - mean_squared_error: 72.9684 - val_loss: 117.1416 - val_mean_squared_error: 117.1416\n",
            "Epoch 12/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 70.7321 - mean_squared_error: 70.7321 - val_loss: 110.5018 - val_mean_squared_error: 110.5018\n",
            "Epoch 13/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 68.8206 - mean_squared_error: 68.8206 - val_loss: 111.0991 - val_mean_squared_error: 111.0991\n",
            "Epoch 14/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 68.2160 - mean_squared_error: 68.2160 - val_loss: 112.1548 - val_mean_squared_error: 112.1548\n",
            "Epoch 15/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 65.7359 - mean_squared_error: 65.7359 - val_loss: 122.0002 - val_mean_squared_error: 122.0002\n",
            "Epoch 16/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 63.8595 - mean_squared_error: 63.8595 - val_loss: 112.6979 - val_mean_squared_error: 112.6979\n",
            "Epoch 17/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 62.8802 - mean_squared_error: 62.8802 - val_loss: 112.7991 - val_mean_squared_error: 112.7991\n",
            "Epoch 18/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 60.4445 - mean_squared_error: 60.4445 - val_loss: 104.4525 - val_mean_squared_error: 104.4525\n",
            "Epoch 19/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 60.4154 - mean_squared_error: 60.4154 - val_loss: 104.9160 - val_mean_squared_error: 104.9160\n",
            "Epoch 20/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 57.3544 - mean_squared_error: 57.3544 - val_loss: 110.1598 - val_mean_squared_error: 110.1598\n",
            "Epoch 21/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 58.3871 - mean_squared_error: 58.3871 - val_loss: 105.9874 - val_mean_squared_error: 105.9874\n",
            "Epoch 22/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 55.9991 - mean_squared_error: 55.9991 - val_loss: 107.1587 - val_mean_squared_error: 107.1587\n",
            "Epoch 23/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 52.9602 - mean_squared_error: 52.9602 - val_loss: 106.5854 - val_mean_squared_error: 106.5854\n",
            "Epoch 24/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 51.9978 - mean_squared_error: 51.9978 - val_loss: 105.3619 - val_mean_squared_error: 105.3619\n",
            "Epoch 25/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 51.8635 - mean_squared_error: 51.8635 - val_loss: 107.1356 - val_mean_squared_error: 107.1356\n",
            "Epoch 26/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 49.2543 - mean_squared_error: 49.2543 - val_loss: 108.4273 - val_mean_squared_error: 108.4272\n",
            "Epoch 27/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 49.1613 - mean_squared_error: 49.1613 - val_loss: 105.5731 - val_mean_squared_error: 105.5731\n",
            "Epoch 28/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 46.6576 - mean_squared_error: 46.6576 - val_loss: 105.5785 - val_mean_squared_error: 105.5785\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 10.220199182744876\n",
            "\n",
            "Training with learning rate=0.01, optimizer=adam, dropout_rate=0.2, epochs=50\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 2273.1926 - mean_squared_error: 2273.1926 - val_loss: 231.0293 - val_mean_squared_error: 231.0293\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 340.4517 - mean_squared_error: 340.4517 - val_loss: 189.8411 - val_mean_squared_error: 189.8411\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 300.2948 - mean_squared_error: 300.2948 - val_loss: 174.4816 - val_mean_squared_error: 174.4816\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 286.2706 - mean_squared_error: 286.2706 - val_loss: 144.8344 - val_mean_squared_error: 144.8344\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 281.9708 - mean_squared_error: 281.9708 - val_loss: 155.5048 - val_mean_squared_error: 155.5048\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 269.1414 - mean_squared_error: 269.1414 - val_loss: 137.4792 - val_mean_squared_error: 137.4792\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 262.2527 - mean_squared_error: 262.2527 - val_loss: 132.8906 - val_mean_squared_error: 132.8906\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 258.1487 - mean_squared_error: 258.1487 - val_loss: 134.9713 - val_mean_squared_error: 134.9713\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 254.8548 - mean_squared_error: 254.8548 - val_loss: 160.4329 - val_mean_squared_error: 160.4329\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 239.1820 - mean_squared_error: 239.1820 - val_loss: 124.3441 - val_mean_squared_error: 124.3441\n",
            "Epoch 11/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 243.4892 - mean_squared_error: 243.4892 - val_loss: 121.3063 - val_mean_squared_error: 121.3063\n",
            "Epoch 12/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 262.1149 - mean_squared_error: 262.1149 - val_loss: 119.8220 - val_mean_squared_error: 119.8220\n",
            "Epoch 13/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 234.6951 - mean_squared_error: 234.6951 - val_loss: 131.7924 - val_mean_squared_error: 131.7924\n",
            "Epoch 14/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 233.3821 - mean_squared_error: 233.3821 - val_loss: 120.0186 - val_mean_squared_error: 120.0186\n",
            "Epoch 15/50\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 240.3017 - mean_squared_error: 240.3017 - val_loss: 116.9434 - val_mean_squared_error: 116.9434\n",
            "Epoch 16/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 244.4412 - mean_squared_error: 244.4412 - val_loss: 128.7432 - val_mean_squared_error: 128.7432\n",
            "Epoch 17/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 229.0825 - mean_squared_error: 229.0825 - val_loss: 119.7992 - val_mean_squared_error: 119.7992\n",
            "Epoch 18/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 242.2329 - mean_squared_error: 242.2329 - val_loss: 114.5021 - val_mean_squared_error: 114.5021\n",
            "Epoch 19/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 253.3600 - mean_squared_error: 253.3600 - val_loss: 115.1715 - val_mean_squared_error: 115.1715\n",
            "Epoch 20/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 230.4274 - mean_squared_error: 230.4274 - val_loss: 130.0390 - val_mean_squared_error: 130.0390\n",
            "Epoch 21/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 223.7125 - mean_squared_error: 223.7125 - val_loss: 140.4626 - val_mean_squared_error: 140.4626\n",
            "Epoch 22/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 231.3509 - mean_squared_error: 231.3509 - val_loss: 146.1102 - val_mean_squared_error: 146.1102\n",
            "Epoch 23/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 233.7724 - mean_squared_error: 233.7724 - val_loss: 122.2030 - val_mean_squared_error: 122.2030\n",
            "Epoch 24/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 237.6422 - mean_squared_error: 237.6422 - val_loss: 146.5515 - val_mean_squared_error: 146.5515\n",
            "Epoch 25/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 219.5605 - mean_squared_error: 219.5605 - val_loss: 119.5494 - val_mean_squared_error: 119.5494\n",
            "Epoch 26/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 219.9691 - mean_squared_error: 219.9691 - val_loss: 116.6361 - val_mean_squared_error: 116.6361\n",
            "Epoch 27/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 216.6884 - mean_squared_error: 216.6884 - val_loss: 111.6531 - val_mean_squared_error: 111.6531\n",
            "Epoch 28/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 233.4720 - mean_squared_error: 233.4720 - val_loss: 113.1393 - val_mean_squared_error: 113.1393\n",
            "Epoch 29/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 227.7811 - mean_squared_error: 227.7811 - val_loss: 106.9228 - val_mean_squared_error: 106.9228\n",
            "Epoch 30/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 221.4129 - mean_squared_error: 221.4129 - val_loss: 115.9393 - val_mean_squared_error: 115.9393\n",
            "Epoch 31/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 240.1671 - mean_squared_error: 240.1671 - val_loss: 115.7694 - val_mean_squared_error: 115.7694\n",
            "Epoch 32/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 206.0999 - mean_squared_error: 206.0999 - val_loss: 112.1292 - val_mean_squared_error: 112.1292\n",
            "Epoch 33/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 226.1951 - mean_squared_error: 226.1951 - val_loss: 114.5162 - val_mean_squared_error: 114.5162\n",
            "Epoch 34/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 212.6069 - mean_squared_error: 212.6069 - val_loss: 111.8372 - val_mean_squared_error: 111.8372\n",
            "Epoch 35/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 210.3564 - mean_squared_error: 210.3564 - val_loss: 118.1005 - val_mean_squared_error: 118.1005\n",
            "Epoch 36/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 225.0196 - mean_squared_error: 225.0196 - val_loss: 126.0646 - val_mean_squared_error: 126.0646\n",
            "Epoch 37/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 234.6089 - mean_squared_error: 234.6089 - val_loss: 112.5745 - val_mean_squared_error: 112.5745\n",
            "Epoch 38/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 212.5470 - mean_squared_error: 212.5470 - val_loss: 107.3268 - val_mean_squared_error: 107.3268\n",
            "Epoch 39/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 209.5828 - mean_squared_error: 209.5828 - val_loss: 131.1545 - val_mean_squared_error: 131.1545\n",
            "13/13 [==============================] - 0s 4ms/step\n",
            "RMSE: 10.34034740707767\n",
            "\n",
            "Training with learning rate=0.01, optimizer=adam, dropout_rate=0.2, epochs=100\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 2s 5ms/step - loss: 2373.4841 - mean_squared_error: 2373.4841 - val_loss: 237.4468 - val_mean_squared_error: 237.4468\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 367.7246 - mean_squared_error: 367.7246 - val_loss: 179.3446 - val_mean_squared_error: 179.3446\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 340.1076 - mean_squared_error: 340.1076 - val_loss: 176.9792 - val_mean_squared_error: 176.9792\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 340.1515 - mean_squared_error: 340.1515 - val_loss: 145.6183 - val_mean_squared_error: 145.6183\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 307.3584 - mean_squared_error: 307.3584 - val_loss: 137.9393 - val_mean_squared_error: 137.9393\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 290.4124 - mean_squared_error: 290.4124 - val_loss: 136.7571 - val_mean_squared_error: 136.7571\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 280.7391 - mean_squared_error: 280.7391 - val_loss: 131.7967 - val_mean_squared_error: 131.7967\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 267.3009 - mean_squared_error: 267.3009 - val_loss: 126.5906 - val_mean_squared_error: 126.5905\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 269.4101 - mean_squared_error: 269.4101 - val_loss: 132.6294 - val_mean_squared_error: 132.6294\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 275.0274 - mean_squared_error: 275.0274 - val_loss: 152.2530 - val_mean_squared_error: 152.2530\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 274.8219 - mean_squared_error: 274.8219 - val_loss: 121.9058 - val_mean_squared_error: 121.9058\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 258.4068 - mean_squared_error: 258.4068 - val_loss: 116.4014 - val_mean_squared_error: 116.4015\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 267.0123 - mean_squared_error: 267.0123 - val_loss: 133.1831 - val_mean_squared_error: 133.1831\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 259.4664 - mean_squared_error: 259.4664 - val_loss: 119.0549 - val_mean_squared_error: 119.0549\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 256.6280 - mean_squared_error: 256.6280 - val_loss: 118.7046 - val_mean_squared_error: 118.7046\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 258.2082 - mean_squared_error: 258.2082 - val_loss: 115.1289 - val_mean_squared_error: 115.1289\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 257.8257 - mean_squared_error: 257.8257 - val_loss: 133.9408 - val_mean_squared_error: 133.9408\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 233.8392 - mean_squared_error: 233.8392 - val_loss: 117.2389 - val_mean_squared_error: 117.2389\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 224.9052 - mean_squared_error: 224.9052 - val_loss: 128.8555 - val_mean_squared_error: 128.8555\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 235.3730 - mean_squared_error: 235.3730 - val_loss: 113.7304 - val_mean_squared_error: 113.7304\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 232.2986 - mean_squared_error: 232.2986 - val_loss: 123.6242 - val_mean_squared_error: 123.6242\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 245.3298 - mean_squared_error: 245.3298 - val_loss: 120.3219 - val_mean_squared_error: 120.3219\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 231.6029 - mean_squared_error: 231.6029 - val_loss: 109.9692 - val_mean_squared_error: 109.9692\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 220.9742 - mean_squared_error: 220.9742 - val_loss: 131.8572 - val_mean_squared_error: 131.8572\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 237.9889 - mean_squared_error: 237.9889 - val_loss: 109.2576 - val_mean_squared_error: 109.2576\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 242.3602 - mean_squared_error: 242.3602 - val_loss: 135.1906 - val_mean_squared_error: 135.1906\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 229.9366 - mean_squared_error: 229.9366 - val_loss: 123.9432 - val_mean_squared_error: 123.9432\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 231.1726 - mean_squared_error: 231.1726 - val_loss: 115.9777 - val_mean_squared_error: 115.9777\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 211.6055 - mean_squared_error: 211.6055 - val_loss: 113.8649 - val_mean_squared_error: 113.8649\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 235.0132 - mean_squared_error: 235.0132 - val_loss: 129.5045 - val_mean_squared_error: 129.5045\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 207.3113 - mean_squared_error: 207.3113 - val_loss: 121.8564 - val_mean_squared_error: 121.8564\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 236.8632 - mean_squared_error: 236.8632 - val_loss: 109.2038 - val_mean_squared_error: 109.2038\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 222.9719 - mean_squared_error: 222.9719 - val_loss: 113.7634 - val_mean_squared_error: 113.7634\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 233.5001 - mean_squared_error: 233.5002 - val_loss: 111.4189 - val_mean_squared_error: 111.4189\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 217.9833 - mean_squared_error: 217.9833 - val_loss: 110.0895 - val_mean_squared_error: 110.0895\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 232.4205 - mean_squared_error: 232.4205 - val_loss: 120.3854 - val_mean_squared_error: 120.3854\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 222.4583 - mean_squared_error: 222.4583 - val_loss: 110.1158 - val_mean_squared_error: 110.1158\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 222.0313 - mean_squared_error: 222.0313 - val_loss: 112.6471 - val_mean_squared_error: 112.6471\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 214.2375 - mean_squared_error: 214.2375 - val_loss: 120.2948 - val_mean_squared_error: 120.2948\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 214.0533 - mean_squared_error: 214.0533 - val_loss: 117.6336 - val_mean_squared_error: 117.6336\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 207.7052 - mean_squared_error: 207.7052 - val_loss: 111.1496 - val_mean_squared_error: 111.1496\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 225.2129 - mean_squared_error: 225.2129 - val_loss: 124.1266 - val_mean_squared_error: 124.1266\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 10.450062677130722\n",
            "\n",
            "Training with learning rate=0.01, optimizer=adam, dropout_rate=0.2, epochs=150\n",
            "Epoch 1/150\n",
            "165/165 [==============================] - 2s 4ms/step - loss: 2107.2278 - mean_squared_error: 2107.2278 - val_loss: 218.9438 - val_mean_squared_error: 218.9438\n",
            "Epoch 2/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 338.4661 - mean_squared_error: 338.4661 - val_loss: 202.7194 - val_mean_squared_error: 202.7194\n",
            "Epoch 3/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 303.7165 - mean_squared_error: 303.7165 - val_loss: 152.7317 - val_mean_squared_error: 152.7317\n",
            "Epoch 4/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 286.3810 - mean_squared_error: 286.3810 - val_loss: 167.4194 - val_mean_squared_error: 167.4194\n",
            "Epoch 5/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 269.3068 - mean_squared_error: 269.3068 - val_loss: 135.7441 - val_mean_squared_error: 135.7441\n",
            "Epoch 6/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 271.3418 - mean_squared_error: 271.3418 - val_loss: 138.0237 - val_mean_squared_error: 138.0237\n",
            "Epoch 7/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 271.9988 - mean_squared_error: 271.9988 - val_loss: 140.4659 - val_mean_squared_error: 140.4659\n",
            "Epoch 8/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 257.0673 - mean_squared_error: 257.0673 - val_loss: 134.9402 - val_mean_squared_error: 134.9402\n",
            "Epoch 9/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 252.2536 - mean_squared_error: 252.2536 - val_loss: 145.4976 - val_mean_squared_error: 145.4976\n",
            "Epoch 10/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 236.2206 - mean_squared_error: 236.2206 - val_loss: 121.6816 - val_mean_squared_error: 121.6816\n",
            "Epoch 11/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 248.0632 - mean_squared_error: 248.0632 - val_loss: 134.3734 - val_mean_squared_error: 134.3734\n",
            "Epoch 12/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 227.7477 - mean_squared_error: 227.7477 - val_loss: 116.8209 - val_mean_squared_error: 116.8209\n",
            "Epoch 13/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 233.1030 - mean_squared_error: 233.1030 - val_loss: 126.9168 - val_mean_squared_error: 126.9168\n",
            "Epoch 14/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 229.7768 - mean_squared_error: 229.7768 - val_loss: 121.8064 - val_mean_squared_error: 121.8064\n",
            "Epoch 15/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 239.9270 - mean_squared_error: 239.9270 - val_loss: 123.6531 - val_mean_squared_error: 123.6531\n",
            "Epoch 16/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 233.3889 - mean_squared_error: 233.3889 - val_loss: 130.8035 - val_mean_squared_error: 130.8035\n",
            "Epoch 17/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 233.8263 - mean_squared_error: 233.8263 - val_loss: 118.6262 - val_mean_squared_error: 118.6262\n",
            "Epoch 18/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 217.5166 - mean_squared_error: 217.5166 - val_loss: 117.2293 - val_mean_squared_error: 117.2293\n",
            "Epoch 19/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 231.7394 - mean_squared_error: 231.7394 - val_loss: 121.5913 - val_mean_squared_error: 121.5913\n",
            "Epoch 20/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 211.3892 - mean_squared_error: 211.3891 - val_loss: 117.4031 - val_mean_squared_error: 117.4031\n",
            "Epoch 21/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 229.7630 - mean_squared_error: 229.7630 - val_loss: 110.3015 - val_mean_squared_error: 110.3015\n",
            "Epoch 22/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 220.3463 - mean_squared_error: 220.3463 - val_loss: 113.6983 - val_mean_squared_error: 113.6983\n",
            "Epoch 23/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 219.0107 - mean_squared_error: 219.0107 - val_loss: 108.2687 - val_mean_squared_error: 108.2687\n",
            "Epoch 24/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 217.1735 - mean_squared_error: 217.1735 - val_loss: 114.6588 - val_mean_squared_error: 114.6588\n",
            "Epoch 25/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 214.9544 - mean_squared_error: 214.9544 - val_loss: 114.7396 - val_mean_squared_error: 114.7396\n",
            "Epoch 26/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 212.5066 - mean_squared_error: 212.5066 - val_loss: 114.3245 - val_mean_squared_error: 114.3245\n",
            "Epoch 27/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 213.7428 - mean_squared_error: 213.7428 - val_loss: 110.9826 - val_mean_squared_error: 110.9826\n",
            "Epoch 28/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 200.0598 - mean_squared_error: 200.0598 - val_loss: 121.7332 - val_mean_squared_error: 121.7332\n",
            "Epoch 29/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 209.2136 - mean_squared_error: 209.2136 - val_loss: 121.6962 - val_mean_squared_error: 121.6962\n",
            "Epoch 30/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 213.0670 - mean_squared_error: 213.0670 - val_loss: 112.2742 - val_mean_squared_error: 112.2742\n",
            "Epoch 31/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 210.1095 - mean_squared_error: 210.1095 - val_loss: 109.1878 - val_mean_squared_error: 109.1878\n",
            "Epoch 32/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 199.8691 - mean_squared_error: 199.8691 - val_loss: 106.6829 - val_mean_squared_error: 106.6829\n",
            "Epoch 33/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 194.6036 - mean_squared_error: 194.6036 - val_loss: 111.6101 - val_mean_squared_error: 111.6101\n",
            "Epoch 34/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 196.6543 - mean_squared_error: 196.6543 - val_loss: 109.1744 - val_mean_squared_error: 109.1744\n",
            "Epoch 35/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 210.5666 - mean_squared_error: 210.5666 - val_loss: 110.1690 - val_mean_squared_error: 110.1690\n",
            "Epoch 36/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 213.6809 - mean_squared_error: 213.6809 - val_loss: 116.2789 - val_mean_squared_error: 116.2789\n",
            "Epoch 37/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 209.1521 - mean_squared_error: 209.1521 - val_loss: 116.9512 - val_mean_squared_error: 116.9512\n",
            "Epoch 38/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 213.4932 - mean_squared_error: 213.4932 - val_loss: 114.1698 - val_mean_squared_error: 114.1698\n",
            "Epoch 39/150\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 195.3785 - mean_squared_error: 195.3785 - val_loss: 139.0224 - val_mean_squared_error: 139.0224\n",
            "Epoch 40/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 196.5786 - mean_squared_error: 196.5786 - val_loss: 131.4448 - val_mean_squared_error: 131.4448\n",
            "Epoch 41/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 221.7088 - mean_squared_error: 221.7088 - val_loss: 111.4689 - val_mean_squared_error: 111.4689\n",
            "Epoch 42/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 203.1547 - mean_squared_error: 203.1547 - val_loss: 115.1644 - val_mean_squared_error: 115.1644\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 10.32874224816559\n",
            "\n",
            "Training with learning rate=0.01, optimizer=adam, dropout_rate=0.5, epochs=50\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 2s 4ms/step - loss: 3159.5723 - mean_squared_error: 3159.5723 - val_loss: 301.1736 - val_mean_squared_error: 301.1736\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 855.5549 - mean_squared_error: 855.5549 - val_loss: 222.7841 - val_mean_squared_error: 222.7841\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 816.8225 - mean_squared_error: 816.8225 - val_loss: 222.2173 - val_mean_squared_error: 222.2173\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 801.6259 - mean_squared_error: 801.6259 - val_loss: 258.2664 - val_mean_squared_error: 258.2664\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 779.7014 - mean_squared_error: 779.7014 - val_loss: 323.7232 - val_mean_squared_error: 323.7232\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 719.4996 - mean_squared_error: 719.4996 - val_loss: 194.6072 - val_mean_squared_error: 194.6072\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 711.0884 - mean_squared_error: 711.0884 - val_loss: 191.8460 - val_mean_squared_error: 191.8460\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 704.3884 - mean_squared_error: 704.3884 - val_loss: 197.0449 - val_mean_squared_error: 197.0449\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 700.0715 - mean_squared_error: 700.0715 - val_loss: 193.1303 - val_mean_squared_error: 193.1303\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 625.1136 - mean_squared_error: 625.1136 - val_loss: 240.3909 - val_mean_squared_error: 240.3909\n",
            "Epoch 11/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 640.5006 - mean_squared_error: 640.5006 - val_loss: 154.4612 - val_mean_squared_error: 154.4612\n",
            "Epoch 12/50\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 650.5300 - mean_squared_error: 650.5300 - val_loss: 182.8562 - val_mean_squared_error: 182.8562\n",
            "Epoch 13/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 620.8062 - mean_squared_error: 620.8062 - val_loss: 235.1783 - val_mean_squared_error: 235.1783\n",
            "Epoch 14/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 650.4192 - mean_squared_error: 650.4192 - val_loss: 210.6683 - val_mean_squared_error: 210.6683\n",
            "Epoch 15/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 649.1978 - mean_squared_error: 649.1978 - val_loss: 174.8069 - val_mean_squared_error: 174.8069\n",
            "Epoch 16/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 582.7473 - mean_squared_error: 582.7473 - val_loss: 189.4161 - val_mean_squared_error: 189.4161\n",
            "Epoch 17/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 615.9034 - mean_squared_error: 615.9034 - val_loss: 178.4976 - val_mean_squared_error: 178.4976\n",
            "Epoch 18/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 586.9493 - mean_squared_error: 586.9493 - val_loss: 128.1433 - val_mean_squared_error: 128.1433\n",
            "Epoch 19/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 612.3667 - mean_squared_error: 612.3667 - val_loss: 263.9298 - val_mean_squared_error: 263.9298\n",
            "Epoch 20/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 594.5899 - mean_squared_error: 594.5899 - val_loss: 210.9811 - val_mean_squared_error: 210.9811\n",
            "Epoch 21/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 587.7560 - mean_squared_error: 587.7560 - val_loss: 163.1767 - val_mean_squared_error: 163.1767\n",
            "Epoch 22/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 599.6882 - mean_squared_error: 599.6882 - val_loss: 150.8811 - val_mean_squared_error: 150.8811\n",
            "Epoch 23/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 589.9888 - mean_squared_error: 589.9888 - val_loss: 189.4238 - val_mean_squared_error: 189.4238\n",
            "Epoch 24/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 565.9548 - mean_squared_error: 565.9548 - val_loss: 139.9430 - val_mean_squared_error: 139.9430\n",
            "Epoch 25/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 560.0474 - mean_squared_error: 560.0474 - val_loss: 215.9391 - val_mean_squared_error: 215.9391\n",
            "Epoch 26/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 576.0624 - mean_squared_error: 576.0624 - val_loss: 137.2378 - val_mean_squared_error: 137.2378\n",
            "Epoch 27/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 577.2610 - mean_squared_error: 577.2610 - val_loss: 165.8609 - val_mean_squared_error: 165.8609\n",
            "Epoch 28/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 560.2471 - mean_squared_error: 560.2471 - val_loss: 110.3697 - val_mean_squared_error: 110.3697\n",
            "Epoch 29/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 542.8048 - mean_squared_error: 542.8048 - val_loss: 160.1499 - val_mean_squared_error: 160.1499\n",
            "Epoch 30/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 550.1807 - mean_squared_error: 550.1807 - val_loss: 150.7729 - val_mean_squared_error: 150.7729\n",
            "Epoch 31/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 584.9341 - mean_squared_error: 584.9341 - val_loss: 212.2565 - val_mean_squared_error: 212.2565\n",
            "Epoch 32/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 557.7057 - mean_squared_error: 557.7057 - val_loss: 153.3175 - val_mean_squared_error: 153.3175\n",
            "Epoch 33/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 548.7342 - mean_squared_error: 548.7342 - val_loss: 162.5819 - val_mean_squared_error: 162.5819\n",
            "Epoch 34/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 510.7662 - mean_squared_error: 510.7661 - val_loss: 139.0886 - val_mean_squared_error: 139.0886\n",
            "Epoch 35/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 495.9575 - mean_squared_error: 495.9575 - val_loss: 130.9351 - val_mean_squared_error: 130.9351\n",
            "Epoch 36/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 513.5783 - mean_squared_error: 513.5783 - val_loss: 176.6356 - val_mean_squared_error: 176.6356\n",
            "Epoch 37/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 554.9884 - mean_squared_error: 554.9884 - val_loss: 133.3623 - val_mean_squared_error: 133.3623\n",
            "Epoch 38/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 498.1248 - mean_squared_error: 498.1248 - val_loss: 130.8576 - val_mean_squared_error: 130.8576\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 10.505699650960908\n",
            "\n",
            "Training with learning rate=0.01, optimizer=adam, dropout_rate=0.5, epochs=100\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 2s 4ms/step - loss: 3467.3967 - mean_squared_error: 3467.3967 - val_loss: 297.5832 - val_mean_squared_error: 297.5832\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 860.7092 - mean_squared_error: 860.7092 - val_loss: 250.6005 - val_mean_squared_error: 250.6005\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 813.2276 - mean_squared_error: 813.2276 - val_loss: 243.5486 - val_mean_squared_error: 243.5486\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 735.2092 - mean_squared_error: 735.2092 - val_loss: 245.9117 - val_mean_squared_error: 245.9117\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 713.0049 - mean_squared_error: 713.0049 - val_loss: 243.0329 - val_mean_squared_error: 243.0329\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 703.5938 - mean_squared_error: 703.5938 - val_loss: 173.1388 - val_mean_squared_error: 173.1388\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 653.5395 - mean_squared_error: 653.5395 - val_loss: 214.5074 - val_mean_squared_error: 214.5074\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 647.8014 - mean_squared_error: 647.8014 - val_loss: 179.4367 - val_mean_squared_error: 179.4367\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 645.9786 - mean_squared_error: 645.9786 - val_loss: 182.8123 - val_mean_squared_error: 182.8123\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 665.4544 - mean_squared_error: 665.4544 - val_loss: 208.9530 - val_mean_squared_error: 208.9530\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 584.9297 - mean_squared_error: 584.9297 - val_loss: 163.9829 - val_mean_squared_error: 163.9829\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 551.9882 - mean_squared_error: 551.9882 - val_loss: 201.8611 - val_mean_squared_error: 201.8611\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 612.9456 - mean_squared_error: 612.9456 - val_loss: 193.2018 - val_mean_squared_error: 193.2018\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 591.3425 - mean_squared_error: 591.3425 - val_loss: 195.6631 - val_mean_squared_error: 195.6631\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 598.3937 - mean_squared_error: 598.3937 - val_loss: 146.0561 - val_mean_squared_error: 146.0561\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 558.5818 - mean_squared_error: 558.5818 - val_loss: 153.6819 - val_mean_squared_error: 153.6819\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 568.6001 - mean_squared_error: 568.6001 - val_loss: 143.7240 - val_mean_squared_error: 143.7240\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 548.3461 - mean_squared_error: 548.3461 - val_loss: 178.8566 - val_mean_squared_error: 178.8566\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 529.4191 - mean_squared_error: 529.4191 - val_loss: 159.0809 - val_mean_squared_error: 159.0809\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 527.7192 - mean_squared_error: 527.7192 - val_loss: 137.0437 - val_mean_squared_error: 137.0437\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 499.5631 - mean_squared_error: 499.5631 - val_loss: 161.4129 - val_mean_squared_error: 161.4129\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 545.6381 - mean_squared_error: 545.6381 - val_loss: 174.2761 - val_mean_squared_error: 174.2761\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 554.3652 - mean_squared_error: 554.3652 - val_loss: 167.2069 - val_mean_squared_error: 167.2069\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 543.3693 - mean_squared_error: 543.3693 - val_loss: 149.5040 - val_mean_squared_error: 149.5040\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 546.2937 - mean_squared_error: 546.2937 - val_loss: 136.2474 - val_mean_squared_error: 136.2474\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 504.9500 - mean_squared_error: 504.9499 - val_loss: 191.2242 - val_mean_squared_error: 191.2242\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 499.3909 - mean_squared_error: 499.3909 - val_loss: 133.2432 - val_mean_squared_error: 133.2432\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 504.5994 - mean_squared_error: 504.5994 - val_loss: 177.2620 - val_mean_squared_error: 177.2620\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 496.2743 - mean_squared_error: 496.2743 - val_loss: 176.9217 - val_mean_squared_error: 176.9217\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 499.4447 - mean_squared_error: 499.4447 - val_loss: 126.6090 - val_mean_squared_error: 126.6090\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 498.9480 - mean_squared_error: 498.9480 - val_loss: 120.7281 - val_mean_squared_error: 120.7281\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 488.0068 - mean_squared_error: 488.0068 - val_loss: 197.3098 - val_mean_squared_error: 197.3098\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 513.1429 - mean_squared_error: 513.1429 - val_loss: 167.0181 - val_mean_squared_error: 167.0181\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 511.4633 - mean_squared_error: 511.4633 - val_loss: 145.3844 - val_mean_squared_error: 145.3844\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 480.5176 - mean_squared_error: 480.5176 - val_loss: 139.2995 - val_mean_squared_error: 139.2995\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 488.6859 - mean_squared_error: 488.6859 - val_loss: 170.8315 - val_mean_squared_error: 170.8315\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 483.3286 - mean_squared_error: 483.3286 - val_loss: 135.7259 - val_mean_squared_error: 135.7259\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 492.9623 - mean_squared_error: 492.9623 - val_loss: 180.1676 - val_mean_squared_error: 180.1676\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 465.0842 - mean_squared_error: 465.0842 - val_loss: 139.1330 - val_mean_squared_error: 139.1330\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 485.5601 - mean_squared_error: 485.5601 - val_loss: 127.6060 - val_mean_squared_error: 127.6060\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 456.7499 - mean_squared_error: 456.7499 - val_loss: 149.0162 - val_mean_squared_error: 149.0162\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 10.98763411786892\n",
            "\n",
            "Training with learning rate=0.01, optimizer=adam, dropout_rate=0.5, epochs=150\n",
            "Epoch 1/150\n",
            "165/165 [==============================] - 2s 4ms/step - loss: 3519.3035 - mean_squared_error: 3519.3035 - val_loss: 359.4521 - val_mean_squared_error: 359.4521\n",
            "Epoch 2/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 937.8245 - mean_squared_error: 937.8245 - val_loss: 261.0505 - val_mean_squared_error: 261.0505\n",
            "Epoch 3/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 917.3713 - mean_squared_error: 917.3713 - val_loss: 274.7843 - val_mean_squared_error: 274.7843\n",
            "Epoch 4/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 865.5869 - mean_squared_error: 865.5869 - val_loss: 254.9108 - val_mean_squared_error: 254.9108\n",
            "Epoch 5/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 858.3614 - mean_squared_error: 858.3614 - val_loss: 294.0200 - val_mean_squared_error: 294.0200\n",
            "Epoch 6/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 789.1796 - mean_squared_error: 789.1795 - val_loss: 244.8593 - val_mean_squared_error: 244.8593\n",
            "Epoch 7/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 831.1916 - mean_squared_error: 831.1916 - val_loss: 211.4529 - val_mean_squared_error: 211.4529\n",
            "Epoch 8/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 803.5626 - mean_squared_error: 803.5626 - val_loss: 195.7897 - val_mean_squared_error: 195.7897\n",
            "Epoch 9/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 785.4672 - mean_squared_error: 785.4672 - val_loss: 225.4460 - val_mean_squared_error: 225.4460\n",
            "Epoch 10/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 808.6578 - mean_squared_error: 808.6578 - val_loss: 188.4141 - val_mean_squared_error: 188.4141\n",
            "Epoch 11/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 763.1693 - mean_squared_error: 763.1693 - val_loss: 178.0757 - val_mean_squared_error: 178.0757\n",
            "Epoch 12/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 814.4848 - mean_squared_error: 814.4848 - val_loss: 223.5153 - val_mean_squared_error: 223.5153\n",
            "Epoch 13/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 782.6575 - mean_squared_error: 782.6575 - val_loss: 198.6774 - val_mean_squared_error: 198.6774\n",
            "Epoch 14/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 778.9189 - mean_squared_error: 778.9189 - val_loss: 154.4885 - val_mean_squared_error: 154.4885\n",
            "Epoch 15/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 761.7864 - mean_squared_error: 761.7864 - val_loss: 153.5241 - val_mean_squared_error: 153.5241\n",
            "Epoch 16/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 778.6284 - mean_squared_error: 778.6284 - val_loss: 170.2079 - val_mean_squared_error: 170.2079\n",
            "Epoch 17/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 733.4797 - mean_squared_error: 733.4797 - val_loss: 256.2335 - val_mean_squared_error: 256.2335\n",
            "Epoch 18/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 725.3233 - mean_squared_error: 725.3233 - val_loss: 158.7562 - val_mean_squared_error: 158.7562\n",
            "Epoch 19/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 705.5626 - mean_squared_error: 705.5626 - val_loss: 192.8136 - val_mean_squared_error: 192.8136\n",
            "Epoch 20/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 732.4458 - mean_squared_error: 732.4458 - val_loss: 218.7901 - val_mean_squared_error: 218.7901\n",
            "Epoch 21/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 705.3444 - mean_squared_error: 705.3444 - val_loss: 142.8125 - val_mean_squared_error: 142.8125\n",
            "Epoch 22/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 698.1459 - mean_squared_error: 698.1459 - val_loss: 157.4163 - val_mean_squared_error: 157.4163\n",
            "Epoch 23/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 723.7658 - mean_squared_error: 723.7658 - val_loss: 164.2141 - val_mean_squared_error: 164.2141\n",
            "Epoch 24/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 671.2322 - mean_squared_error: 671.2322 - val_loss: 155.1976 - val_mean_squared_error: 155.1976\n",
            "Epoch 25/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 661.1562 - mean_squared_error: 661.1562 - val_loss: 195.8098 - val_mean_squared_error: 195.8098\n",
            "Epoch 26/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 661.4953 - mean_squared_error: 661.4953 - val_loss: 161.7780 - val_mean_squared_error: 161.7780\n",
            "Epoch 27/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 667.5518 - mean_squared_error: 667.5518 - val_loss: 180.6117 - val_mean_squared_error: 180.6117\n",
            "Epoch 28/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 669.4009 - mean_squared_error: 669.4009 - val_loss: 212.2674 - val_mean_squared_error: 212.2674\n",
            "Epoch 29/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 631.3156 - mean_squared_error: 631.3156 - val_loss: 165.2491 - val_mean_squared_error: 165.2491\n",
            "Epoch 30/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 658.5237 - mean_squared_error: 658.5237 - val_loss: 196.4541 - val_mean_squared_error: 196.4541\n",
            "Epoch 31/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 668.4850 - mean_squared_error: 668.4851 - val_loss: 153.9407 - val_mean_squared_error: 153.9407\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "RMSE: 11.950416626363607\n",
            "\n",
            "Training with learning rate=0.01, optimizer=sgd, dropout_rate=0.0, epochs=50\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 2s 6ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.01, optimizer=sgd, dropout_rate=0.0, epochs=50\n",
            "Training with learning rate=0.01, optimizer=sgd, dropout_rate=0.0, epochs=100\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.01, optimizer=sgd, dropout_rate=0.0, epochs=100\n",
            "Training with learning rate=0.01, optimizer=sgd, dropout_rate=0.0, epochs=150\n",
            "Epoch 1/150\n",
            "165/165 [==============================] - 2s 5ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.01, optimizer=sgd, dropout_rate=0.0, epochs=150\n",
            "Training with learning rate=0.01, optimizer=sgd, dropout_rate=0.2, epochs=50\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.01, optimizer=sgd, dropout_rate=0.2, epochs=50\n",
            "Training with learning rate=0.01, optimizer=sgd, dropout_rate=0.2, epochs=100\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.01, optimizer=sgd, dropout_rate=0.2, epochs=100\n",
            "Training with learning rate=0.01, optimizer=sgd, dropout_rate=0.2, epochs=150\n",
            "Epoch 1/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.01, optimizer=sgd, dropout_rate=0.2, epochs=150\n",
            "Training with learning rate=0.01, optimizer=sgd, dropout_rate=0.5, epochs=50\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 3s 5ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.01, optimizer=sgd, dropout_rate=0.5, epochs=50\n",
            "Training with learning rate=0.01, optimizer=sgd, dropout_rate=0.5, epochs=100\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "NaN values found in predictions with learning rate=0.01, optimizer=sgd, dropout_rate=0.5, epochs=100\n",
            "Training with learning rate=0.01, optimizer=sgd, dropout_rate=0.5, epochs=150\n",
            "Epoch 1/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 2/150\n",
            "165/165 [==============================] - 1s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 3/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 4/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 5/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 6/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 7/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 8/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 9/150\n",
            "165/165 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "Epoch 10/150\n",
            "165/165 [==============================] - 1s 4ms/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
            "13/13 [==============================] - 0s 4ms/step\n",
            "NaN values found in predictions with learning rate=0.01, optimizer=sgd, dropout_rate=0.5, epochs=150\n",
            "Best RMSE: 9.712043589463898 with parameters: {'learning_rate': 0.0001, 'optimizer': 'adam', 'dropout_rate': 0.0, 'epochs': 50}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Define a function to create a model with a variable number of hidden layers\n",
        "def create_model(hidden_layers=2):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "\n",
        "    for _ in range(hidden_layers):\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return model\n",
        "\n",
        "# Define the list of hidden layers to experiment with\n",
        "hidden_layers_list = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Use early stopping to avoid overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# DataFrame to store RMSE values\n",
        "results = pd.DataFrame(columns=['Hidden Layers', 'RMSE'])\n",
        "\n",
        "# Train and evaluate the model with different numbers of hidden layers\n",
        "for hl in hidden_layers_list:\n",
        "    print(f'Training with hidden_layers={hl}')\n",
        "    model = create_model(hidden_layers=hl)\n",
        "    history = model.fit(X_train_scaled, y_train,\n",
        "                        validation_data=(X_test_scaled, y_test),\n",
        "                        epochs=100, batch_size=10, verbose=1,\n",
        "                        callbacks=[early_stopping])\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # Check for NaN values in predictions\n",
        "    if np.isnan(y_pred).any():\n",
        "        print(f'NaN values found in predictions with hidden_layers={hl}')\n",
        "        continue\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    print(f'RMSE: {rmse}\\n')\n",
        "\n",
        "    # Append results to DataFrame using concat\n",
        "    new_row = pd.DataFrame({'Hidden Layers': [hl], 'RMSE': [rmse]})\n",
        "    results = pd.concat([results, new_row], ignore_index=True)\n",
        "\n",
        "# Display the results\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOPCrM9KLcBn",
        "outputId": "5057cf1d-37f3-4afb-afbb-9bb87b43cc97"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with hidden_layers=1\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 3211.0476 - mean_squared_error: 3211.0476 - val_loss: 266.8030 - val_mean_squared_error: 266.8030\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 162.8952 - mean_squared_error: 162.8952 - val_loss: 181.0668 - val_mean_squared_error: 181.0668\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 125.4295 - mean_squared_error: 125.4295 - val_loss: 155.1625 - val_mean_squared_error: 155.1625\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 110.9395 - mean_squared_error: 110.9395 - val_loss: 145.8250 - val_mean_squared_error: 145.8250\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 100.7789 - mean_squared_error: 100.7789 - val_loss: 134.1551 - val_mean_squared_error: 134.1551\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 93.0655 - mean_squared_error: 93.0655 - val_loss: 127.9969 - val_mean_squared_error: 127.9969\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 88.2567 - mean_squared_error: 88.2567 - val_loss: 120.7412 - val_mean_squared_error: 120.7412\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 83.7556 - mean_squared_error: 83.7556 - val_loss: 119.5360 - val_mean_squared_error: 119.5360\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 80.8050 - mean_squared_error: 80.8050 - val_loss: 116.1895 - val_mean_squared_error: 116.1895\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 78.7461 - mean_squared_error: 78.7461 - val_loss: 113.3761 - val_mean_squared_error: 113.3761\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 77.3117 - mean_squared_error: 77.3117 - val_loss: 113.2805 - val_mean_squared_error: 113.2805\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 75.2318 - mean_squared_error: 75.2318 - val_loss: 111.7492 - val_mean_squared_error: 111.7492\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 73.6163 - mean_squared_error: 73.6163 - val_loss: 114.3323 - val_mean_squared_error: 114.3323\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 71.8253 - mean_squared_error: 71.8253 - val_loss: 110.8347 - val_mean_squared_error: 110.8347\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 69.9717 - mean_squared_error: 69.9717 - val_loss: 108.3755 - val_mean_squared_error: 108.3755\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 68.7230 - mean_squared_error: 68.7230 - val_loss: 109.4856 - val_mean_squared_error: 109.4856\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 67.5098 - mean_squared_error: 67.5098 - val_loss: 110.2697 - val_mean_squared_error: 110.2697\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 66.7092 - mean_squared_error: 66.7092 - val_loss: 110.7388 - val_mean_squared_error: 110.7388\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 64.5578 - mean_squared_error: 64.5578 - val_loss: 106.5775 - val_mean_squared_error: 106.5775\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 64.1735 - mean_squared_error: 64.1735 - val_loss: 109.3728 - val_mean_squared_error: 109.3728\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 61.0594 - mean_squared_error: 61.0594 - val_loss: 106.1767 - val_mean_squared_error: 106.1767\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 60.0927 - mean_squared_error: 60.0927 - val_loss: 105.6068 - val_mean_squared_error: 105.6068\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 58.6866 - mean_squared_error: 58.6866 - val_loss: 108.5287 - val_mean_squared_error: 108.5287\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 57.0409 - mean_squared_error: 57.0409 - val_loss: 104.3610 - val_mean_squared_error: 104.3610\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 54.7982 - mean_squared_error: 54.7982 - val_loss: 103.0460 - val_mean_squared_error: 103.0460\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 53.0276 - mean_squared_error: 53.0276 - val_loss: 110.2239 - val_mean_squared_error: 110.2239\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 51.9874 - mean_squared_error: 51.9874 - val_loss: 102.9620 - val_mean_squared_error: 102.9620\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 50.1320 - mean_squared_error: 50.1320 - val_loss: 101.1215 - val_mean_squared_error: 101.1215\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 48.9708 - mean_squared_error: 48.9708 - val_loss: 101.0808 - val_mean_squared_error: 101.0808\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 47.6845 - mean_squared_error: 47.6845 - val_loss: 100.4674 - val_mean_squared_error: 100.4674\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 46.4716 - mean_squared_error: 46.4716 - val_loss: 104.0316 - val_mean_squared_error: 104.0316\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 44.8463 - mean_squared_error: 44.8463 - val_loss: 103.4536 - val_mean_squared_error: 103.4536\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 43.7045 - mean_squared_error: 43.7045 - val_loss: 101.3314 - val_mean_squared_error: 101.3314\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 42.4782 - mean_squared_error: 42.4782 - val_loss: 100.9250 - val_mean_squared_error: 100.9250\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 40.1537 - mean_squared_error: 40.1537 - val_loss: 99.1360 - val_mean_squared_error: 99.1360\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 39.5714 - mean_squared_error: 39.5714 - val_loss: 105.9118 - val_mean_squared_error: 105.9118\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 37.8739 - mean_squared_error: 37.8739 - val_loss: 101.7711 - val_mean_squared_error: 101.7711\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 36.1849 - mean_squared_error: 36.1849 - val_loss: 110.0447 - val_mean_squared_error: 110.0447\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 35.0064 - mean_squared_error: 35.0064 - val_loss: 102.3183 - val_mean_squared_error: 102.3183\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 34.8300 - mean_squared_error: 34.8300 - val_loss: 102.6037 - val_mean_squared_error: 102.6037\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 33.0897 - mean_squared_error: 33.0897 - val_loss: 100.6912 - val_mean_squared_error: 100.6912\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 32.2424 - mean_squared_error: 32.2424 - val_loss: 106.7487 - val_mean_squared_error: 106.7487\n",
            "Epoch 43/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 30.7752 - mean_squared_error: 30.7752 - val_loss: 106.3028 - val_mean_squared_error: 106.3028\n",
            "Epoch 44/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 30.2142 - mean_squared_error: 30.2142 - val_loss: 103.8368 - val_mean_squared_error: 103.8368\n",
            "Epoch 45/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 28.2631 - mean_squared_error: 28.2631 - val_loss: 112.4204 - val_mean_squared_error: 112.4204\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 9.956705893261878\n",
            "\n",
            "Training with hidden_layers=2\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 1988.7444 - mean_squared_error: 1988.7444 - val_loss: 209.9928 - val_mean_squared_error: 209.9928\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 137.6457 - mean_squared_error: 137.6457 - val_loss: 169.5937 - val_mean_squared_error: 169.5937\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 111.5608 - mean_squared_error: 111.5608 - val_loss: 149.7276 - val_mean_squared_error: 149.7276\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 99.6913 - mean_squared_error: 99.6913 - val_loss: 142.7906 - val_mean_squared_error: 142.7906\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 91.6501 - mean_squared_error: 91.6501 - val_loss: 133.8638 - val_mean_squared_error: 133.8638\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 86.8130 - mean_squared_error: 86.8130 - val_loss: 137.1102 - val_mean_squared_error: 137.1102\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 83.8767 - mean_squared_error: 83.8767 - val_loss: 129.6042 - val_mean_squared_error: 129.6042\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 82.0373 - mean_squared_error: 82.0373 - val_loss: 122.4029 - val_mean_squared_error: 122.4029\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 77.8855 - mean_squared_error: 77.8855 - val_loss: 124.3621 - val_mean_squared_error: 124.3621\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 76.1800 - mean_squared_error: 76.1800 - val_loss: 121.3882 - val_mean_squared_error: 121.3882\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 74.0678 - mean_squared_error: 74.0678 - val_loss: 120.8241 - val_mean_squared_error: 120.8241\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 70.7906 - mean_squared_error: 70.7906 - val_loss: 118.2910 - val_mean_squared_error: 118.2910\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 70.6071 - mean_squared_error: 70.6071 - val_loss: 114.1783 - val_mean_squared_error: 114.1783\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 68.8169 - mean_squared_error: 68.8169 - val_loss: 111.9131 - val_mean_squared_error: 111.9131\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 66.8962 - mean_squared_error: 66.8962 - val_loss: 108.5952 - val_mean_squared_error: 108.5952\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 65.8956 - mean_squared_error: 65.8956 - val_loss: 108.1070 - val_mean_squared_error: 108.1070\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 61.1781 - mean_squared_error: 61.1781 - val_loss: 115.4985 - val_mean_squared_error: 115.4985\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 59.6476 - mean_squared_error: 59.6476 - val_loss: 113.3009 - val_mean_squared_error: 113.3009\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 57.3185 - mean_squared_error: 57.3185 - val_loss: 107.8496 - val_mean_squared_error: 107.8496\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 56.7943 - mean_squared_error: 56.7943 - val_loss: 109.5248 - val_mean_squared_error: 109.5248\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 55.4384 - mean_squared_error: 55.4384 - val_loss: 105.4391 - val_mean_squared_error: 105.4391\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 52.6002 - mean_squared_error: 52.6002 - val_loss: 109.3282 - val_mean_squared_error: 109.3282\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 52.2063 - mean_squared_error: 52.2063 - val_loss: 110.7809 - val_mean_squared_error: 110.7809\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 49.3562 - mean_squared_error: 49.3562 - val_loss: 119.8166 - val_mean_squared_error: 119.8166\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 47.0848 - mean_squared_error: 47.0848 - val_loss: 105.1851 - val_mean_squared_error: 105.1851\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 46.6127 - mean_squared_error: 46.6127 - val_loss: 108.5357 - val_mean_squared_error: 108.5357\n",
            "Epoch 27/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 44.8353 - mean_squared_error: 44.8353 - val_loss: 107.7587 - val_mean_squared_error: 107.7587\n",
            "Epoch 28/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 45.1995 - mean_squared_error: 45.1995 - val_loss: 105.4414 - val_mean_squared_error: 105.4414\n",
            "Epoch 29/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 42.6306 - mean_squared_error: 42.6306 - val_loss: 109.4398 - val_mean_squared_error: 109.4398\n",
            "Epoch 30/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 40.4019 - mean_squared_error: 40.4019 - val_loss: 108.2299 - val_mean_squared_error: 108.2299\n",
            "Epoch 31/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 39.0066 - mean_squared_error: 39.0066 - val_loss: 112.4127 - val_mean_squared_error: 112.4127\n",
            "Epoch 32/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 37.3633 - mean_squared_error: 37.3633 - val_loss: 104.4765 - val_mean_squared_error: 104.4765\n",
            "Epoch 33/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 36.3416 - mean_squared_error: 36.3416 - val_loss: 114.1163 - val_mean_squared_error: 114.1163\n",
            "Epoch 34/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 35.5018 - mean_squared_error: 35.5018 - val_loss: 117.5916 - val_mean_squared_error: 117.5916\n",
            "Epoch 35/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 35.7399 - mean_squared_error: 35.7399 - val_loss: 107.7017 - val_mean_squared_error: 107.7017\n",
            "Epoch 36/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 34.6316 - mean_squared_error: 34.6316 - val_loss: 112.3016 - val_mean_squared_error: 112.3016\n",
            "Epoch 37/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 32.5475 - mean_squared_error: 32.5475 - val_loss: 113.8159 - val_mean_squared_error: 113.8159\n",
            "Epoch 38/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 31.4478 - mean_squared_error: 31.4478 - val_loss: 116.9807 - val_mean_squared_error: 116.9807\n",
            "Epoch 39/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 29.8131 - mean_squared_error: 29.8131 - val_loss: 112.3943 - val_mean_squared_error: 112.3943\n",
            "Epoch 40/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 29.9488 - mean_squared_error: 29.9488 - val_loss: 112.7852 - val_mean_squared_error: 112.7852\n",
            "Epoch 41/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 31.4960 - mean_squared_error: 31.4960 - val_loss: 114.7792 - val_mean_squared_error: 114.7792\n",
            "Epoch 42/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 27.5753 - mean_squared_error: 27.5753 - val_loss: 116.2656 - val_mean_squared_error: 116.2656\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 10.22137670006501\n",
            "\n",
            "Training with hidden_layers=3\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 2s 4ms/step - loss: 1488.3898 - mean_squared_error: 1488.3898 - val_loss: 192.4358 - val_mean_squared_error: 192.4358\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 147.6873 - mean_squared_error: 147.6873 - val_loss: 155.9239 - val_mean_squared_error: 155.9239\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 122.2513 - mean_squared_error: 122.2512 - val_loss: 141.6910 - val_mean_squared_error: 141.6910\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 106.6515 - mean_squared_error: 106.6515 - val_loss: 132.4037 - val_mean_squared_error: 132.4037\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 98.8445 - mean_squared_error: 98.8445 - val_loss: 128.1854 - val_mean_squared_error: 128.1854\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 90.1850 - mean_squared_error: 90.1850 - val_loss: 129.4462 - val_mean_squared_error: 129.4462\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 88.2180 - mean_squared_error: 88.2180 - val_loss: 131.7141 - val_mean_squared_error: 131.7141\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 78.4015 - mean_squared_error: 78.4015 - val_loss: 123.3307 - val_mean_squared_error: 123.3307\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 76.7576 - mean_squared_error: 76.7576 - val_loss: 117.2105 - val_mean_squared_error: 117.2105\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 75.3287 - mean_squared_error: 75.3287 - val_loss: 119.2848 - val_mean_squared_error: 119.2848\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 72.8740 - mean_squared_error: 72.8740 - val_loss: 112.5205 - val_mean_squared_error: 112.5205\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 67.5822 - mean_squared_error: 67.5822 - val_loss: 109.2354 - val_mean_squared_error: 109.2354\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 63.8310 - mean_squared_error: 63.8310 - val_loss: 108.9710 - val_mean_squared_error: 108.9710\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 60.3227 - mean_squared_error: 60.3227 - val_loss: 109.3328 - val_mean_squared_error: 109.3328\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 57.0631 - mean_squared_error: 57.0631 - val_loss: 108.2851 - val_mean_squared_error: 108.2851\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 51.4010 - mean_squared_error: 51.4010 - val_loss: 103.8468 - val_mean_squared_error: 103.8468\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 50.1560 - mean_squared_error: 50.1560 - val_loss: 115.0975 - val_mean_squared_error: 115.0975\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 48.9546 - mean_squared_error: 48.9546 - val_loss: 115.2321 - val_mean_squared_error: 115.2321\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 43.8321 - mean_squared_error: 43.8321 - val_loss: 111.4516 - val_mean_squared_error: 111.4516\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 44.2489 - mean_squared_error: 44.2489 - val_loss: 106.0003 - val_mean_squared_error: 106.0003\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 38.6860 - mean_squared_error: 38.6860 - val_loss: 114.6445 - val_mean_squared_error: 114.6445\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 37.9338 - mean_squared_error: 37.9338 - val_loss: 109.1803 - val_mean_squared_error: 109.1803\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 35.4157 - mean_squared_error: 35.4157 - val_loss: 116.5509 - val_mean_squared_error: 116.5509\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 35.4284 - mean_squared_error: 35.4284 - val_loss: 108.4960 - val_mean_squared_error: 108.4960\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 31.4062 - mean_squared_error: 31.4062 - val_loss: 111.5894 - val_mean_squared_error: 111.5894\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 30.0228 - mean_squared_error: 30.0228 - val_loss: 106.4505 - val_mean_squared_error: 106.4505\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 10.190523329022472\n",
            "\n",
            "Training with hidden_layers=4\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 2s 4ms/step - loss: 1299.7823 - mean_squared_error: 1299.7823 - val_loss: 171.2796 - val_mean_squared_error: 171.2796\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 141.5583 - mean_squared_error: 141.5583 - val_loss: 139.6780 - val_mean_squared_error: 139.6780\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 113.4619 - mean_squared_error: 113.4619 - val_loss: 130.4435 - val_mean_squared_error: 130.4435\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 101.2980 - mean_squared_error: 101.2980 - val_loss: 132.2406 - val_mean_squared_error: 132.2406\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 93.1754 - mean_squared_error: 93.1754 - val_loss: 123.2023 - val_mean_squared_error: 123.2023\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 91.5215 - mean_squared_error: 91.5215 - val_loss: 113.1907 - val_mean_squared_error: 113.1907\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 82.9733 - mean_squared_error: 82.9733 - val_loss: 127.5205 - val_mean_squared_error: 127.5205\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 81.1726 - mean_squared_error: 81.1726 - val_loss: 103.4848 - val_mean_squared_error: 103.4848\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 76.1356 - mean_squared_error: 76.1356 - val_loss: 117.7527 - val_mean_squared_error: 117.7527\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 78.4608 - mean_squared_error: 78.4608 - val_loss: 109.0379 - val_mean_squared_error: 109.0379\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 69.6581 - mean_squared_error: 69.6581 - val_loss: 109.3157 - val_mean_squared_error: 109.3157\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 66.9219 - mean_squared_error: 66.9219 - val_loss: 105.8323 - val_mean_squared_error: 105.8323\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 64.9126 - mean_squared_error: 64.9126 - val_loss: 102.0129 - val_mean_squared_error: 102.0129\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 63.8392 - mean_squared_error: 63.8392 - val_loss: 104.0685 - val_mean_squared_error: 104.0685\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 65.0074 - mean_squared_error: 65.0074 - val_loss: 106.1404 - val_mean_squared_error: 106.1404\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 56.1924 - mean_squared_error: 56.1924 - val_loss: 107.2112 - val_mean_squared_error: 107.2112\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 58.5534 - mean_squared_error: 58.5534 - val_loss: 108.8304 - val_mean_squared_error: 108.8304\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 55.3392 - mean_squared_error: 55.3392 - val_loss: 106.4455 - val_mean_squared_error: 106.4455\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 51.3710 - mean_squared_error: 51.3710 - val_loss: 107.2006 - val_mean_squared_error: 107.2006\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 49.5285 - mean_squared_error: 49.5285 - val_loss: 106.8486 - val_mean_squared_error: 106.8486\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 50.0291 - mean_squared_error: 50.0291 - val_loss: 106.6938 - val_mean_squared_error: 106.6938\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 52.0974 - mean_squared_error: 52.0974 - val_loss: 106.5100 - val_mean_squared_error: 106.5100\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 42.9236 - mean_squared_error: 42.9236 - val_loss: 125.0121 - val_mean_squared_error: 125.0121\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 10.10014486690117\n",
            "\n",
            "Training with hidden_layers=5\n",
            "Epoch 1/100\n",
            "165/165 [==============================] - 2s 4ms/step - loss: 1421.4653 - mean_squared_error: 1421.4653 - val_loss: 200.7914 - val_mean_squared_error: 200.7914\n",
            "Epoch 2/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 147.8718 - mean_squared_error: 147.8718 - val_loss: 163.1904 - val_mean_squared_error: 163.1904\n",
            "Epoch 3/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 120.5359 - mean_squared_error: 120.5359 - val_loss: 144.3036 - val_mean_squared_error: 144.3036\n",
            "Epoch 4/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 104.8886 - mean_squared_error: 104.8886 - val_loss: 137.9430 - val_mean_squared_error: 137.9430\n",
            "Epoch 5/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 96.2066 - mean_squared_error: 96.2066 - val_loss: 138.9276 - val_mean_squared_error: 138.9276\n",
            "Epoch 6/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 89.7918 - mean_squared_error: 89.7918 - val_loss: 128.6472 - val_mean_squared_error: 128.6472\n",
            "Epoch 7/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 85.3270 - mean_squared_error: 85.3270 - val_loss: 116.6328 - val_mean_squared_error: 116.6328\n",
            "Epoch 8/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 78.0316 - mean_squared_error: 78.0316 - val_loss: 136.7692 - val_mean_squared_error: 136.7692\n",
            "Epoch 9/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 71.0029 - mean_squared_error: 71.0029 - val_loss: 119.0034 - val_mean_squared_error: 119.0034\n",
            "Epoch 10/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 72.8007 - mean_squared_error: 72.8007 - val_loss: 110.9543 - val_mean_squared_error: 110.9543\n",
            "Epoch 11/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 65.6451 - mean_squared_error: 65.6451 - val_loss: 109.0642 - val_mean_squared_error: 109.0642\n",
            "Epoch 12/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 61.9034 - mean_squared_error: 61.9034 - val_loss: 108.7698 - val_mean_squared_error: 108.7698\n",
            "Epoch 13/100\n",
            "165/165 [==============================] - 1s 3ms/step - loss: 61.2834 - mean_squared_error: 61.2834 - val_loss: 115.0868 - val_mean_squared_error: 115.0868\n",
            "Epoch 14/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 59.7856 - mean_squared_error: 59.7856 - val_loss: 106.5844 - val_mean_squared_error: 106.5844\n",
            "Epoch 15/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 51.8211 - mean_squared_error: 51.8211 - val_loss: 112.1795 - val_mean_squared_error: 112.1795\n",
            "Epoch 16/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 47.5666 - mean_squared_error: 47.5666 - val_loss: 105.3836 - val_mean_squared_error: 105.3836\n",
            "Epoch 17/100\n",
            "165/165 [==============================] - 1s 5ms/step - loss: 45.5084 - mean_squared_error: 45.5084 - val_loss: 107.2948 - val_mean_squared_error: 107.2948\n",
            "Epoch 18/100\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 44.8692 - mean_squared_error: 44.8692 - val_loss: 107.6364 - val_mean_squared_error: 107.6364\n",
            "Epoch 19/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 41.5420 - mean_squared_error: 41.5420 - val_loss: 106.5898 - val_mean_squared_error: 106.5898\n",
            "Epoch 20/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 40.7385 - mean_squared_error: 40.7385 - val_loss: 107.0688 - val_mean_squared_error: 107.0688\n",
            "Epoch 21/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 36.5269 - mean_squared_error: 36.5269 - val_loss: 110.8824 - val_mean_squared_error: 110.8824\n",
            "Epoch 22/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 33.8329 - mean_squared_error: 33.8329 - val_loss: 110.5118 - val_mean_squared_error: 110.5118\n",
            "Epoch 23/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 34.8166 - mean_squared_error: 34.8166 - val_loss: 113.1081 - val_mean_squared_error: 113.1081\n",
            "Epoch 24/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 31.7986 - mean_squared_error: 31.7986 - val_loss: 115.7997 - val_mean_squared_error: 115.7997\n",
            "Epoch 25/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 30.0817 - mean_squared_error: 30.0817 - val_loss: 110.2039 - val_mean_squared_error: 110.2039\n",
            "Epoch 26/100\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 26.6603 - mean_squared_error: 26.6603 - val_loss: 113.6103 - val_mean_squared_error: 113.6103\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "RMSE: 10.265652065455408\n",
            "\n",
            "  Hidden Layers       RMSE\n",
            "0             1   9.956706\n",
            "1             2  10.221377\n",
            "2             3  10.190523\n",
            "3             4  10.100145\n",
            "4             5  10.265652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best parameters: learning rate=0.0001, optimizer=adam, dropout_rate=0.0, epochs=50, RMSE VALUE: 9.712043589463898"
      ],
      "metadata": {
        "id": "ggyj-PhBQ1ON"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7R_-38_BO84O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}